\question[9] Indicate \textbf{true} if the statement is true, otherwise, indicate \textbf{false}.

\vspace{-0.8cm}
\setlength{\extrarowheight}{0.20cm}
\begin{center}
\hspace{-.9cm}\begin{tabular}[H]{ p{.15cm} p{14.2cm} p{.6cm} p{.6cm} }
       & & true &  false  \\[2pt] \hline 
    
    % DETERMINANTS
    a) &  
    \ifnum \Version=0      
        If $\det(A) =0$, then zero is a root of the characteristic polynomial of $A$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: true, because if $\det A = 0$, then the matrix will be singular, and singular matrices have a zero eigenvalue.}  } \fi
    \fi            
    \ifnum \Version=1         
        If $A$ is $n\times n$, and $A$ does not have $n$ pivots, then $\text{det}(A) = 0$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because the determinant of a singular matrix is zero. } \fi
    \fi
    \ifnum \Version=2      
        If $A$ is square and row equivalent to an identity matrix, then det$(A) \ne 0$.
        \ifnum \Solutions=1 {\color{DarkBlue} 
        \textit{Solution:} true, because the matrix will be invertible, and the determinant of an invertible matrix is non-zero.}   \fi
    \fi    
    \ifnum \Version=3  
        If $A$ is $n\times n$, and there exists a $\vec b \in \mathbb R^n$ such that $A\vec x = \vec b$ is inconsistent, then $\text{det}(A) = 0$.    
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: true, because the matrix will be singular, and the determinant of an singular matrix is zero.}  } \fi
    \fi    
    \ifnum \Version=4    
        Swapping the rows of $A$ does not change the value of $\text{det}(A)$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{False. This is a property of determinants. Swapping a row changes the sign of the determinant.}  } \fi
    \fi   
    \ifnum \Version=5    
        Swapping the rows of $A$ does not change the value of $\text{det}(A)$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: false, a property of determinants is that swapping rows changes the sign of the determinant. }  } \fi
    \fi    
    \ifnum \Version=6
        If $A$ is a $n\times n$, and  $\text{det}(A) = 3$, then  $Ax=b$ has a solution for all $b\in \mathbb R^n$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } True. The determinant is non-zero, so matrix is invertible, and $x= A^{-1}b$ is the solution. } \fi
    \fi    
    \ifnum \Version=7
        If $E$ is a $2\times2$ elementary matrix, then $\text{det}(E) = 1$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: false. An elementary matrix is any square matrix that is obtained by applying one row operation to the identity. For example \setlength{\extrarowheight}{0.0cm} $E = \begin{pmatrix} 2&0\\0&1 \end{pmatrix}$ is an elementary matrix, and $\det A \ne 0$. }  } \fi
    \fi    
    \ifnum \Version=8
         If $A$ is a $n\times n$, and  $\text{det}(A) = 3$, then $3$ is an eigenvalue of $A$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. The number 3 is an eigenvalue when $\text{det}(A - 3I) = 0$, not when $\det A = 3$. } \fi
    \fi   
    \ifnum \Version=9
        If $E$ is n $n\times n$ elementary matrix, then $\text{det}(E) \ne 0$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: True. An elementary matrix is any square matrix that is obtained by applying one row operation to the identity. So all elementary matrices are row equivalent to the identity, so they must also be invertible. Invertible matrices have non-zero determinants. }  } \fi
    \fi        
    & $\bigcirc$  & $\bigcirc$ \\
    
    % STOCHASTIC
    b) & 
    \ifnum \Version=0      
    The set of all probability vectors in $\mathbb R^n$ forms a subspace of $\mathbb R^n$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, because if $v$ is a probability vector, then $kv$ is not a probability vector for every $k$. } \fi
    \fi          
    \ifnum \Version=1         
        If $A$ is an $n\times n$ stochastic matrix and $\vec p$ is a column of $A$, then $\vec p$ is a probability vector. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because the columns of a stochastic matrix are probability vectors (by definition).  } \fi
    \fi
    \ifnum \Version=2   
        The steady state of a stochastic matrix is unique. \ifnum \Solutions=1 {\color{DarkBlue} false, a counterexample would be the chain $x_{k+1} = Px_k$ with $P = I_n$.   } \fi
    \fi    
    \ifnum \Version=3  
        A steady-state vector of a regular stochastic matrix $P$ is unique. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, this is one of the theorems we covered in lecture and is given in the textbook. Regularity means starting from any state of the Markov Chain, one will visit every other state.} \fi
    \fi    
    \ifnum \Version=4      
        Any stochastic matrix with a zero entry cannot be regular.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, if $P$ is a $3\times 3$ stochastic matrix with only one zero entry, then $P$ will have the property that every entry of $P^2$ is positive.} \fi
    \fi   
    \ifnum \Version=5      
        If $q$ is a steady-state vector for stochastic matrix $P$, then the Markov Chain $x_{k+1} = Px_k$ converges to $q$ as $k \to \infty$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, we are only guaranteed that the chain converges to its steady state when it is regular.} \fi
    \fi    
    \ifnum \Version=6
         A steady-state vector of a stochastic matrix $P$ is unique. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. Think of a Chain where state A only goes to A, and B only goes to B. Regularity is required for uniqueness of the Markov state.  Regularity means starting from any state of the Markov Chain, one will visit every other state.} \fi
    \fi    
    \ifnum \Version=7
        $1$ is always an eigenvalue for any stochastic matrix $P$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } True. A steady state always exists for any stochastic matrix, and the steady-state is an eigenvector associated with eigenvalue $1$.} \fi
    \fi    
    \ifnum \Version=8
        A steady state vector of a regular stochastic matrix only has positive entries.  
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } True. Because the steady state is defined as a probability vector, and probability vectors have entries that are between 0 and 1. Also because regular means that every state can visit every other state, so every entry of the steady state vector must be positive. } \fi
    \fi        
    & $\bigcirc$  & $\bigcirc$ \\ 




    % EIG 1 EASY
    c) & 
    \ifnum \Version=0      
        Row operations on a matrix do not change its eigenvalues. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: false, row operations can change the eigenvalues of a matrix. Change the rows on the $2\times 2$ Identity, for instance.}  } \fi
    \fi          
    \ifnum \Version = 1
        If $A$ is $n\times n$ and upper triangular then the eigenvalues of $A$ are non-zero. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: false, because for example the matrix \setlength{\extrarowheight}{0.00cm} $\begin{pmatrix} -1&0\\0&0\end{pmatrix}$ is upper triangular and has eigenvalues $-1$ and $0$.}  } \fi
    \fi
    \ifnum \Version=2      
        A $2\times 2$ matrix $A$ whose rank is $1$ must have an eigenvalue that is equal to zero. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because the matrix must be singular if its rank is only 1, and singular matrices have at least one eigenvalue that is equal to zero. } \fi
    \fi    
    \ifnum \Version=3  
        If $\lambda=0$ is an eigenvalue of $A$, then the matrix $A$ is non-singular.    
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: false, if an eigenvalue is zero the matrix must be non-invertible.}  } \fi
    \fi    
    \ifnum \Version=4      
        An eigenspace is a subspace spanned by a single eigenvector.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: false because an eigenspace is a subspace, but an eigenspace can be spanned by two eigenvectors. Take for example the matrix $A = \begin{pmatrix} 1&0&0\\0&2&0\\0&0&2\end{pmatrix}$ The eigenspace for eigenvalue $\lambda = 2$ is two dimensional. }  } \fi
    \fi   
    \ifnum \Version=5      
        An eigenvalue of a matrix could be associated with two linearly independent eigenvectors. 
        \ifnum \Solutions=1 {\color{DarkBlue} \setlength{\extrarowheight}{0.0cm} \textit{Solution: true, for example $A = \begin{pmatrix} 2&0\\0 & 2 \end{pmatrix}$ has eigenvalue $\lambda = 2$, and the eigenvectors $\begin{pmatrix}1\\0 \end{pmatrix}$ and $\begin{pmatrix}0\\1 \end{pmatrix}$ are associated with $\lambda = 2$.  }  } \fi
    \fi    
    \ifnum \Version=6
         An eigenspace of a square matrix $A$ has a basis that consists of eigenvectors. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } True. Every non-zero vector in an eigenspace is an eigenvector. So any basis consists only of eigenvectors. } \fi
    \fi    
    \ifnum \Version=7
        The dimension of an eigenspace of a square matrix $A $ is one. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. The eigenspace of the $n\times n$ identity matrix is $\mathbb R^n$.   } \fi
    \fi    
    \ifnum \Version=8
        If $A$ is a square matrix, and $A -3I $ is non-singular, then $3$ is an eigenvector of $A$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False.  $A-3I$ should be \emph{singular.} } \fi
    \fi        
    \ifnum \Version=9
        If $A$ is a $n\times n$ and $A +6I $ is singular, then $-6$ is an eigenvalue of the matrix. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: True. There is a vector $x$ so that $(A+6I)x=0$, which means $Ax=-6x$.}  } \fi    
    \fi
    & $\bigcirc$  & $\bigcirc$ \\
    
    
    % EIG 2 SIMILAR
    d) &  
    \ifnum \Version=0      
        If matrices $A$ and $B$ have the same eigenvalues, then $A$ and $B$ are similar. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, this was covered in lectures and the textbook. A counter example would be the matrices \setlength{\extrarowheight}{0.0cm} $A = \begin{pmatrix} 0&1\\0&0\end{pmatrix} , B = \begin{pmatrix} 0&0\\0&0 \end{pmatrix}$. The two matrices have the same eigenvalues but cannot be similar because there is no $P$ so that $A = PBP^{-1}$, because $PBP^{-1} = P\begin{pmatrix} 0&0\\0&0 \end{pmatrix}P^{-1} =  \begin{pmatrix} 0&0\\0&0 \end{pmatrix} \ne A$.} \fi
    \fi          
    \ifnum \Version=1         
        If two matrices have the same eigenvalues, then the matrices are similar. \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. Similarity implies the same eigenvalues. But requires the same eigenvectors as well. The identity matrix and
        \setlength{\extrarowheight}{0.00cm}$\begin{pmatrix}
            1 &1 \\ 0 & 1
        \end{pmatrix}$ are not similar.} \fi
    \fi 
    \ifnum \Version=2      
        If $A$ is square and similar to the identity matrix, then $A$ is the identity matrix. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because if A is similar to I, then $A = PIP^{-1} = PP^{-1} = I$.  } \fi
    \fi    
    \ifnum \Version=3  
        If matrices $A$ and $B$ are similar then $A$ and $B$ have the same eigenvalues. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, this is a theorem introduced in lectures and the textbook.   } \fi
    \fi    
    \ifnum \Version=4      
        If matrices $A$ and $B$ are similar then $A$ and $B$ have the same characteristic polynomial. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: }  true, this is a theorem introduced in lectures and the textbook.} \fi
    \fi   
    \ifnum \Version=5      
        If matrices $A$ and $B$ are similar then $A$ and $B$ must have the same eigenvalues. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, this is a theorem introduced in lectures and the textbook.   } \fi
    \fi    
    \ifnum \Version=6
        If $A$ and $B$ are $2\times 2$ similar matrices, then $A$ and $B$ have the same rank. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } True. They share the same eigenvalues, and the rank would be the number of non-zero eigenvalues, with multiplicity. } \fi
    \fi    
    \ifnum \Version=7
        If matrices $A$ and $B$ have the same eigenvalues, then $A$ and $B$ are similar. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. We encountered a counterexample in lectures. } \fi
        \fi    
    \ifnum \Version=8
        A non-zero matrix $A$ can be similar to the zero matrix. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. 
        We have $A = P 0 P^{-1} = 0$} \fi
    \fi        
    & $\bigcirc$  & $\bigcirc$ \\ 
       
    
    
    
    % DIAG AND INVERTIBILITY
    e) & 
    \ifnum \Version=0      
        If $A$ is $n \times n$ and not invertible, then $A$ cannot be diagonalizable. 
        \ifnum \Solutions=1 {\color{DarkBlue} 
        \textit{Solution: } false, the zero matrix is a counterexample because it is both singular and diagonalizable. Also, matrices with distinct eigenvalues are also diagonalizable. So a matrix such as \setlength{\extrarowheight}{0.0cm}
        $\begin{pmatrix} 1&0\\0&0\end{pmatrix}$ is another counter example because it is both singular and diagonalizable. }\fi
    \fi          
    \ifnum \Version = 1
        If $A$ is a diagonalizable $n\times n$ matrix, then rank$(A) = n$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. The zero matrix is diagonalizable. } \fi
    \fi 
    \ifnum \Version=2      
    If $A$ is $n \times n$ and not diagonalizable, then $A$ is not invertible. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, a counterexample would be \setlength{\extrarowheight}{0.0cm}$A = \begin{pmatrix} 1&1\\0&1\end{pmatrix}$} \fi
    \fi    
    \ifnum \Version=3  
    If $A$ is $n \times n$ and diagonalizable, then $A$ is invertible. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, the zero matrix is diagonalizable.} \fi
    \fi    
    \ifnum \Version=4      
    If $A$ is $n \times n$ and not diagonalizable, then $A$ is not invertible. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false} \fi
    \fi   
    \ifnum \Version=5      
        If $A$ is $n \times n$ and not invertible, then $A$ is not diagonalizable. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, a counterexample would be \setlength{\extrarowheight}{0.0cm}$A = \begin{pmatrix} 1&1\\0&1\end{pmatrix}$} \fi
    \fi    
    \ifnum \Version=6
        Suppose $A$ is a diagonalizable $n\times n$ matrix, $x$ and $b$ are vectors in $\mathbb R^n$. The linear system $Ax=b$ has a solution for all $n$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. The zero matrix is diagonalizable. } 
         \fi
    \fi    
    \ifnum \Version=7
        If $A$ is a diagonalizable $n\times n$ matrix, then $A$ has $n$ distinct eigenvalues.  
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. The zero matrix is diagonalizable, and all eigenvalues equal zero. } 
         \fi
    \fi    
    \ifnum \Version=8
        If $A$ is a diagonalizable $n\times n$ matrix, then  it is similar to a diagonal matrix. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } True. That is the definition.} 
     \fi
    \fi        
    & $\bigcirc$  & $\bigcirc$ \\
    
    
    % DIAGONALIZABLE AND EIGENVALUES OR OTHER DIAGONALIZABILITY THING
    f) & 
    \ifnum \Version=0  
        If an $n\times n$ matrix has $n$ distinct eigenvalues, then the matrix is diagonalizable.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: }  true, this is a theorem introduced in the textbook and in lectures. } \fi
    \fi        
    \ifnum \Version = 1
        If $A$ is $n\times n$ and diagonalizable, then $A$ has $n$ distinct eigenvalues. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, the zero matrix and identity matrix are examples of matrices that are diagonalizable, with  } \fi
    \fi 
    \ifnum \Version=2      
        If $A$ is $n\times n$ has $n$ distinct eigenvalues then $A$ is diagonalizable. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, this is a theorem introduced in the textbook and in lectures. } \fi
    \fi    
    \ifnum \Version=3  
        Suppose $A$ is a $3\times3$ matrix with two eigenvalues, $\lambda_1$ and $\lambda_2$. If the geometric multiplicity of $\lambda_1$ is 1, and the geometric multiplicity of $\lambda_2$ is 2, then $A$ must be diagonalizable. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, if the sum of the geometric multiplicities is equal to the sum of the algebraic multiplicities, the matrix is diagonalizable.  } \fi
    \fi    
    \ifnum \Version=4      
        The $n\times n$ zero matrix can be diagonalized. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because it is diagonal. } \fi
    \fi   
    \ifnum \Version=5      
        Suppose $A$ is a $4\times 4$ matrix that has exactly 2 distinct eigenvalues. If both of them have geometric multiplicity 2, then $A$ can be diagonalized.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, if the sum of the geometric multiplicities is equal to the sum of the algebraic multiplicities, the matrix is diagonalizable. } \fi
    \fi      
    \ifnum \Version=6
         If matrix $A$ is $n\times n$ and has $n$ distinct eigenvalues, then $\text{rank} A = n$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: }  False. An eigenvalue could be zero.  } \fi
    \fi    
    \ifnum \Version=7
       If an $n\times n$ matrix has $n$ distinct eigenvalues, then $Ax=b$ 
       has a solution for all $b$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. An eigenvalue could be zero.} \fi
    \fi    
    \ifnum \Version=8
        The only $2\times 2$ matrix that has the eigenvalues $\lambda_1 = \lambda_2 = 0$ is the zero matrix.  
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: False.}  
        a counterexample would be \setlength{\extrarowheight}{0.0cm}$A = \begin{pmatrix} 0&1\\0&0\end{pmatrix}$} \fi
    \fi            
    & $\bigcirc$  & $\bigcirc$ \\
    

    % COMPLEX OR GOOGLE PAGE RANK
    g) & 
    \ifnum \Version=0      
        If $A \in \mathbb R^{2\times2}$ has complex eigenvalues $\lambda_1$ and $\lambda_2$, then $|\lambda_1 | = |\lambda_2|$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true because the eigenvalues are complex conjugates of each other. } \fi
    \fi        
    \ifnum \Version=1
        The steady-state of the Google matrix for any web with at least two pages is unique when the damping factor, $p$, is equal to 0.85.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true because the second adjustment will force the matrix to have positive entries.  } \fi
    \fi        
    \ifnum \Version = 2
        If the characteristic polynomial of a $2\times 2$ matrix has no real roots, then $A$ must have two complex eigenvalues. \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, the roots are the eigenvalues of the matrix. So if the roots are complex the eigenvalues are also complex.} \fi
    \fi 
    \ifnum \Version=3
        If $A$ is a real $n\times n$ matrix and $n$ is odd, at least one of the eigenvalues of $A$ is real.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true because complex eigenvalues come in conjugate pairs, so if $n$ is odd then one eigenvalue must be real. } \fi
    \fi         
    \ifnum \Version=4      
        The Google matrix for any web with at least two pages is always regular stochastic when the damping factor, $p$, is equal to 0.85.     
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true because the second adjustment will force the matrix to have positive entries.} \fi
    \fi   
    \ifnum \Version=5      
        If $A$ is a real $2\times 2$ singular matrix, then both eigenvalues of $A$ cannot have an imaginary component. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because eigenvalues come in conjugate pairs and one eigenvalue is zero. } \fi
    \fi     
    \ifnum \Version=6
        A $2 \times 2$ matrix $A$ with characteristic polynomial $\lambda ^2 +1 $ has two complex eigenvalues. 
        %%%%%%%%%%%%%%
        %  The pmatrix below was causing a mysterious problem. --MTL
        %%%%%%%%%%%%%
        %The matrix  \setlength{\extrarowheight}{0.0cm}
       %$ A = \begin{pmatrix}0&-1\\1&0\end{pmatrix}$ 
       %has two complex eigenvalues. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: True.} The characteristic polynomial is $\lambda ^2 + 1=0$, and the eigenvalues  are $\pm i$} 
    \fi \fi    
    \ifnum \Version=7
    A $2 \times 2$ matrix $A$ with characteristic polynomial $\lambda ^2 +1 $ has two real eigenvalues. 
    %%%%%%%% See comment in the previous problem. 
    %    The matrix  \setlength{\extrarowheight}{0.0cm}
         %$A = \begin{pmatrix} 0&-1\\1&0\end{pmatrix}$ has two real  eigenvalues. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: False.} The characteristic polynomial is $\lambda ^2 + 1=0$, and the eigenvalues  are $\pm i$} 
    \fi
    \fi    
    \ifnum \Version=8
         If $A$ is a real $5\times 5$ matrix, then at least one of the eigenvalues of $A$ is real.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true because complex eigenvalues come in conjugate pairs.  There are 5 eigenvalues, so one must be odd. } \fi
    \fi            
    & $\bigcirc$  & $\bigcirc$ \\

    
    % SECOND DETERMINANT
    h) & 
    \ifnum \Version=0    
        If $A$ is $n\times n$ and invertible, then $\det(A^3) \ne 0$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because $\det(A^3) = (\det A)(\det A)(\det A) = (\det A)^3 $. And if $A$ is invertible, $\det A \ne 0$, so $(\det A)^3 \ne 0$, so $\det (A^3)$ is also nonzero.  } \fi
    \fi  
    \ifnum \Version = 1 
        If $A$ and $B$ are $n\times n$ matrices, $n>1$, and $B$ is obtained by swapping two of the rows of $A$, then $\det A = \det B$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, a row swap will change the sign of the determinant. } \fi
    \fi
    \ifnum \Version = 2
        If $A$ and $B$ are invertible $n\times n$ matrices, then $\det(AB)\ne 0$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because $\det(AB) = \det A \det B$ and if $A$ and $B$ are invertible, then $\det A$ and $\det B$ are non-zero.  } \fi
    \fi
    \ifnum \Version = 3
        If $\det(A)= 4$ and $A$ is a $2\times2$ matrix, then $\det(2A)=8$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } \setlength{\extrarowheight}{0.0cm}False. $\det(2A) = 2^2\det A = 2^2\cdot4 = 16$. We can verify this result with any $2\times2$ matrix whose determinant is $4$. Take for example the case where $A = \begin{pmatrix} 4&0\\0&1\end{pmatrix}$, Then $\det(2A) = \det\left(2 \begin{pmatrix} 4&0\\0&1\end{pmatrix}\right) = \det\begin{pmatrix} 8&0\\0&2 \end{pmatrix} = 8\cdot 2 = 16$. } \fi
    \fi
    \ifnum \Version = 4
       If $\det(A)= 3$ and $A$ is a $2\times2$ matrix, then $\det(2A)=6$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: }  False. Take for example the matrix \setlength{\extrarowheight}{0.0cm} $A = \begin{pmatrix}1&0\\0&3 \end{pmatrix}$. Then $\det(A) = 3$, and $\det(2A) = \det \left( \begin{pmatrix} 2&0\\0&6\end{pmatrix} \right) = 12$. For any $2\times 2$ matrix, $\det(2A) = 4\det A$.} \fi
    \fi     
    \ifnum \Version = 5
       If $\det(A)= 3$ and $A$ is a $2\times2$ matrix, then $\det(2A)=6$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: }  false, $\det(2A) = 4\det A = 4\cdot6 = 12$. } \fi
    \fi     
    \ifnum \Version=6
        If $A$ and $B$ are $n\times n$ matrices, $n>1$, and $B$ is obtained by swapping two of the rows of $A$, then $\det A = -\det B$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } True, a row swap will change the sign of the determinant. } 
         \fi
    \fi    
    \ifnum \Version=7
        If $\det(A)= 3$ and $A$ is a $3\times3$ matrix, then $\det(-A)=-3$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: True.}   $\det(-A) = (-1)^3\det A = -3$. } \fi
    \fi    
    \ifnum \Version=8
          If $\det(A)= 3$ and $A$ is a $3\times3$ matrix, then $\det(-A)=3$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: False.}  , $\det(-A) = (-1)\det A = -3$. } \fi
    \fi            
    & $\bigcirc$  & $\bigcirc$ \\
    
    
    % OTHER
    i) & 
    \ifnum \Version=0
        A stochastic matrix that is not regular can have a unique steady-state vector. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, the matrix \setlength{\extrarowheight}{0.0cm} $\begin{pmatrix} 0&1\\1&0\end{pmatrix}$ is one such example. Any stochastic matrix $P$ with the property that $I-P$ has exactly one non-pivot column will have a unique steady-state. } \fi
    \fi          
    \ifnum \Version = 1
        The geometric multiplicity of an eigenvalue $\lambda$ can be zero.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, because the dimension of an eigenspace must be at least one.  } \fi
    \fi     
    \ifnum \Version = 2
        If an eigenvalue of $n\times n$ matrix $A$ is $\lambda = 1$, then $\dim(\Null(A - I)) = n-1$.    
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, a counterexample would be \setlength{\extrarowheight}{0.0cm} $A = \begin{pmatrix}1&0\\0&1 \end{pmatrix}$, because $\dim(\Null(A - I)) = 2 \ne n -1$. } \fi
    \fi     
    \ifnum \Version = 3
        If $A$ is an $n\times n$ matrix and has eigenvector $\vec x$, then $2\vec x$ is also an eigenvector of $A$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } true, because 
        $A(2 \vec x)= 2 A \vec x = 2 \lambda \vec x = \lambda (2\vec x)$.  Non-zero multiples of eigenvectors are eigenvectors. 
        %if $\vec x$ satisfies $$A\vec v = \lambda \vec v$$ then $$A(2\vec v) = \lambda (2\vec v)$$ simplifies to $$A\vec v = \lambda \vec v$$ because the factor of 2 cancels out.  
        } \fi
    \fi     
    \ifnum \Version = 4
        If $A$ is a square matrix, $\vec v$ and $\vec w$ are eigenvectors of $A$, then $\vec v + \vec w$ is also an eigenvector of $A$. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{False.} The eigenvalues would have to be equal as well. } \fi
    \fi     
    \ifnum \Version = 5
        If a stochastic matrix is not regular then it cannot have a steady state. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } False. Think of State A always goes to State B, and vice versa. Not regular, and has a unique steady state.} \fi
    \fi        
    \ifnum \Version = 6
        If $A$ is an $n\times n$ matrix and has eigenvector $\vec x$, then $2\vec x$ is also an eigenvector of $A$.
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: True.} Because 
        $A(-2 \vec x)= -2 A \vec x = -2 \lambda \vec x = \lambda (2\vec x)$.  Non-zero multiples of eigenvectors are eigenvectors. }
        \fi
    \fi    
    \ifnum \Version = 7
        If an eigenvalue of $n\times n$ matrix $A$ is $\lambda = 2$, then $\dim(\Null(A - 2I)) = n-1$.    
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: } false, a counterexample would be \setlength{\extrarowheight}{0.0cm} $A = \begin{pmatrix}2&0\\0&2 \end{pmatrix}$, because $\dim(\Null(A - I)) = 2 \ne n -1$. } \fi
    \fi    
    \ifnum \Version = 8 
        A regular stochastic matrix has full rank. 
        \ifnum \Solutions=1 {\color{DarkBlue} \textit{Solution: False.} Take the $2\times 2$ matrix with all entries equal to $1/2$.} \fi
    \fi
    & $\bigcirc$  & $\bigcirc$ \\[8pt]     
    \hline
\end{tabular}
\end{center}
\setlength{\extrarowheight}{0.0cm}

