{
    "Parametric Equations and Polar Coordinates": {
        "1-5-conic-sections": [
            {
                "question": "In a parabola, the distance from any point on the parabola to the focus is always equal to the distance from that point to the directrix.",
                "answer": "True",
                "explanation": "A parabola is defined as the set of all points $(x, y)$ such that the distance to a fixed point (the focus) is equal to the distance to a fixed line (the directrix). This means that for any point $(x, y)$ on the parabola, the distance to the focus $(x_f, y_f)$ is equal to the perpendicular distance to the directrix. For example, if the focus is at $(0, 1)$ and the directrix is the line $y = -1$, then any point $(x, y)$ on the parabola will satisfy the condition $\\sqrt{(x - 0)^2 + (y - 1)^2} = |y + 1|$. This equality is the fundamental property of a parabola."
            },
            {
                "question": "The equation of a parabola opening upward with vertex at (h, k) and focus at (h, k + p) is given by $y = \\frac{1}{4p}(x - h)^2 + k$.",
                "answer": "True",
                "explanation": "The standard form of a parabola that opens upward with its vertex at $(h, k)$ and focus at $(h, k + p)$ is indeed given by $y = \\frac{1}{4p}(x - h)^2 + k$. This equation represents a parabola where $p$ is the distance from the vertex to the focus. For example, if the vertex is at $(2, 3)$ and $p = 1$, the focus would be at $(2, 4)$, and the equation of the parabola would be $y = \\frac{1}{4}(x - 2)^2 + 3$."
            },
            {
                "question": "An ellipse is defined as the set of all points such that the sum of their distances from two fixed points, called the foci, is always the same.",
                "answer": "True",
                "explanation": "An ellipse is indeed defined by the property that for any point on the ellipse, the sum of its distances to two fixed points (the foci) is constant. This constant sum is greater than the distance between the foci. For example, if the foci are at points $F_1$ and $F_2$, and a point on the ellipse is $P$, then $d(P, F_1) + d(P, F_2)$ is always equal to a constant value. This property distinguishes ellipses from other conic sections like parabolas and hyperbolas."
            },
            {
                "question": "For an ellipse with a horizontal major axis, the equation in standard form is $\\frac{(x-h)^2}{a^2} + \\frac{(y-k)^2}{b^2} = 1$ and the foci are located at $(h \\pm c, k)$ where $c^2 = a^2 - b^2$.",
                "answer": "True",
                "explanation": "The standard form of the equation of an ellipse with a horizontal major axis is $\\frac{(x-h)^2}{a^2} + \\frac{(y-k)^2}{b^2} = 1$. Here, $(h,k)$ is the center of the ellipse, $2a$ is the length of the major axis, and $2b$ is the length of the minor axis. The foci of the ellipse are located at $(h \\pm c, k)$, where $c$ is given by $c^2 = a^2 - b^2$. For example, if $a = 5$ and $b = 3$, then $c = \\sqrt{5^2 - 3^2} = \\sqrt{25 - 9} = \\sqrt{16} = 4$, so the foci would be at $(h \\pm 4, k)$."
            },
            {
                "question": "A hyperbola is defined as the set of all points where the sum of their distances from two fixed points (the foci) is constant.",
                "answer": "False",
                "explanation": "A hyperbola is actually defined as the set of all points where the difference between their distances from two fixed points (the foci) is constant. This is different from an ellipse, where the sum of the distances from the foci to any point on the ellipse is constant. For example, if the foci of a hyperbola are at points $F_1$ and $F_2$, and a point on the hyperbola is $P$, then $|PF_1 - PF_2|$ is constant. In contrast, for an ellipse, the sum $PF_1 + PF_2$ is constant."
            },
            {
                "question": "For a hyperbola with a horizontal major axis and center at $(h, k)$, the equation is given by $\\frac{(x-h)^2}{a^2} - \\frac{(y-k)^2}{b^2} = 1$, and the foci are located at $(h \\pm c, k)$ where $c^2 = a^2 + b^2$.",
                "answer": "True",
                "explanation": "The standard form of the equation of a hyperbola with a horizontal major axis and center at $(h, k)$ is $\\frac{(x-h)^2}{a^2} - \\frac{(y-k)^2}{b^2} = 1$. The foci of this hyperbola are located at $(h \\pm c, k)$, where $c$ is determined by the relationship $c^2 = a^2 + b^2$. For example, if $a = 3$ and $b = 4$, then $c = \\sqrt{3^2 + 4^2} = 5$, so the foci would be at $(h \\pm 5, k)$. This confirms the given statement is true."
            },
            {
                "question": "A conic section with an eccentricity of 0.5 is an ellipse.",
                "answer": "True",
                "explanation": "The eccentricity $e$ of a conic section determines its shape. If $e < 1$, the conic section is an ellipse. Since 0.5 is less than 1, a conic section with an eccentricity of 0.5 is indeed an ellipse. For example, if we have a conic section where the distance from any point on the conic to its focus is half the perpendicular distance from that point to the nearest directrix, this conic section is an ellipse."
            },
            {
                "question": "The polar equation of a conic section with focal parameter $p$ can be expressed as $r = \\frac{ep}{1 \\pm e \\cos \\theta}$ or $r = \\frac{ep}{1 \\pm e \\sin \\theta}$, where $e$ is the eccentricity.",
                "answer": "True",
                "explanation": "The given polar equations $r = \\frac{ep}{1 \\pm e \\cos \\theta}$ and $r = \\frac{ep}{1 \\pm e \\sin \\theta}$ describe conic sections (ellipse, parabola, or hyperbola) in polar coordinates. Here, $r$ is the radial distance, $\\theta$ is the polar angle, $e$ is the eccentricity, and $p$ is the focal parameter. The form of the equation depends on the orientation of the conic section. For example, if the conic section is oriented such that its directrix is perpendicular to the polar axis, the equation $r = \\frac{ep}{1 \\pm e \\cos \\theta}$ is used. If the directrix is parallel to the polar axis, the equation $r = \\frac{ep}{1 \\pm e \\sin \\theta}$ is used. These equations help in identifying the type of conic section based on the value of $e$: $e < 1$ for an ellipse, $e = 1$ for a parabola, and $e > 1$ for a hyperbola."
            }
        ],
        "1-2-calculus-of-parametric-curves": [
            {
                "question": "For a plane curve defined by the parametric equations $x = x(t)$ and $y = y(t)$, if $x'(t) \\neq 0$, then the derivative $\\frac{dy}{dx}$ can be found using $\\frac{dy}{dt}$ and $\\frac{dx}{dt}$ as $\\frac{dy}{dx} = \\frac{y'(t)}{x'(t)}$.",
                "answer": "True",
                "explanation": "The derivative $\\frac{dy}{dx}$ for a curve defined by parametric equations $x = x(t)$ and $y = y(t)$ can be found using the chain rule. Given that $x'(t) \\neq 0$, we can express $\\frac{dy}{dx}$ as $\\frac{dy/dt}{dx/dt} = \\frac{y'(t)}{x'(t)}$. For example, if $x(t) = t^2$ and $y(t) = t^3$, then $x'(t) = 2t$ and $y'(t) = 3t^2$. Thus, $\\frac{dy}{dx} = \\frac{3t^2}{2t} = \\frac{3t}{2}$."
            },
            {
                "question": "The area under a non-self-intersecting plane curve defined by the parametric equations $x = x(t)$ and $y = y(t)$ for $a \\leq t \\leq b$ is given by $A = \\int_a^b y(t) x'(t) \\, dt$.",
                "answer": "True",
                "explanation": "The area under a parametric curve defined by $x = x(t)$ and $y = y(t)$, where $x(t)$ is differentiable and $a \\leq t \\leq b$, is indeed given by the integral $A = \\int_a^b y(t) x'(t) \\, dt$. This formula arises from the concept of integrating the product of the $y$-coordinate and the derivative of the $x$-coordinate with respect to $t$ over the interval $[a, b]$. For example, if $x(t) = t^2$ and $y(t) = t$, then $x'(t) = 2t$, and the area would be $A = \\int_a^b t \\cdot 2t \\, dt = \\int_a^b 2t^2 \\, dt$."
            },
            {
                "question": "The arc length of a parametric curve defined by $x = x(t)$ and $y = y(t)$, where $t_1 \\leq t \\leq t_2$ and both $x(t)$ and $y(t)$ are differentiable, is given by $s = \\int_{t_1}^{t_2} \\sqrt{\\left( \\frac{dx}{dt} \\right)^2 + \\left( \\frac{dy}{dt} \\right)^2} \\, dt$.",
                "answer": "True",
                "explanation": "The arc length formula for a parametric curve $x = x(t)$ and $y = y(t)$, where $t_1 \\leq t \\leq t_2$, is indeed given by $s = \\int_{t_1}^{t_2} \\sqrt{\\left( \\frac{dx}{dt} \\right)^2 + \\left( \\frac{dy}{dt} \\right)^2} \\, dt$. This formula is derived from the Pythagorean theorem applied to infinitesimal segments of the curve. For example, if $x(t) = t$ and $y(t) = t^2$ for $0 \\leq t \\leq 1$, then $\\frac{dx}{dt} = 1$ and $\\frac{dy}{dt} = 2t$. The arc length would be $s = \\int_{0}^{1} \\sqrt{1^2 + (2t)^2} \\, dt = \\int_{0}^{1} \\sqrt{1 + 4t^2} \\, dt$."
            }
        ],
        "1-1-parametric-equations": [
            {
                "question": "If $x = x(t)$ and $y = y(t)$ are continuous functions of $t$ on an interval $I$, then the set of points $(x, y)$ obtained as $t$ varies over $I$ is called a parametric curve.",
                "answer": "True",
                "explanation": "The given statement is true. Parametric equations $x = x(t)$ and $y = y(t)$ describe a set of points $(x, y)$ as the parameter $t$ varies over an interval $I$. This set of points forms a graph known as a parametric curve or plane curve, denoted by $C$. For example, if $x(t) = \\cos(t)$ and $y(t) = \\sin(t)$ for $t$ in $[0, 2\\pi]$, the resulting set of points $(\\cos(t), \\sin(t))$ describes a circle, which is a parametric curve."
            }
        ],
        "1-4-area-and-arc-length-in-polar-coordinates": [
            {
                "question": "The area of a region bounded by a polar curve $r=f(\\theta)$ between the radial lines $\\theta=\\alpha$ and $\\theta=\\beta$ is given by $A=\\frac{1}{2}\\int_{\\alpha}^{\\beta} [f(\\theta)]^2 d\\theta$.",
                "answer": "True",
                "explanation": "The formula for the area of a region bounded by a polar curve $r=f(\\theta)$ between the angles $\\theta=\\alpha$ and $\\theta=\\beta$ is indeed $A=\\frac{1}{2}\\int_{\\alpha}^{\\beta} [f(\\theta)]^2 d\\theta$. This formula is derived from the concept of integrating the square of the radius function over the given interval, scaled by $\\frac{1}{2}$ to account for the polar coordinate system. For example, if $f(\\theta) = 2$ and the interval is from $\\theta=0$ to $\\theta=\\pi$, the area would be $A=\\frac{1}{2}\\int_{0}^{\\pi} 2^2 d\\theta = \\frac{1}{2} \\cdot 4 \\cdot \\pi = 2\\pi$."
            },
            {
                "question": "The arc length of a curve defined by a polar function $r=f(\\theta)$ from $\\theta=\\alpha$ to $\\theta=\\beta$ is given by $L=\\int_{\\alpha}^{\\beta} \\sqrt{[f(\\theta)]^2 + [f'(\\theta)]^2} \\, d\\theta$.",
                "answer": "False",
                "explanation": "The correct formula for the arc length of a curve defined by a polar function $r=f(\\theta)$ from $\\theta=\\alpha$ to $\\theta=\\beta$ is $L=\\int_{\\alpha}^{\\beta} \\sqrt{[f(\\theta)]^2 + \\left(\\frac{dr}{d\\theta}\\right)^2} \\, d\\theta$. The given formula incorrectly omits the square root and uses $f'(\\theta)$ instead of $\\frac{dr}{d\\theta}$. For example, if $r=\\theta$, then $\\frac{dr}{d\\theta}=1$, and the arc length from $\\theta=0$ to $\\theta=\\pi$ would be $L=\\int_{0}^{\\pi} \\sqrt{\\theta^2 + 1} \\, d\\theta$."
            }
        ],
        "1-3-polar-coordinates": [
            {
                "question": "Given a point $P$ in the plane with Cartesian coordinates $(x,y)$ and polar coordinates $(r,\\theta)$, the conversion formulas $x = r \\cos \\theta$ and $y = r \\sin \\theta$ can be used to convert from polar to rectangular coordinates, while the formulas $r^2 = x^2 + y^2$ and $\\tan \\theta = \\frac{y}{x}$ can be used to convert from rectangular to polar coordinates.",
                "answer": "True",
                "explanation": "The formulas $x = r \\cos \\theta$ and $y = r \\sin \\theta$ are used to convert from polar coordinates $(r, \\theta)$ to Cartesian coordinates $(x, y)$. For example, if $r = 5$ and $\\theta = \\frac{\\pi}{4}$, then $x = 5 \\cos \\frac{\\pi}{4} = 5 \\times \\frac{\\sqrt{2}}{2} = \\frac{5\\sqrt{2}}{2}$ and $y = 5 \\sin \\frac{\\pi}{4} = 5 \\times \\frac{\\sqrt{2}}{2} = \\frac{5\\sqrt{2}}{2}$. Conversely, the formulas $r^2 = x^2 + y^2$ and $\\tan \\theta = \\frac{y}{x}$ are used to convert from Cartesian coordinates $(x, y)$ to polar coordinates $(r, \\theta)$. For instance, if $x = 3$ and $y = 4$, then $r = \\sqrt{3^2 + 4^2} = 5$ and $\\theta = \\tan^{-1}(\\frac{4}{3})$."
            },
            {
                "question": "A polar curve given by the equation $r = f(\\theta)$ is symmetric about the polar axis if for every point $(r, \\theta)$ on the graph, the point $(r, -\\theta)$ is also on the graph.",
                "answer": "True",
                "explanation": "Symmetry about the polar axis means that if a point $(r, \\theta)$ lies on the curve, then the point $(r, -\\theta)$ must also lie on the curve. This implies that the equation $r = f(\\theta)$ remains unchanged when $\\theta$ is replaced by $-\\theta$. For example, if $r = 1 + \\cos(\\theta)$, then $r = 1 + \\cos(-\\theta)$ also holds true because $\\cos(\\theta) = \\cos(-\\theta)$. Hence, the curve is symmetric about the polar axis."
            }
        ]
    },
    "Vectors in Space": {
        "2-7-cylindrical-and-spherical-coordinates": [
            {
                "question": "In the cylindrical coordinate system, the ordered triple (r, \u03b8, z) represents a point where (r, \u03b8) are the polar coordinates of the point's projection in the xy-plane, and z is the same as the z-coordinate in the Cartesian coordinate system.",
                "answer": "True",
                "explanation": "In the cylindrical coordinate system, a point is represented by the ordered triple (r, \u03b8, z). Here, (r, \u03b8) are the polar coordinates of the point's projection onto the xy-plane, meaning r is the radial distance from the origin to the projection, and \u03b8 is the angle between the positive x-axis and the line connecting the origin to the projection. The z-coordinate remains the same as in the Cartesian coordinate system, representing the height above or below the xy-plane. For example, the point (3, \u03c0/4, 5) in cylindrical coordinates means the projection in the xy-plane is 3 units away from the origin at an angle of \u03c0/4 radians from the positive x-axis, and the point is 5 units above the xy-plane."
            },
            {
                "question": "To convert from cylindrical coordinates $(r, \\theta, z)$ to Cartesian coordinates $(x, y, z)$, the equations $x = r \\cos \\theta$, $y = r \\sin \\theta$, and $z = z$ are used.",
                "answer": "True",
                "explanation": "The conversion from cylindrical coordinates $(r, \\theta, z)$ to Cartesian coordinates $(x, y, z)$ involves using the equations $x = r \\cos \\theta$, $y = r \\sin \\theta$, and $z = z$. These equations map the radial distance $r$ and the angle $\\theta$ in the cylindrical system to the $x$ and $y$ coordinates in the Cartesian system, while the $z$ coordinate remains unchanged. For example, if a point in cylindrical coordinates is $(2, \\frac{\\pi}{4}, 3)$, then in Cartesian coordinates it would be $(2 \\cos \\frac{\\pi}{4}, 2 \\sin \\frac{\\pi}{4}, 3)$, which simplifies to $(\\sqrt{2}, \\sqrt{2}, 3)$."
            },
            {
                "question": "In the spherical coordinate system, the angle $\\varphi$ is the angle between the positive z-axis and the line segment connecting the origin to the point, and it ranges from $0$ to $2\\pi$.",
                "answer": "False",
                "explanation": "In the spherical coordinate system, the angle $\\varphi$ is indeed the angle between the positive z-axis and the line segment connecting the origin to the point. However, the range of $\\varphi$ is from $0$ to $\\pi$, not $2\\pi$. This means $\\varphi$ can only describe angles up to $180$ degrees, which is sufficient to cover all possible directions from the z-axis to any point in space. For example, if a point is directly above the origin on the positive z-axis, $\\varphi$ is $0$. If it is directly below on the negative z-axis, $\\varphi$ is $\\pi$."
            },
            {
                "question": "To convert from spherical coordinates $(\\rho, \\theta, \\varphi)$ to rectangular coordinates $(x, y, z)$, the equations $x = \\rho \\sin \\varphi \\cos \\theta$, $y = \\rho \\sin \\varphi \\sin \\theta$, and $z = \\rho \\cos \\varphi$ are used.",
                "answer": "True",
                "explanation": "The given equations $x = \\rho \\sin \\varphi \\cos \\theta$, $y = \\rho \\sin \\varphi \\sin \\theta$, and $z = \\rho \\cos \\varphi$ are indeed used to convert from spherical coordinates $(\\rho, \\theta, \\varphi)$ to rectangular coordinates $(x, y, z)$. In spherical coordinates, $\\rho$ represents the radial distance, $\\theta$ is the azimuthal angle, and $\\varphi$ is the polar angle. These equations translate the spherical coordinates into the Cartesian system by projecting the point onto the $x$, $y$, and $z$ axes. For example, if $\\rho = 1$, $\\theta = \\frac{\\pi}{4}$, and $\\varphi = \\frac{\\pi}{3}$, then $x = 1 \\cdot \\sin(\\frac{\\pi}{3}) \\cdot \\cos(\\frac{\\pi}{4}) = \\frac{\\sqrt{2}}{2}$, $y = 1 \\cdot \\sin(\\frac{\\pi}{3}) \\cdot \\sin(\\frac{\\pi}{4}) = \\frac{\\sqrt{2}}{2}$, and $z = 1 \\cdot \\cos(\\frac{\\pi}{3}) = \\frac{1}{2}$."
            }
        ],
        "2-5-equations-of-lines-and-planes-in-space": [
            {
                "question": "The parametric equations x = $x_0$ + ta, y = $y_0$ + tb, and z = z_0 + tc describe a line L parallel to vector $v = \u27e8a, b, c\u27e9$  and passing through point $P(x_0, y_0, z_0)$. If a, b, and c are all nonzero, the line L can also be described by the symmetric equation (x - x_0)/a = (y - y_0)/b = (z - z_0)/c.",
                "answer": "True",
                "explanation": "The parametric equations x = x_0 + ta, y = y_0 + tb, and z = z_0 + tc describe a line L parallel to the vector v = \u27e8a, b, c\u27e9 and passing through the point P(x_0, y_0, z_0). These equations express the coordinates of any point on the line as a function of the parameter t. When the constants a, b, and c are all nonzero, the parametric equations can be rearranged to form the symmetric equation (x - x_0)/a = (y - y_0)/b = (z - z_0)/c. This symmetric form eliminates the parameter t and directly relates the coordinates of any point on the line. For example, if a = 2, b = 3, and c = 4, and the line passes through the point (1, 2, 3), the parametric equations would be x = 1 + 2t, y = 2 + 3t, and z = 3 + 4t. The symmetric equation would then be (x - 1)/2 = (y - 2)/3 = (z - 3)/4."
            },
            {
                "question": "The distance from a point M to a line L, which passes through point P with direction vector v, is given by the formula $d = \\frac{\\Vert PM \\times v \\Vert}{\\Vert v \\Vert}$.",
                "answer": "True",
                "explanation": "The formula $d = \\frac{\\Vert PM \\times v \\Vert}{\\Vert v \\Vert}$ correctly represents the distance from a point M to a line L. Here, $PM$ is the vector from point P to point M, and $v$ is the direction vector of the line L. The cross product $PM \\times v$ gives a vector perpendicular to both $PM$ and $v$, and its magnitude represents the area of the parallelogram formed by these vectors. Dividing this area by the magnitude of $v$ gives the height of the parallelogram, which is the shortest distance from point M to the line L. For example, if $P = (0,0,0)$, $M = (1,1,1)$, and $v = (1,0,0)$, then $PM = (1,1,1)$ and $PM \\times v = (0,1,-1)$. The magnitude of $PM \\times v$ is $\\sqrt{2}$, and the magnitude of $v$ is 1, so the distance $d = \\frac{\\sqrt{2}}{1} = \\sqrt{2}$."
            },
            {
                "question": "The scalar equation of a plane containing the point $P=(1,2,3)$ with normal vector $n=\\langle 4,5,6 \\rangle$ can be written as $4(x-1) + 5(y-2) + 6(z-3) = 0$.",
                "answer": "True",
                "explanation": "The scalar equation of a plane containing a point $P=(x_0, y_0, z_0)$ with a normal vector $n=\\langle a, b, c \\rangle$ is given by $a(x-x_0) + b(y-y_0) + c(z-z_0) = 0$. Substituting $P=(1,2,3)$ and $n=\\langle 4, 5, 6 \\rangle$, we get $4(x-1) + 5(y-2) + 6(z-3) = 0$. This equation represents the plane passing through the point $(1,2,3)$ with the normal vector $\\langle 4, 5, 6 \\rangle$."
            },
            {
                "question": "The distance from a point P to a plane with normal vector n that passes through point Q is given by the formula $d = \\frac{|\\overrightarrow{QP} \\cdot \\mathbf{n}|}{\\|\\mathbf{n}\\|}$.",
                "answer": "True",
                "explanation": "The distance from a point P to a plane with normal vector n that passes through point Q is indeed given by the formula $d = \\frac{|\\overrightarrow{QP} \\cdot \\mathbf{n}|}{\\|\\mathbf{n}\\|}$. This formula is derived from the projection of the vector $\\overrightarrow{QP}$ onto the normal vector n. The projection gives the component of $\\overrightarrow{QP}$ in the direction of n, and taking the absolute value ensures the distance is non-negative. Dividing by the magnitude of n normalizes the projection to give the perpendicular distance from the point to the plane. For example, if $\\overrightarrow{QP} = (3, 4, 5)$ and $\\mathbf{n} = (1, 0, 0)$, the distance would be $\\frac{|3 \\cdot 1 + 4 \\cdot 0 + 5 \\cdot 0|}{\\sqrt{1^2 + 0^2 + 0^2}} = 3$."
            },
            {
                "question": "The distance from a point $P(x_0, y_0, z_0)$ to the plane $ax + by + cz + k = 0$ is given by $d = \\frac{|ax_0 + by_0 + cz_0 + k|}{\\sqrt{a^2 + b^2 + c^2}}$.",
                "answer": "True",
                "explanation": "The formula for the distance from a point $P(x_0, y_0, z_0)$ to a plane $ax + by + cz + k = 0$ is indeed $d = \\frac{|ax_0 + by_0 + cz_0 + k|}{\\sqrt{a^2 + b^2 + c^2}}$. This formula is derived from the general equation of a plane and the perpendicular distance from a point to a plane. For example, if we have a point $P(1, 2, 3)$ and a plane $2x + 3y + 4z + 5 = 0$, the distance would be $d = \\frac{|2(1) + 3(2) + 4(3) + 5|}{\\sqrt{2^2 + 3^2 + 4^2}} = \\frac{|2 + 6 + 12 + 5|}{\\sqrt{4 + 9 + 16}} = \\frac{25}{\\sqrt{29}}$."
            }
        ],
        "2-4-the-cross-product": [
            {
                "question": "The cross product of two vectors $u = \\langle u_1, u_2, u_3 \\rangle$ and $v = \\langle v_1, v_2, v_3 \\rangle$ is given by $u \\times v = \\langle u_2 v_3 - u_3 v_2, -(u_1 v_3 - u_3 v_1), u_1 v_2 - u_2 v_1 \\rangle$.",
                "answer": "True",
                "explanation": "The cross product of two vectors $u = \\langle u_1, u_2, u_3 \\rangle$ and $v = \\langle v_1, v_2, v_3 \\rangle$ is calculated using the determinant of a matrix formed by the unit vectors $i$, $j$, $k$ and the components of $u$ and $v$. The resulting vector is $u \\times v = (u_2 v_3 - u_3 v_2)i - (u_1 v_3 - u_3 v_1)j + (u_1 v_2 - u_2 v_1)k$, which can be written as $u \\times v = \\langle u_2 v_3 - u_3 v_2, -(u_1 v_3 - u_3 v_1), u_1 v_2 - u_2 v_1 \\rangle$. For example, if $u = \\langle 1, 2, 3 \\rangle$ and $v = \\langle 4, 5, 6 \\rangle$, then $u \\times v = \\langle 2 \\cdot 6 - 3 \\cdot 5, -(1 \\cdot 6 - 3 \\cdot 4), 1 \\cdot 5 - 2 \\cdot 4 \\rangle = \\langle 12 - 15, -(6 - 12), 5 - 8 \\rangle = \\langle -3, 6, -3 \\rangle$."
            },
            {
                "question": "The cross product of a vector with itself is always zero.",
                "answer": "True",
                "explanation": "The cross product of a vector $\\mathbf{v}$ with itself, $\\mathbf{v} \\times \\mathbf{v}$, is always zero. This is because the cross product measures the area of the parallelogram formed by the two vectors, and when the vectors are identical, the parallelogram collapses into a line segment with zero area. For example, if $\\mathbf{v} = \\begin{pmatrix} a \\ b \\ c \\end{pmatrix}$, then $\\mathbf{v} \\times \\mathbf{v} = \\begin{pmatrix} a \\ b \\ c \\end{pmatrix} \\times \\begin{pmatrix} a \\ b \\ c \\end{pmatrix} = \\begin{pmatrix} 0 \\ 0 \\ 0 \\end{pmatrix}$."
            },
            {
                "question": "The magnitude of the cross product of two vectors $u$ and $v$ is given by $\\Vert u \\times v \\Vert = \\Vert u \\Vert \\cdot \\Vert v \\Vert \\cdot \\sin \\theta$, where $\\theta$ is the angle between the vectors.",
                "answer": "True",
                "explanation": "The magnitude of the cross product of two vectors $u$ and $v$ is indeed given by $\\Vert u \\times v \\Vert = \\Vert u \\Vert \\cdot \\Vert v \\Vert \\cdot \\sin \\theta$. This formula captures the geometric interpretation of the cross product, which measures the area of the parallelogram formed by the two vectors. For example, if $u$ and $v$ are perpendicular, $\\theta = 90^\\circ$ and $\\sin \\theta = 1$, so $\\Vert u \\times v \\Vert = \\Vert u \\Vert \\cdot \\Vert v \\Vert$. If $u$ and $v$ are parallel, $\\theta = 0^\\circ$ or $180^\\circ$ and $\\sin \\theta = 0$, so $\\Vert u \\times v \\Vert = 0$."
            },
            {
                "question": "The area of a parallelogram formed by vectors $u$ and $v$ is given by $\\Vert u \\times v \\Vert$.",
                "answer": "True",
                "explanation": "The area of a parallelogram formed by two vectors $u$ and $v$ is calculated using the magnitude of their cross product, denoted as $\\Vert u \\times v \\Vert$. This is because the cross product $u \\times v$ results in a vector whose magnitude represents the area of the parallelogram spanned by $u$ and $v$. For example, if $u = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$ and $v = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$, then $u \\times v = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$ and $\\Vert u \\times v \\Vert = 1$, which is the area of the unit square formed by $u$ and $v$."
            },
            {
                "question": "The triple scalar product of vectors $\\mathbf{u}$, $\\mathbf{v}$, and $\\mathbf{w}$ is given by $\\mathbf{u} \\cdot (\\mathbf{v} \\times \\mathbf{w})$.",
                "answer": "True",
                "explanation": "The triple scalar product of vectors $\\mathbf{u}$, $\\mathbf{v}$, and $\\mathbf{w}$ is indeed defined as $\\mathbf{u} \\cdot (\\mathbf{v} \\times \\mathbf{w})$. This operation results in a scalar value. The cross product $\\mathbf{v} \\times \\mathbf{w}$ produces a vector that is perpendicular to both $\\mathbf{v}$ and $\\mathbf{w}$. The dot product $\\mathbf{u} \\cdot (\\mathbf{v} \\times \\mathbf{w})$ then projects $\\mathbf{u}$ onto this perpendicular vector, resulting in a scalar. For example, if $\\mathbf{u} = (1, 0, 0)$, $\\mathbf{v} = (0, 1, 0)$, and $\\mathbf{w} = (0, 0, 1)$, then $\\mathbf{v} \\times \\mathbf{w} = (1, 0, 0)$ and $\\mathbf{u} \\cdot (\\mathbf{v} \\times \\mathbf{w}) = (1, 0, 0) \\cdot (1, 0, 0) = 1$."
            },
            {
                "question": "The triple scalar product of vectors $\\mathbf{u}$, $\\mathbf{v}$, and $\\mathbf{w}$ is given by the determinant of the $3 \\times 3$ matrix formed by the components of these vectors.",
                "answer": "True",
                "explanation": "The triple scalar product of vectors $\\mathbf{u} = u_1\\mathbf{i} + u_2\\mathbf{j} + u_3\\mathbf{k}$, $\\mathbf{v} = v_1\\mathbf{i} + v_2\\mathbf{j} + v_3\\mathbf{k}$, and $\\mathbf{w} = w_1\\mathbf{i} + w_2\\mathbf{j} + w_3\\mathbf{k}$ is calculated as $\\mathbf{u} \\cdot (\\mathbf{v} \\times \\mathbf{w})$. This is equivalent to the determinant of the $3 \\times 3$ matrix formed by placing the components of $\\mathbf{u}$, $\\mathbf{v}$, and $\\mathbf{w}$ in the rows or columns of the matrix: $\\begin{vmatrix} u_1 & u_2 & u_3 \\\\ v_1 & v_2 & v_3 \\\\ w_1 & w_2 & w_3 \\end{vmatrix}$. For example, if $\\mathbf{u} = \\mathbf{i} + 2\\mathbf{j} + 3\\mathbf{k}$, $\\mathbf{v} = 4\\mathbf{i} + 5\\mathbf{j} + 6\\mathbf{k}$, and $\\mathbf{w} = 7\\mathbf{i} + 8\\mathbf{j} + 9\\mathbf{k}$, the triple scalar product is the determinant of the matrix $\\begin{vmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{vmatrix}$."
            },
            {
                "question": "The volume of a parallelepiped formed by vectors $\\mathbf{u}$, $\\mathbf{v}$, and $\\mathbf{w}$ is given by the absolute value of the dot product of $\\mathbf{u}$ and the cross product of $\\mathbf{v}$ and $\\mathbf{w}$, i.e., $V = |\\mathbf{u} \\cdot (\\mathbf{v} \\times \\mathbf{w})|$.",
                "answer": "True",
                "explanation": "The volume of a parallelepiped is calculated using the triple scalar product of its defining vectors. This involves taking the cross product of two vectors, $\\mathbf{v}$ and $\\mathbf{w}$, which results in a vector perpendicular to the plane formed by $\\mathbf{v}$ and $\\mathbf{w}$. Then, the dot product of this resultant vector with the third vector, $\\mathbf{u}$, gives a scalar value. The absolute value of this scalar is the volume of the parallelepiped. For example, if $\\mathbf{u} = \\begin{pmatrix}1 \\\\ 2 \\\\ 3\\end{pmatrix}$, $\\mathbf{v} = \\begin{pmatrix}4 \\\\ 5 \\\\ 6\\end{pmatrix}$, and $\\mathbf{w} = \\begin{pmatrix}7 \\\\ 8 \\\\ 9\\end{pmatrix}$, then $\\mathbf{v} \\times \\mathbf{w} = \\begin{pmatrix}-3 \\\\ 6 \\\\ -3\\end{pmatrix}$ and $\\mathbf{u} \\cdot (\\mathbf{v} \\times \\mathbf{w}) = 1(-3) + 2(6) + 3(-3) = 0$. Thus, $V = |0| = 0$, indicating the vectors are coplanar and the volume is zero."
            },
            {
                "question": "Torque is the dot product of the position vector $\\mathbf{r}$ and the force vector $\\mathbf{F}$, which measures the tendency of a force to produce rotation about an axis of rotation.",
                "answer": "False",
                "explanation": "Torque, denoted by $\\tau$, measures the tendency of a force to produce rotation about an axis of rotation. It is given by the cross product of the position vector $\\mathbf{r}$ and the force vector $\\mathbf{F}$, not the dot product. The cross product $\\tau = \\mathbf{r} \\times \\mathbf{F}$ results in a vector that is perpendicular to the plane formed by $\\mathbf{r}$ and $\\mathbf{F}$, indicating the direction of the rotational effect. For example, if $\\mathbf{r}$ is a vector from the axis of rotation to the point where the force is applied, and $\\mathbf{F}$ is the force applied, the magnitude of the torque is given by $|\\tau| = |\\mathbf{r}| |\\mathbf{F}| \\sin(\\theta)$, where $\\theta$ is the angle between $\\mathbf{r}$ and $\\mathbf{F}$. This contrasts with the dot product, which measures the projection of one vector onto another and is not used to calculate torque."
            }
        ],
        "2-6-quadric-surfaces": [
            {
                "question": "A cylindrical surface is formed by a set of lines parallel to a given line that intersect a given curve, and these lines are known as rulings.",
                "answer": "False",
                "explanation": "A cylindrical surface, or cylinder, is formed by a set of lines parallel to a given line that pass through a given curve, not intersect it. The parallel lines are called rulings. For example, if we have a curve in the $xy$-plane and lines parallel to the $z$-axis passing through every point on this curve, the resulting surface is a cylindrical surface. The key concept is that the lines (rulings) must pass through the curve, not merely intersect it."
            },
            {
                "question": "The traces of a surface are the cross-sections created when the surface intersects a plane parallel to one of the coordinate planes.",
                "answer": "True",
                "explanation": "The statement is true. Traces of a surface are indeed the cross-sections formed when the surface intersects with planes that are parallel to the coordinate planes (xy-plane, xz-plane, or yz-plane). For example, if we have a surface defined by $z = x^2 + y^2$, the trace in the xy-plane (where $z = 0$) would be the curve $0 = x^2 + y^2$, which is a single point at the origin. Similarly, the trace in the xz-plane (where $y = 0$) would be $z = x^2$, a parabola. These intersections help in visualizing and understanding the shape and properties of the surface."
            },
            {
                "question": "The equation $x^2 + y^2 + z^2 - 1 = 0$ represents a quadric surface.",
                "answer": "True",
                "explanation": "The given equation $x^2 + y^2 + z^2 - 1 = 0$ can be expressed in the form $Ax^2 + By^2 + Cz^2 + Dxy + Exz + Fyz + Gx + Hy + Jz + K = 0$ where $A=1$, $B=1$, $C=1$, $D=0$, $E=0$, $F=0$, $G=0$, $H=0$, $J=0$, and $K=-1$. This matches the general form of a quadric surface equation, confirming that it is indeed a quadric surface. An example of a quadric surface is a sphere, which is represented by the equation $x^2 + y^2 + z^2 = r^2$. In this case, $r^2 = 1$, making it a unit sphere."
            }
        ],
        "2-3-the-dot-product": [
            {
                "question": "The dot product of vectors $u = \\langle 1, 2, 3 \\rangle$ and $v = \\langle 4, 5, 6 \\rangle$ is $32$.",
                "answer": "False",
                "explanation": "The dot product of vectors $u = \\langle 1, 2, 3 \\rangle$ and $v = \\langle 4, 5, 6 \\rangle$ is calculated as $u \\cdot v = 1 \\cdot 4 + 2 \\cdot 5 + 3 \\cdot 6 = 4 + 10 + 18 = 32$. Therefore, the correct dot product is $32$, making the statement 'True'."
            },
            {
                "question": "The dot product of a vector with itself equals the square of its magnitude.",
                "answer": "True",
                "explanation": "The property of the dot product states that for any vector $v$, the dot product $v \\cdot v$ equals the square of its magnitude, i.e., $v \\cdot v = \\|v\\|^2$. For example, if $v = [3, 4]$, then $v \\cdot v = 3^2 + 4^2 = 9 + 16 = 25$, and $\\|v\\| = \\sqrt{3^2 + 4^2} = \\sqrt{25} = 5$. Thus, $\\|v\\|^2 = 5^2 = 25$, confirming the property."
            },
            {
                "question": "The dot product of two vectors $u$ and $v$ is equal to the product of their magnitudes and the cosine of the angle between them.",
                "answer": "True",
                "explanation": "The dot product of two vectors $u$ and $v$ is defined as $u \\cdot v = \\|u\\| \\|v\\| \\cos \\theta$, where $\\|u\\|$ and $\\|v\\|$ are the magnitudes of the vectors $u$ and $v$, respectively, and $\\theta$ is the angle between them. For example, if $u$ and $v$ are perpendicular, $\\cos \\theta = 0$, making the dot product zero. If $u$ and $v$ are parallel and in the same direction, $\\cos \\theta = 1$, making the dot product equal to the product of their magnitudes."
            },
            {
                "question": "If the dot product of two nonzero vectors $u$ and $v$ is zero, then $u$ and $v$ are orthogonal.",
                "answer": "True",
                "explanation": "Two nonzero vectors $u$ and $v$ are considered orthogonal if their dot product is zero, i.e., $u \\cdot v = 0$. The dot product of two vectors is calculated as $u \\cdot v = u_1v_1 + u_2v_2 + \\ldots + u_nv_n$. If this sum equals zero, it indicates that the vectors are perpendicular to each other in the vector space. For example, in 2D space, the vectors $u = (1, 0)$ and $v = (0, 1)$ are orthogonal because their dot product $1 \\cdot 0 + 0 \\cdot 1 = 0$."
            },
            {
                "question": "The direction cosines of a nonzero vector are the cosines of the angles formed between the vector and the coordinate axes.",
                "answer": "True",
                "explanation": "The direction angles of a nonzero vector are the angles formed between the vector and the coordinate axes. The cosines of these angles are known as the direction cosines. For example, if a vector $\\mathbf{v}$ forms angles $\\alpha$, $\\beta$, and $\\gamma$ with the x, y, and z axes respectively, then the direction cosines are $\\cos(\\alpha)$, $\\cos(\\beta)$, and $\\cos(\\gamma)$. These cosines help in understanding the orientation of the vector in the coordinate system."
            },
            {
                "question": "The vector projection of $v$ onto $u$ is given by $\\text{proj}_u v = \\frac{u \\cdot v}{\\|u\\|^2} u$, and its length is $\\|v\\| \\cos \\theta$ where $\\theta$ is the angle between $u$ and $v$.",
                "answer": "True",
                "explanation": "The vector projection of $v$ onto $u$ is indeed given by $\\text{proj}_u v = \\frac{u \\cdot v}{\\|u\\|^2} u$. This formula projects $v$ onto the direction of $u$ and scales it appropriately. The length of this projection, also known as the scalar projection, is $\\|v\\| \\cos \\theta$, where $\\theta$ is the angle between $u$ and $v$. This is derived from the dot product definition, where $u \\cdot v = \\|u\\| \\|v\\| \\cos \\theta$. For example, if $u = [1, 0]$ and $v = [1, 1]$, the projection of $v$ onto $u$ is $\\text{proj}_u v = \\frac{1 \\cdot 1 + 0 \\cdot 1}{1^2} [1, 0] = [1, 0]$, and its length is $\\|v\\| \\cos \\theta = \\sqrt{2} \\cdot \\frac{1}{\\sqrt{2}} = 1$."
            },
            {
                "question": "The work done by a constant force $F$ acting at an angle $\\theta$ to the direction of motion of an object moving in a straight line from point $P$ to point $Q$ is given by $W = \\|F\\| \\|PQ\\| \\cos \\theta$.",
                "answer": "True",
                "explanation": "The work $W$ done by a force $F$ when an object moves from point $P$ to point $Q$ is calculated using the formula $W = F \\cdot PQ \\rightarrow = \\|F\\| \\|PQ\\| \\cos \\theta$. Here, $\\|F\\|$ is the magnitude of the force, $\\|PQ\\|$ is the distance between points $P$ and $Q$, and $\\theta$ is the angle between the force vector and the direction of motion. For example, if a force of 10 N is applied at an angle of 30 degrees to the direction of motion over a distance of 5 meters, the work done is $10 \\times 5 \\times \\cos 30^\\circ = 10 \\times 5 \\times \\frac{\\sqrt{3}}{2} = 25\\sqrt{3}$ Joules."
            }
        ],
        "2-2-vectors-in-three-dimensions": [
            {
                "question": "In a three-dimensional rectangular coordinate system, the origin is the point where the x-axis, y-axis, and z-axis intersect, and each axis represents all real numbers in $\\mathbb{R}$.",
                "answer": "True",
                "explanation": "The three-dimensional rectangular coordinate system is defined by three perpendicular axes: the x-axis, the y-axis, and the z-axis. These axes intersect at a common point called the origin, which is denoted as (0, 0, 0). Each axis is a number line that represents all real numbers in $\\mathbb{R}$. Therefore, the entire three-dimensional space is often denoted by $\\mathbb{R}^3$. For example, any point in this space can be represented by coordinates (x, y, z) where x, y, and z are real numbers."
            },
            {
                "question": "The distance $d$ between two points $(x_1, y_1, z_1)$ and $(x_2, y_2, z_2)$ in 3-dimensional space is given by the formula $d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}$.",
                "answer": "True",
                "explanation": "The formula for the distance between two points in 3-dimensional space is derived from the Pythagorean theorem. For points $(x_1, y_1, z_1)$ and $(x_2, y_2, z_2)$, the distance $d$ is calculated as $d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}$. This formula accounts for the differences in each coordinate direction (x, y, and z) and combines them to find the straight-line distance between the points. For example, if $(x_1, y_1, z_1) = (1, 2, 3)$ and $(x_2, y_2, z_2) = (4, 6, 8)$, then $d = \\sqrt{(4 - 1)^2 + (6 - 2)^2 + (8 - 3)^2} = \\sqrt{3^2 + 4^2 + 5^2} = \\sqrt{9 + 16 + 25} = \\sqrt{50} = 5\\sqrt{2}$."
            },
            {
                "question": "In a sphere, the distance from the center to any point on the surface is always the same, similar to how the distance from the center to any point on the circumference of a circle is always the same.",
                "answer": "True",
                "explanation": "A sphere is defined as the set of all points in space that are equidistant from a fixed point, known as the center. This distance is called the radius. Similarly, a circle is the set of all points in a plane that are equidistant from its center, and this distance is also called the radius. For example, if the radius of a sphere is 5 units, then every point on the surface of the sphere is exactly 5 units away from the center. The same concept applies to a circle in a plane."
            }
        ],
        "2-1-vectors-in-the-plane": [
            {
                "question": "A vector is a quantity that only has magnitude.",
                "answer": "False",
                "explanation": "A vector is defined as a quantity that has both magnitude and direction. For example, velocity is a vector because it describes both how fast an object is moving (magnitude) and in which direction it is moving. In contrast, speed is a scalar quantity because it only has magnitude and no direction."
            },
            {
                "question": "Two vectors are considered equivalent if they have the same magnitude but different directions.",
                "answer": "False",
                "explanation": "Vectors are considered equivalent if and only if they have both the same magnitude and the same direction. Magnitude refers to the length or size of the vector, while direction refers to the orientation of the vector in space. For example, the vectors $\\vec{A} = 3\\hat{i} + 4\\hat{j}$ and $\\vec{B} = 3\\hat{i} + 4\\hat{j}$ are equivalent because they have the same magnitude $\\sqrt{3^2 + 4^2} = 5$ and the same direction. However, the vectors $\\vec{C} = 3\\hat{i} + 4\\hat{j}$ and $\\vec{D} = -3\\hat{i} - 4\\hat{j}$ are not equivalent because, despite having the same magnitude, their directions are opposite."
            },
            {
                "question": "If a vector $v$ is multiplied by a scalar $k$, the resulting vector will always have a magnitude that is $|k|$ times the magnitude of $v$ and will point in the same direction as $v$ if $k > 0$, or in the opposite direction if $k < 0$.",
                "answer": "True",
                "explanation": "Scalar multiplication involves multiplying a vector $v$ by a scalar $k$. The resulting vector $kv$ has a magnitude of $|k|$ times the magnitude of $v$. If $k > 0$, the direction of $kv$ is the same as $v$, and if $k < 0$, the direction of $kv$ is opposite to $v$. For example, if $v$ is a vector with a magnitude of 3 units and $k = 2$, then $kv$ will have a magnitude of $2 \\times 3 = 6$ units and will point in the same direction as $v$. If $k = -2$, then $kv$ will still have a magnitude of 6 units but will point in the opposite direction of $v$. If $k = 0$ or $v = 0$, then $kv = 0$."
            },
            {
                "question": "To graphically add two vectors $\\mathbf{v}$ and $\\mathbf{w}$, you place the initial point of $\\mathbf{w}$ at the terminal point of $\\mathbf{v}$, and the resulting vector $\\mathbf{v} + \\mathbf{w}$ starts at the initial point of $\\mathbf{v}$ and ends at the terminal point of $\\mathbf{w}$. This process is called vector addition.",
                "answer": "True",
                "explanation": "The process described is indeed vector addition. When adding two vectors $\\mathbf{v}$ and $\\mathbf{w}$ graphically, you place the initial point of $\\mathbf{w}$ at the terminal point of $\\mathbf{v}$. The resultant vector $\\mathbf{v} + \\mathbf{w}$ starts at the initial point of $\\mathbf{v}$ and ends at the terminal point of $\\mathbf{w}$. For example, if $\\mathbf{v}$ represents a displacement of 3 units to the right and $\\mathbf{w}$ represents a displacement of 4 units up, placing the initial point of $\\mathbf{w}$ at the terminal point of $\\mathbf{v}$ will result in a vector that starts at the origin (initial point of $\\mathbf{v}$) and ends at the point (3, 4), which is the terminal point of $\\mathbf{w}$. This resultant vector represents the combined effect of both displacements."
            },
            {
                "question": "The vector with initial point (0,0) and terminal point (3,4) can be written in component form as $\\mathbf{v} = \\langle 3, 4 \\rangle$.",
                "answer": "True",
                "explanation": "The vector with initial point $(0,0)$ and terminal point $(x,y)$ can be written in component form as $\\mathbf{v} = \\langle x, y \\rangle$. Here, the initial point is $(0,0)$ and the terminal point is $(3,4)$, so the vector can be written as $\\mathbf{v} = \\langle 3, 4 \\rangle$. The components of the vector are the scalars $3$ and $4$. For example, if the terminal point were $(5,7)$, the vector would be $\\mathbf{v} = \\langle 5, 7 \\rangle$."
            },
            {
                "question": "Given vectors $v = \\langle x_1, y_1 \\rangle$ and $w = \\langle x_2, y_2 \\rangle$, and a scalar $k$, the result of the operation $k(v + w)$ is equal to $k \\langle x_1 + x_2, y_1 + y_2 \\rangle$.",
                "answer": "True",
                "explanation": "The operation $v + w$ results in the vector $\\langle x_1 + x_2, y_1 + y_2 \\rangle$. When we multiply this vector by the scalar $k$, we apply the scalar multiplication to each component of the vector. Therefore, $k(v + w) = k \\langle x_1 + x_2, y_1 + y_2 \\rangle = \\langle k(x_1 + x_2), k(y_1 + y_2) \\rangle$. This matches the definition of scalar multiplication and vector addition."
            },
            {
                "question": "The property $r(u+v) = ru + rv$ is an example of the commutative property of vector addition.",
                "answer": "False",
                "explanation": "The property $r(u+v) = ru + rv$ is an example of the distributive property of scalar multiplication over vector addition, not the commutative property of vector addition. The commutative property of vector addition states that $u + v = v + u$. For example, if $u = (1, 2)$ and $v = (3, 4)$, then $u + v = (1+3, 2+4) = (4, 6)$ and $v + u = (3+1, 4+2) = (4, 6)$, demonstrating that $u + v = v + u$. On the other hand, the distributive property can be illustrated by taking a scalar $r = 2$ and vectors $u = (1, 2)$ and $v = (3, 4)$, then $r(u+v) = 2(4, 6) = (8, 12)$ and $ru + rv = 2(1, 2) + 2(3, 4) = (2, 4) + (6, 8) = (8, 12)$, showing that $r(u+v) = ru + rv$."
            }
        ]
    },
    "Second-Order Differential Equations": {
        "7-2-nonhomogeneous-linear-equations": [
            {
                "question": "A particular solution to a differential equation is a solution that includes arbitrary constants.",
                "answer": "False",
                "explanation": "A particular solution to a differential equation is defined as a solution that contains no arbitrary constants. In contrast, a general solution includes arbitrary constants that can be adjusted to fit specific initial conditions or boundary values. For example, for the differential equation $y'' + y = 0$, the general solution is $y(x) = C_1 \\cos(x) + C_2 \\sin(x)$, where $C_1$ and $C_2$ are arbitrary constants. A particular solution might be $y(x) = \\cos(x)$, which does not include any arbitrary constants."
            },
            {
                "question": "The general solution to a nonhomogeneous linear differential equation $a_2(x)y'' + a_1(x)y' + a_0(x)y = r(x)$ is given by $y(x) = c_1 y_1(x) + c_2 y_2(x) + y_p(x)$, where $y_p(x)$ is any particular solution to the nonhomogeneous equation and $c_1 y_1(x) + c_2 y_2(x)$ is the general solution to the complementary homogeneous equation.",
                "answer": "True",
                "explanation": "The general solution to a nonhomogeneous linear differential equation $a_2(x)y'' + a_1(x)y' + a_0(x)y = r(x)$ indeed consists of two parts: the general solution to the corresponding homogeneous equation $a_2(x)y'' + a_1(x)y' + a_0(x)y = 0$, which is $c_1 y_1(x) + c_2 y_2(x)$, and any particular solution $y_p(x)$ to the nonhomogeneous equation. Therefore, the general solution to the nonhomogeneous equation is $y(x) = c_1 y_1(x) + c_2 y_2(x) + y_p(x)$. For example, if $y_1(x)$ and $y_2(x)$ are solutions to the homogeneous equation and $y_p(x)$ is a particular solution to the nonhomogeneous equation, then combining these gives the complete solution to the original nonhomogeneous problem."
            }
        ],
        "7-1-second-order-linear-equations": [
            {
                "question": "The differential equation $3y'' + 2y' - y = 0$ is a homogeneous linear second-order differential equation.",
                "answer": "True",
                "explanation": "The given differential equation $3y'' + 2y' - y = 0$ can be written in the form $a_2(x)y'' + a_1(x)y' + a_0(x)y = r(x)$ where $a_2(x) = 3$, $a_1(x) = 2$, $a_0(x) = -1$, and $r(x) = 0$. Since $a_2(x)$ is not identically zero and $r(x) = 0$ for every value of $x$, the equation is a homogeneous linear second-order differential equation. A homogeneous linear equation has $r(x) \\equiv 0$, which is true in this case."
            },
            {
                "question": "If $y_1(x)$ and $y_2(x)$ are solutions to a linear homogeneous differential equation, then the function $y(x) = c_1 y_1(x) + c_2 y_2(x)$, where $c_1$ and $c_2$ are constants, is also a solution.",
                "answer": "True",
                "explanation": "The Superposition Principle states that if $y_1(x)$ and $y_2(x)$ are solutions to a linear homogeneous differential equation, then any linear combination of these solutions, $y(x) = c_1 y_1(x) + c_2 y_2(x)$, is also a solution. This is because linear homogeneous differential equations have the property that the sum of any two solutions is also a solution. For example, if $y_1(x) = e^x$ and $y_2(x) = e^{-x}$ are solutions to a differential equation, then $y(x) = c_1 e^x + c_2 e^{-x}$ will also be a solution for any constants $c_1$ and $c_2$."
            },
            {
                "question": "The set of functions $f_1(x) = x$, $f_2(x) = x^2$, and $f_3(x) = x^3$ is linearly dependent.",
                "answer": "False",
                "explanation": "A set of functions is linearly dependent if there exist constants $c_1, c_2, \\ldots, c_n$, not all zero, such that $c_1 f_1(x) + c_2 f_2(x) + \\cdots + c_n f_n(x) = 0$ for all $x$ over the interval of interest. For the functions $f_1(x) = x$, $f_2(x) = x^2$, and $f_3(x) = x^3$, we need to check if there are constants $c_1, c_2, c_3$ (not all zero) such that $c_1 x + c_2 x^2 + c_3 x^3 = 0$ for all $x$. This equation implies that the polynomial $c_1 x + c_2 x^2 + c_3 x^3$ must be identically zero. However, the only solution to this equation is $c_1 = c_2 = c_3 = 0$, which means the functions are linearly independent. Therefore, the statement is false."
            },
            {
                "question": "The functions $f_1(x) = 3x$ and $f_2(x) = x$ are linearly dependent.",
                "answer": "True",
                "explanation": "The functions $f_1(x) = 3x$ and $f_2(x) = x$ are linearly dependent because $f_1(x)$ can be expressed as a constant multiple of $f_2(x)$. Specifically, $f_1(x) = 3 \\cdot f_2(x)$, where the constant $C = 3$. This satisfies the condition for linear dependence, which states that two functions $f_1(x)$ and $f_2(x)$ are linearly dependent if $f_1(x) = C \\cdot f_2(x)$ for some constant $C$ and for all $x$ over the interval of interest."
            },
            {
                "question": "If $y_1(x)$ and $y_2(x)$ are linearly independent solutions to a second-order, linear, homogeneous differential equation, then any solution to this differential equation can be expressed as $y(x) = c_1 y_1(x) + c_2 y_2(x)$, where $c_1$ and $c_2$ are constants.",
                "answer": "True",
                "explanation": "In the context of second-order, linear, homogeneous differential equations, the general solution is formed by a linear combination of two linearly independent solutions. This is because the solution space of such differential equations is a two-dimensional vector space. Therefore, any solution can be written as $y(x) = c_1 y_1(x) + c_2 y_2(x)$, where $c_1$ and $c_2$ are constants. For example, if $y_1(x) = e^x$ and $y_2(x) = e^{-x}$ are solutions, then $y(x) = c_1 e^x + c_2 e^{-x}$ represents the general solution."
            },
            {
                "question": "The characteristic equation of the differential equation $ay'' + by' + cy = 0$ is $a\\lambda^2 + b\\lambda + c = 0$.",
                "answer": "True",
                "explanation": "The characteristic equation is derived from the differential equation $ay'' + by' + cy = 0$ by assuming a solution of the form $y = e^{\\lambda t}$. Substituting $y = e^{\\lambda t}$ into the differential equation, we get $a(\\lambda^2 e^{\\lambda t}) + b(\\lambda e^{\\lambda t}) + c(e^{\\lambda t}) = 0$. Factoring out $e^{\\lambda t}$, which is never zero, we obtain $a\\lambda^2 + b\\lambda + c = 0$. This is the characteristic equation. For example, if $a = 1$, $b = 3$, and $c = 2$, the characteristic equation would be $\\lambda^2 + 3\\lambda + 2 = 0$."
            }
        ],
        "7-3-applications": [
            {
                "question": "The function $x(t) = c_1 \\cos(\\omega t) + c_2 \\sin(\\omega t)$ can be expressed in the form $x(t) = A \\sin(\\omega t + \\phi)$, where $A = \\sqrt{c_1^2 + c_2^2}$ and $\\tan(\\phi) = \\frac{c_2}{c_1}$.",
                "answer": "True",
                "explanation": "The given function $x(t) = c_1 \\cos(\\omega t) + c_2 \\sin(\\omega t)$ represents a solution to the simple harmonic motion equation. It can be rewritten in the form $x(t) = A \\sin(\\omega t + \\phi)$ by using trigonometric identities. Here, $A$ is the amplitude and is given by $A = \\sqrt{c_1^2 + c_2^2}$, which is derived from the Pythagorean theorem. The phase angle $\\phi$ is determined by the ratio of the coefficients of the sine and cosine terms, such that $\\tan(\\phi) = \\frac{c_2}{c_1}$. For example, if $c_1 = 3$ and $c_2 = 4$, then $A = \\sqrt{3^2 + 4^2} = 5$ and $\\tan(\\phi) = \\frac{4}{3}$."
            }
        ]
    },
    "Vector Calculus": {
        "6-8-the-divergence-theorem": [
            {
                "question": "The Divergence Theorem states that the flux of a vector field F through a closed surface S is equal to the volume integral of the divergence of F over the region E enclosed by S, provided that F has continuous partial derivatives and S is oriented outward.",
                "answer": "True",
                "explanation": "The Divergence Theorem, also known as Gauss's Theorem, relates the flux of a vector field $\\mathbf{F}$ through a closed surface $S$ to the volume integral of the divergence of $\\mathbf{F}$ over the region $E$ enclosed by $S$. Mathematically, it is expressed as $\\iiint_E \\text{div} \\mathbf{F} \\, dV = \\iint_S \\mathbf{F} \\cdot d\\mathbf{S}$. Here, $\\text{div} \\mathbf{F}$ represents the divergence of the vector field $\\mathbf{F}$, and $d\\mathbf{S}$ is the outward-pointing surface element. For example, if $\\mathbf{F}$ represents the velocity field of a fluid, the theorem states that the net rate of fluid outflow through the surface $S$ is equal to the total divergence of the fluid's velocity within the volume $E$. This theorem requires that $\\mathbf{F}$ has continuous partial derivatives and that $S$ is a piecewise smooth, closed surface oriented outward."
            },
            {
                "question": "The flux of the vector field $\\mathbf{F} = \\frac{1}{r^2} \\langle x, y, z \\rangle$ across a connected, piecewise smooth closed surface $S$ is $4\\pi$ if and only if $S$ encompasses the origin.",
                "answer": "True",
                "explanation": "The flux of the vector field $\\mathbf{F} = \\frac{1}{r^2} \\langle x, y, z \\rangle$ across a closed surface $S$ depends on whether $S$ encompasses the origin. If $S$ does not encompass the origin, the flux is $0$. If $S$ does encompass the origin, the flux is $4\\pi$. This result is derived from the divergence theorem and the fact that the divergence of $\\mathbf{F}$ is zero everywhere except at the origin, where it has a singularity. For example, if $S$ is a sphere centered at the origin, the flux through $S$ is $4\\pi$. If $S$ is a sphere not centered at the origin, the flux through $S$ is $0$."
            }
        ],
        "6-1-vector-fields": [
            {
                "question": "A vector field $F$ in $\\mathbb{R}^2$ assigns a three-dimensional vector $F(x,y,z)$ to each point $(x,y)$ of a subset $D$ of $\\mathbb{R}^2$.",
                "answer": "False",
                "explanation": "A vector field $F$ in $\\mathbb{R}^2$ assigns a two-dimensional vector $F(x,y)$ to each point $(x,y)$ of a subset $D$ of $\\mathbb{R}^2$. For example, if $D$ is a subset of $\\mathbb{R}^2$, then $F(x,y)$ could be something like $(2x, 3y)$. In contrast, a vector field in $\\mathbb{R}^3$ assigns a three-dimensional vector $F(x,y,z)$ to each point $(x,y,z)$ of a subset $D$ of $\\mathbb{R}^3$. For instance, $F(x,y,z)$ could be $(x^2, y^2, z^2)$. Therefore, the statement is false because it incorrectly describes the dimensionality of the vectors assigned in $\\mathbb{R}^2$."
            },
            {
                "question": "A vector field $F$ in $\\mathbb{R}^2$ or $\\mathbb{R}^3$ is a gradient field if and only if there exists a scalar function $f$ such that $\\nabla f = F$.",
                "answer": "True",
                "explanation": "A vector field $F$ is called a gradient field if it can be expressed as the gradient of some scalar function $f$. This means that for $F$ to be a gradient field, there must exist a scalar function $f$ such that $\\nabla f = F$. For example, in $\\mathbb{R}^2$, if $F = (2x, 2y)$, then $f = x^2 + y^2$ is a scalar function whose gradient $\\nabla f = (2x, 2y) = F$. Similarly, in $\\mathbb{R}^3$, if $F = (yz, xz, xy)$, then $f = xyz$ is a scalar function whose gradient $\\nabla f = (yz, xz, xy) = F$. Therefore, the statement is true."
            },
            {
                "question": "If $F$ is a conservative vector field on an open and connected domain, and $f$ and $g$ are potential functions such that $\\nabla f = F$ and $\\nabla g = F$, then $f$ and $g$ differ by a constant.",
                "answer": "True",
                "explanation": "In a conservative vector field $F$, the potential functions $f$ and $g$ are related by a constant because the gradient of a function is unique up to an additive constant. This means that if $\\nabla f = F$ and $\\nabla g = F$, then $f$ and $g$ must satisfy $f = g + C$ for some constant $C$. For example, if $F = \\nabla f = \\nabla g$, then integrating $F$ along any path in the domain will yield $f$ and $g$ differing only by a constant, ensuring the uniqueness of the potential function up to an additive constant."
            },
            {
                "question": "If a vector field $F(x,y,z)=\\langle P(x,y,z), Q(x,y,z), R(x,y,z) \\rangle$ in $\\mathbb{R}^3$ is conservative, then the following conditions must hold: $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$, $\\frac{\\partial Q}{\\partial z} = \\frac{\\partial R}{\\partial y}$, and $\\frac{\\partial R}{\\partial x} = \\frac{\\partial P}{\\partial z}$.",
                "answer": "True",
                "explanation": "A vector field $F$ is conservative if it can be expressed as the gradient of some scalar potential function. For $F(x,y,z)=\\langle P(x,y,z), Q(x,y,z), R(x,y,z) \\rangle$ in $\\mathbb{R}^3$, the cross-partial property states that the mixed partial derivatives must be equal. Specifically, $\\frac{\\partial P}{\\partial y} = \\frac{\\partial Q}{\\partial x}$, $\\frac{\\partial Q}{\\partial z} = \\frac{\\partial R}{\\partial y}$, and $\\frac{\\partial R}{\\partial x} = \\frac{\\partial P}{\\partial z}$. This ensures that the curl of $F$ is zero, a necessary condition for $F$ to be conservative. For example, if $P(x,y,z) = x^2 + yz$, $Q(x,y,z) = y^2 + xz$, and $R(x,y,z) = z^2 + xy$, then $\\frac{\\partial P}{\\partial y} = z$, $\\frac{\\partial Q}{\\partial x} = z$, $\\frac{\\partial Q}{\\partial z} = x$, $\\frac{\\partial R}{\\partial y} = x$, $\\frac{\\partial R}{\\partial x} = y$, and $\\frac{\\partial P}{\\partial z} = y$, satisfying the cross-partial conditions."
            }
        ],
        "6-6-surface-integrals": [
            {
                "question": "The parameter domain of the parameterization $r(u,v)=\\langle x(u,v), y(u,v), z(u,v) \\rangle$ is the set of points in the $uv$-plane that can be substituted into $r$ to generate points on the surface.",
                "answer": "True",
                "explanation": "The parameter domain of a parameterization $r(u,v)=\\langle x(u,v), y(u,v), z(u,v) \\rangle$ is indeed the set of points $(u,v)$ in the $uv$-plane that can be substituted into the parameterization function $r$ to generate corresponding points on the surface. For example, if $r(u,v)$ describes a surface like a sphere, the domain might be restricted to certain ranges of $u$ and $v$ to ensure valid points on the sphere. Thus, the parameter domain is crucial for defining the valid input values that map to the surface."
            },
            {
                "question": "A parameterization $r(u,v)=\\langle x(u,v), y(u,v), z(u,v) \\rangle$ is considered regular if the cross product $r_u \\times r_v$ is non-zero for all points $(u,v)$ in the parameter domain.",
                "answer": "True",
                "explanation": "A parameterization $r(u,v)=\\langle x(u,v), y(u,v), z(u,v) \\rangle$ is regular if the vectors $r_u$ and $r_v$ are linearly independent at every point $(u,v)$ in the parameter domain. This linear independence is ensured if their cross product $r_u \\times r_v$ is non-zero. For example, consider the parameterization of a surface like a sphere. If $r_u \\times r_v = 0$ at any point, it would imply that the tangent vectors $r_u$ and $r_v$ are parallel, which would mean the surface is not well-defined at that point. Therefore, for a parameterization to be regular, $r_u \\times r_v$ must be non-zero for all $(u,v)$ in the domain."
            },
            {
                "question": "A surface parameterization $r(u,v)=\\langle x(u,v), y(u,v), z(u,v) \\rangle$ is considered smooth if the cross product of the partial derivatives $r_u \\times r_v$ is non-zero for any choice of $u$ and $v$ in the parameter domain.",
                "answer": "True",
                "explanation": "A surface parameterization $r(u,v)=\\langle x(u,v), y(u,v), z(u,v) \\rangle$ is smooth if the vectors $r_u = \\frac{\\partial r}{\\partial u}$ and $r_v = \\frac{\\partial r}{\\partial v}$ are linearly independent at every point in the parameter domain. This linear independence is ensured if their cross product $r_u \\times r_v$ is non-zero for any choice of $u$ and $v$. For example, consider the parameterization of a sphere $r(u,v) = \\langle \\sin u \\cos v, \\sin u \\sin v, \\cos u \\rangle$. The partial derivatives $r_u$ and $r_v$ are $\\langle \\cos u \\cos v, \\cos u \\sin v, -\\sin u \\rangle$ and $\\langle -\\sin u \\sin v, \\sin u \\cos v, 0 \\rangle$, respectively. Their cross product is $\\langle \\sin^2 u \\cos v, \\sin^2 u \\sin v, \\sin u \\cos u \\rangle$, which is non-zero for any $u$ and $v$ in the domain, confirming the smoothness of the parameterization."
            },
            {
                "question": "The surface area of a smooth parameterized surface $S$ given by $r(u,v)=\\langle x(u,v), y(u,v), z(u,v) \\rangle$ over a domain $D$ is calculated using the double integral $\\iint_D \\Vert t_u \\times t_v \\Vert dA$, where $t_u = \\langle \\frac{\\partial x}{\\partial u}, \\frac{\\partial y}{\\partial u}, \\frac{\\partial z}{\\partial u} \\rangle$ and $t_v = \\langle \\frac{\\partial x}{\\partial v}, \\frac{\\partial y}{\\partial v}, \\frac{\\partial z}{\\partial v} \\rangle$.",
                "answer": "True",
                "explanation": "The surface area of a smooth parameterized surface $S$ is indeed calculated using the double integral $\\iint_D \\Vert t_u \\times t_v \\Vert dA$. Here, $t_u$ and $t_v$ are the tangent vectors to the surface in the directions of the parameters $u$ and $v$, respectively. The cross product $t_u \\times t_v$ gives a vector normal to the surface, and its magnitude $\\Vert t_u \\times t_v \\Vert$ represents the area of the parallelogram spanned by $t_u$ and $t_v$. Integrating this magnitude over the domain $D$ gives the total surface area. For example, if $r(u,v)$ parameterizes a sphere, $t_u$ and $t_v$ would be tangent vectors at each point on the sphere, and their cross product would give the normal vector whose magnitude corresponds to the infinitesimal surface area element."
            },
            {
                "question": "The surface integral of a scalar-valued function $f$ over a piecewise smooth surface $S$ can be approximated by summing the values of $f$ at specific points on $S$ multiplied by the area of small surface elements, and taking the limit as the number of these elements approaches infinity.",
                "answer": "True",
                "explanation": "The surface integral of a scalar-valued function $f$ over a piecewise smooth surface $S$ is defined as $\\iint_S f(x,y,z) \\, dS = \\lim_{m,n \\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f(P_{ij}) \\Delta S_{ij}$. This means that to compute the surface integral, we can approximate it by dividing the surface $S$ into small elements $\\Delta S_{ij}$, evaluating the function $f$ at points $P_{ij}$ within these elements, summing these products, and then taking the limit as the number of elements $m$ and $n$ approaches infinity. For example, if $S$ is a sphere and $f$ is a temperature distribution, this process would involve summing the temperature values at various points on the sphere's surface, weighted by the area of the small surface patches, and refining this approximation by increasing the number of patches."
            },
            {
                "question": "The surface integral of a continuous vector field $F$ over an oriented surface $S$ with unit normal vector $N$ can be expressed as $\\iint_S F \\cdot dS = \\iint_S F \\cdot N dS$.",
                "answer": "True",
                "explanation": "The surface integral of a vector field $F$ over a surface $S$ is defined as the integral of the dot product of $F$ with the differential surface element $dS$. When the surface $S$ is oriented with a unit normal vector $N$, the differential surface element $dS$ can be expressed as $N dS$. Therefore, the surface integral $\\iint_S F \\cdot dS$ is equivalent to $\\iint_S F \\cdot N dS$. For example, if $F$ represents the flow of a fluid across a surface $S$, the integral $\\iint_S F \\cdot N dS$ measures the net flow through the surface, taking into account the orientation given by $N$."
            }
        ],
        "6-7-stokes-theorem": [
            {
                "question": "Stokes' Theorem states that for a piecewise smooth oriented surface S with a boundary that is a simple closed curve C, and a vector field F with continuous partial derivatives on an open region containing S, the line integral of F over C is equal to the surface integral of the curl of F over S.",
                "answer": "True",
                "explanation": "Stokes' Theorem connects the circulation of a vector field around a closed curve to the flux of its curl through the surface bounded by the curve. Mathematically, it is expressed as $\\int_C \\mathbf{F} \\cdot d\\mathbf{r} = \\iint_S (\\nabla \\times \\mathbf{F}) \\cdot d\\mathbf{S}$. Here, $\\mathbf{F}$ is the vector field, $C$ is the boundary curve of the surface $S$, and $\\nabla \\times \\mathbf{F}$ represents the curl of $\\mathbf{F}$. For example, if $\\mathbf{F}$ represents the velocity field of a fluid, the theorem relates the circulation of the fluid around the boundary to the rotation (or curl) of the fluid within the surface."
            }
        ],
        "6-5-divergence-and-curl": [
            {
                "question": "The divergence of a vector field $F = \\langle P, Q, R \\rangle$ in $\\mathbb{R}^3$ is given by $div F = \\frac{\\partial P}{\\partial x} + \\frac{\\partial Q}{\\partial y} + \\frac{\\partial R}{\\partial z}$, provided that the partial derivatives $\\frac{\\partial P}{\\partial x}$, $\\frac{\\partial Q}{\\partial y}$, and $\\frac{\\partial R}{\\partial z}$ all exist.",
                "answer": "True",
                "explanation": "The divergence of a vector field $F = \\langle P, Q, R \\rangle$ in $\\mathbb{R}^3$ is a scalar field that measures the rate at which the vector field spreads out from a point. It is defined as $div F = \\frac{\\partial P}{\\partial x} + \\frac{\\partial Q}{\\partial y} + \\frac{\\partial R}{\\partial z}$. This definition requires that the partial derivatives $\\frac{\\partial P}{\\partial x}$, $\\frac{\\partial Q}{\\partial y}$, and $\\frac{\\partial R}{\\partial z}$ exist. For example, if $F = \\langle x^2, y^2, z^2 \\rangle$, then $div F = \\frac{\\partial (x^2)}{\\partial x} + \\frac{\\partial (y^2)}{\\partial y} + \\frac{\\partial (z^2)}{\\partial z} = 2x + 2y + 2z$."
            },
            {
                "question": "If $\\mathbf{F} = \\langle P, Q \\rangle$ is a source-free continuous vector field with differentiable component functions, then $\\text{div} \\mathbf{F} = 0$.",
                "answer": "True",
                "explanation": "The divergence of a vector field $\\mathbf{F} = \\langle P, Q \\rangle$ is given by $\\text{div} \\mathbf{F} = \\frac{\\partial P}{\\partial x} + \\frac{\\partial Q}{\\partial y}$. A source-free vector field means that there are no sources or sinks within the field, implying that the net flux out of any closed surface is zero. For this to hold true, the divergence must be zero everywhere in the field. Hence, if $\\mathbf{F}$ is source-free and continuous with differentiable components, $\\text{div} \\mathbf{F} = 0$. For example, the vector field $\\mathbf{F} = \\langle -y, x \\rangle$ is source-free because $\\text{div} \\mathbf{F} = \\frac{\\partial (-y)}{\\partial x} + \\frac{\\partial x}{\\partial y} = 0 + 0 = 0$."
            },
            {
                "question": "If a continuous vector field $\\mathbf{F} = \\langle P, Q \\rangle$ with differentiable components has a divergence of zero, then $\\mathbf{F}$ is source-free in a simply connected domain.",
                "answer": "True",
                "explanation": "The Divergence Test for Source-Free Vector Fields states that for a continuous vector field $\\mathbf{F} = \\langle P, Q \\rangle$ with differentiable components in a simply connected domain, the field is source-free if and only if its divergence is zero. A source-free vector field means that there are no sources or sinks within the domain, implying that the net flux out of any closed surface within the domain is zero. Mathematically, this is expressed as $\\text{div} \\mathbf{F} = \\frac{\\partial P}{\\partial x} + \\frac{\\partial Q}{\\partial y} = 0$. For example, the vector field $\\mathbf{F} = \\langle -y, x \\rangle$ has a divergence of zero ($\\frac{\\partial (-y)}{\\partial x} + \\frac{\\partial x}{\\partial y} = 0$), indicating it is source-free in a simply connected domain."
            },
            {
                "question": "The curl of a vector field $F = \\langle P, Q, R \\rangle$ in $\\mathbb{R}^3$ is a scalar field.",
                "answer": "False",
                "explanation": "The curl of a vector field $F = \\langle P, Q, R \\rangle$ in $\\mathbb{R}^3$ is defined as $curl \\, F = \\left( \\frac{\\partial R}{\\partial y} - \\frac{\\partial Q}{\\partial z} \\right) \\mathbf{i} + \\left( \\frac{\\partial P}{\\partial z} - \\frac{\\partial R}{\\partial x} \\right) \\mathbf{j} + \\left( \\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y} \\right) \\mathbf{k}$. This results in a vector field, not a scalar field. For example, if $F = \\langle y, z, x \\rangle$, then $curl \\, F = \\langle 1, -1, 1 \\rangle$, which is a vector field."
            },
            {
                "question": "For any vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ in $\\mathbb{R}^3$ with continuous second-order partial derivatives, the divergence of the curl of $\\mathbf{F}$ is always zero.",
                "answer": "True",
                "explanation": "The divergence of the curl of a vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ in $\\mathbb{R}^3$ is given by $\\nabla \\cdot (\\nabla \\times \\mathbf{F})$. By definition, if the component functions $P$, $Q$, and $R$ have continuous second-order partial derivatives, this expression always equals zero. This is a fundamental result in vector calculus. For example, if $\\mathbf{F} = \\langle x^2, y^2, z^2 \\rangle$, calculating $\\nabla \\times \\mathbf{F}$ and then taking the divergence of the result will yield zero."
            },
            {
                "question": "If a vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ is conservative, then $\\nabla \\times \\mathbf{F} = 0$.",
                "answer": "True",
                "explanation": "A vector field $\\mathbf{F}$ is conservative if it can be expressed as the gradient of some scalar potential function $\\phi$, i.e., $\\mathbf{F} = \\nabla \\phi$. The curl of a gradient is always zero, which means $\\nabla \\times (\\nabla \\phi) = 0$. Therefore, if $\\mathbf{F}$ is conservative, $\\nabla \\times \\mathbf{F} = 0$. For example, consider $\\mathbf{F} = \\langle x, y, z \\rangle$. This can be written as $\\nabla \\phi$ where $\\phi = \\frac{1}{2}(x^2 + y^2 + z^2)$. The curl of $\\mathbf{F}$ is $\\nabla \\times \\mathbf{F} = \\mathbf{0}$, confirming the statement."
            },
            {
                "question": "If a vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ in a simply connected domain has a curl of zero, then the vector field $\\mathbf{F}$ is conservative.",
                "answer": "True",
                "explanation": "A vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ is said to be conservative if there exists a scalar potential function $\\phi$ such that $\\mathbf{F} = \\nabla \\phi$. One of the key properties of conservative fields is that their curl is zero, i.e., $\\nabla \\times \\mathbf{F} = 0$. In a simply connected domain, this condition is both necessary and sufficient for a field to be conservative. For example, the vector field $\\mathbf{F} = \\langle y, -x, 0 \\rangle$ has a curl of zero and can be expressed as the gradient of the potential function $\\phi = xy$. Therefore, if $\\nabla \\times \\mathbf{F} = 0$ in a simply connected domain, $\\mathbf{F}$ must be conservative."
            }
        ],
        "6-2-line-integrals": [
            {
                "question": "The scalar line integral of a function $f$ along a smooth curve $C$ parameterized by $r(t) = \\langle x(t), y(t), z(t) \\rangle$ for $a \\leq t \\leq b$ is defined as $ \\int_C f(x,y,z) \\, ds = \\lim_{n \\to \\infty} \\sum_{i=1}^n f(P_i^*) \\Delta s_i $ if this limit exists.",
                "answer": "True",
                "explanation": "The scalar line integral of a function $f$ along a smooth curve $C$ parameterized by $r(t) = \\langle x(t), y(t), z(t) \\rangle$ for $a \\leq t \\leq b$ is indeed defined as $ \\int_C f(x,y,z) \\, ds = \\lim_{n \\to \\infty} \\sum_{i=1}^n f(P_i^*) \\Delta s_i $ if this limit exists. This definition involves partitioning the curve into $n$ segments, evaluating the function at a representative point $P_i^*$ in each segment, and summing the products of these function values with the lengths of the segments $\\Delta s_i$. As $n$ approaches infinity, the sum approximates the integral. For example, if $C$ is a straight line from $(0,0,0)$ to $(1,1,1)$ and $f(x,y,z) = x + y + z$, the integral would sum the values of $f$ at points along the line, weighted by the infinitesimal segment lengths."
            },
            {
                "question": "To evaluate the scalar line integral of a continuous function $f$ over a smooth curve $C$ parameterized by $\\mathbf{r}(t)$ for $a \\leq t \\leq b$, you can use the formula $\\int_C f \\, ds = \\int_a^b f(\\mathbf{r}(t)) \\| \\mathbf{r}'(t) \\| \\, dt$.",
                "answer": "True",
                "explanation": "The scalar line integral of a continuous function $f$ over a smooth curve $C$ parameterized by $\\mathbf{r}(t)$ for $a \\leq t \\leq b$ is given by $\\int_C f \\, ds = \\int_a^b f(\\mathbf{r}(t)) \\| \\mathbf{r}'(t) \\| \\, dt$. This formula accounts for the function values along the curve and the differential arc length $ds$, which is represented by $\\| \\mathbf{r}'(t) \\| \\, dt$. For example, if $\\mathbf{r}(t) = (t, t^2)$ for $0 \\leq t \\leq 1$ and $f(x, y) = x + y$, then $\\mathbf{r}'(t) = (1, 2t)$ and $\\| \\mathbf{r}'(t) \\| = \\sqrt{1 + 4t^2}$. The integral becomes $\\int_0^1 (t + t^2) \\sqrt{1 + 4t^2} \\, dt$."
            },
            {
                "question": "The scalar line integral of a continuous function $f$ over a smooth curve $C$ parameterized by $\\mathbf{r}(t) = \\langle x(t), y(t), z(t) \\rangle$ from $t = a$ to $t = b$ is given by $\\int_C f(x, y, z) \\, ds = \\int_a^b f(\\mathbf{r}(t)) \\sqrt{(x'(t))^2 + (y'(t))^2 + (z'(t))^2} \\, dt$.",
                "answer": "True",
                "explanation": "The scalar line integral of a continuous function $f$ over a smooth curve $C$ parameterized by $\\mathbf{r}(t) = \\langle x(t), y(t), z(t) \\rangle$ from $t = a$ to $t = b$ is indeed given by $\\int_C f(x, y, z) \\, ds = \\int_a^b f(\\mathbf{r}(t)) \\sqrt{(x'(t))^2 + (y'(t))^2 + (z'(t))^2} \\, dt$. This formula accounts for the contribution of the function $f$ along the curve $C$ by integrating the product of $f$ evaluated at the points on the curve and the differential arc length $ds$. For example, if $f(x, y, z) = x + y + z$ and $\\mathbf{r}(t) = \\langle t, t^2, t^3 \\rangle$ from $t = 0$ to $t = 1$, the integral would be $\\int_0^1 (t + t^2 + t^3) \\sqrt{1 + 4t^2 + 9t^4} \\, dt$."
            },
            {
                "question": "The vector line integral of a vector field $\\mathbf{F}$ along an oriented smooth curve $C$ is defined as $\\int_C \\mathbf{F} \\cdot \\mathbf{T} \\, ds = \\lim_{n \\to \\infty} \\sum_{i=1}^n \\mathbf{F}(P_i^*) \\cdot \\mathbf{T}(P_i^*) \\Delta s_i$ if that limit exists.",
                "answer": "True",
                "explanation": "The vector line integral of a vector field $\\mathbf{F}$ along an oriented smooth curve $C$ is indeed defined as $\\int_C \\mathbf{F} \\cdot \\mathbf{T} \\, ds = \\lim_{n \\to \\infty} \\sum_{i=1}^n \\mathbf{F}(P_i^*) \\cdot \\mathbf{T}(P_i^*) \\Delta s_i$ if that limit exists. Here, $\\mathbf{T}$ represents the unit tangent vector to the curve $C$ at each point, $P_i^*$ are sample points on the curve, and $\\Delta s_i$ are small segments of the curve. This definition captures the idea of summing the dot products of the vector field $\\mathbf{F}$ and the tangent vector $\\mathbf{T}$ over infinitesimally small segments of the curve, and taking the limit as the number of segments approaches infinity. For example, if $\\mathbf{F}$ represents a force field and $C$ represents a path, the line integral gives the work done by the force along the path."
            },
            {
                "question": "If $F$ and $G$ are continuous vector fields defined on an oriented smooth curve $C$, then the line integral of their sum over $C$ is equal to the sum of their individual line integrals over $C$.",
                "answer": "True",
                "explanation": "The property of vector line integrals states that for continuous vector fields $F$ and $G$ defined on an oriented smooth curve $C$, the line integral of their sum is equal to the sum of their individual line integrals. Mathematically, this is expressed as $\\int_C (F + G) \\cdot dr = \\int_C F \\cdot dr + \\int_C G \\cdot dr$. This property is analogous to the linearity of integrals in calculus. For example, if $F = (x, y)$ and $G = (y, x)$, then $\\int_C (F + G) \\cdot dr = \\int_C (x + y, y + x) \\cdot dr = \\int_C (x, y) \\cdot dr + \\int_C (y, x) \\cdot dr$."
            },
            {
                "question": "The flux of a vector field $F$ across a curve $C$ is given by the line integral $\\int_C F \\cdot n(t) \\|n(t)\\| \\, ds$.",
                "answer": "False",
                "explanation": "The flux of a vector field $F$ across a curve $C$ is actually given by the line integral $\\int_C F \\cdot n(t) \\, ds$, where $n(t)$ is the unit normal vector to the curve $C$. The expression $\\int_C F \\cdot n(t) \\|n(t)\\| \\, ds$ incorrectly includes the magnitude of the normal vector $\\|n(t)\\|$, which should be 1 for a unit normal vector. For example, if $F = (y, -x)$ and $C$ is the unit circle, the correct flux calculation would involve integrating $F \\cdot n(t)$, not $F \\cdot n(t) \\|n(t)\\|$."
            },
            {
                "question": "The flux of a vector field $F$ across a smooth curve $C$ parameterized by $r(t) = \\langle x(t), y(t) \\rangle$ for $a \\leq t \\leq b$ can be calculated using the integral $\\int_{a}^{b} F(r(t)) \\cdot \\langle y'(t), -x'(t) \\rangle \\, dt$.",
                "answer": "True",
                "explanation": "The flux of a vector field $F$ across a smooth curve $C$ is given by the integral $\\int_{C} F \\cdot N \\, ds$. For a parameterized curve $r(t) = \\langle x(t), y(t) \\rangle$, the normal vector $n(t)$ is $\\langle y'(t), -x'(t) \\rangle$. Therefore, the flux can be computed as $\\int_{a}^{b} F(r(t)) \\cdot n(t) \\, dt$, which simplifies to $\\int_{a}^{b} F(r(t)) \\cdot \\langle y'(t), -x'(t) \\rangle \\, dt$. For example, if $F = \\langle P, Q \\rangle$ and $r(t) = \\langle t, t^2 \\rangle$, then $n(t) = \\langle 2t, -1 \\rangle$ and the flux integral becomes $\\int_{a}^{b} (P(t, t^2) \\cdot 2t + Q(t, t^2) \\cdot (-1)) \\, dt$."
            }
        ],
        "6-3-conservative-vector-fields": [
            {
                "question": "A simple curve can never be a closed curve.",
                "answer": "False",
                "explanation": "A simple curve is defined as a curve that does not cross itself, meaning there exists a parameterization $r(t)$ over $a \\leq t \\leq b$ such that $r$ is one-to-one over $(a, b)$. However, it is possible for $r(a) = r(b)$, which means the curve starts and ends at the same point, making it a closed curve. Therefore, a simple curve can indeed be a closed curve. For example, a circle is a simple closed curve because it does not intersect itself and the parameterization $r(t)$ satisfies $r(a) = r(b)$. Another example is an ellipse, which is also a simple closed curve."
            },
            {
                "question": "A region D is simply connected if it is connected and any simple closed curve within D can be continuously shrunk to a point while remaining inside D.",
                "answer": "True",
                "explanation": "A simply connected region is one where any simple closed curve within the region can be continuously shrunk to a point without leaving the region. This implies that the region is connected and has no holes. For example, a disk in the plane is simply connected because any loop within the disk can be contracted to a point without exiting the disk. Conversely, an annulus (a ring-shaped region) is not simply connected because a loop around the hole cannot be shrunk to a point without leaving the region."
            },
            {
                "question": "According to the Fundamental Theorem for Line Integrals, if $C$ is a piecewise smooth curve parameterized by $\\mathbf{r}(t)$ for $a \\leq t \\leq b$, and $f$ is a function with continuous first-order partial derivatives on $C$, then the line integral of the gradient of $f$ along $C$ is equal to $f(\\mathbf{r}(b)) - f(\\mathbf{r}(a))$.",
                "answer": "True",
                "explanation": "The Fundamental Theorem for Line Integrals states that if $C$ is a piecewise smooth curve parameterized by $\\mathbf{r}(t)$ for $a \\leq t \\leq b$, and $f$ is a function with continuous first-order partial derivatives on $C$, then the line integral of the gradient of $f$ along $C$ is given by $\\int_C \\nabla f \\cdot d\\mathbf{r} = f(\\mathbf{r}(b)) - f(\\mathbf{r}(a))$. This theorem essentially states that the integral of the gradient of a function over a curve depends only on the values of the function at the endpoints of the curve. For example, if $f(x, y) = x^2 + y^2$ and $\\mathbf{r}(t) = (t, t^2)$ for $0 \\leq t \\leq 1$, then $\\int_C \\nabla f \\cdot d\\mathbf{r} = f(\\mathbf{r}(1)) - f(\\mathbf{r}(0)) = (1^2 + 1^4) - (0^2 + 0^4) = 2 - 0 = 2$."
            },
            {
                "question": "A vector field $F$ is path independent if the line integrals of $F$ along any two paths $C_1$ and $C_2$ with the same initial and terminal points in the domain $D$ are equal.",
                "answer": "True",
                "explanation": "A vector field $F$ is said to be path independent if the value of the line integral of $F$ between two points depends only on the endpoints and not on the specific path taken between them. Mathematically, this means that for any two paths $C_1$ and $C_2$ in the domain $D$ with the same initial and terminal points, the line integrals are equal: $\\int_{C_1} F \\cdot dr = \\int_{C_2} F \\cdot dr$. For example, if $F$ is a conservative vector field, then $F$ is path independent because there exists a potential function $\\phi$ such that $F = \\nabla \\phi$, and the line integral of $F$ between any two points is simply the difference in the values of $\\phi$ at those points, regardless of the path taken."
            },
            {
                "question": "If a vector field $\\mathbf{F}$ is conservative, then the line integral of $\\mathbf{F}$ between any two points is independent of the path taken.",
                "answer": "True",
                "explanation": "A vector field $\\mathbf{F}$ is conservative if there exists a scalar potential function $\\phi$ such that $\\mathbf{F} = \\nabla \\phi$. For conservative fields, the line integral $\\int_C \\mathbf{F} \\cdot d\\mathbf{r}$ depends only on the endpoints of the path $C$ and not on the specific path taken. This is because the integral can be evaluated as $\\phi(B) - \\phi(A)$, where $A$ and $B$ are the endpoints. For example, in a gravitational field, the work done moving an object between two points depends only on the height difference, not the path taken."
            },
            {
                "question": "If a continuous vector field $\\mathbf{F}$ is independent of path and its domain $D$ is open and connected, then $\\mathbf{F}$ is conservative.",
                "answer": "True",
                "explanation": "A vector field $\\mathbf{F}$ is said to be conservative if there exists a scalar potential function $\\phi$ such that $\\mathbf{F} = \\nabla \\phi$. One of the key properties of conservative fields is path independence, meaning the line integral of $\\mathbf{F}$ between two points is independent of the path taken. The given statement asserts that if $\\mathbf{F}$ is path-independent and its domain $D$ is open and connected, then $\\mathbf{F}$ must be conservative. This is true because path independence implies that the integral of $\\mathbf{F}$ around any closed loop is zero, which is a necessary and sufficient condition for $\\mathbf{F}$ to be conservative in an open and connected domain. For example, the gravitational field $\\mathbf{F} = -\\nabla U$ (where $U$ is the gravitational potential) is conservative because the work done by gravity is path-independent and the domain (space) is open and connected."
            },
            {
                "question": "If a vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ on an open, simply connected region $D$ satisfies $P_y = Q_x$, $P_z = R_x$, and $Q_z = R_y$ throughout $D$, then $\\mathbf{F}$ is conservative.",
                "answer": "True",
                "explanation": "A vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ is conservative if it can be expressed as the gradient of some scalar potential function $\\phi$, i.e., $\\mathbf{F} = \\nabla \\phi$. For this to be true, the mixed partial derivatives of $\\phi$ must be equal, which translates to the conditions $P_y = Q_x$, $P_z = R_x$, and $Q_z = R_y$. These conditions ensure that the curl of $\\mathbf{F}$ is zero, implying that $\\mathbf{F}$ is conservative in an open, simply connected region $D$. For example, if $\\mathbf{F} = \\langle 2xy, x^2, 0 \\rangle$, then $P = 2xy$, $Q = x^2$, and $R = 0$. We find $P_y = 2x$, $Q_x = 2x$, $P_z = 0$, $R_x = 0$, $Q_z = 0$, and $R_y = 0$, satisfying the conditions and confirming that $\\mathbf{F}$ is conservative."
            },
            {
                "question": "For a vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ on an open, simply connected region $D$, the conditions $P_y = Q_x$, $P_z = R_x$, and $Q_z = R_y$ throughout $D$ are both necessary and sufficient for $\\mathbf{F}$ to be conservative.",
                "answer": "True",
                "explanation": "A vector field $\\mathbf{F} = \\langle P, Q, R \\rangle$ is conservative if it can be expressed as the gradient of some scalar potential function $\\phi$, i.e., $\\mathbf{F} = \\nabla \\phi$. For $\\mathbf{F}$ to be conservative in an open, simply connected region $D$, the mixed partial derivatives of $\\phi$ must be equal. This translates to the conditions $P_y = Q_x$, $P_z = R_x$, and $Q_z = R_y$. These conditions are both necessary (if $\\mathbf{F}$ is conservative, they must hold) and sufficient (if they hold, $\\mathbf{F}$ is conservative) for $\\mathbf{F}$ to be conservative. For example, if $\\mathbf{F} = \\langle 2xy, x^2, 0 \\rangle$, then $P = 2xy$, $Q = x^2$, and $R = 0$. Checking the conditions: $P_y = 2x = Q_x$, $P_z = 0 = R_x$, and $Q_z = 0 = R_y$. Since all conditions are satisfied, $\\mathbf{F}$ is conservative."
            }
        ],
        "6-4-greens-theorem": [
            {
                "question": "Green's Theorem states that for a vector field $\\mathbf{F} = \\langle P, Q \\rangle$ with continuous partial derivatives on an open, simply connected region $D$ with a piecewise smooth, simple closed curve $C$ oriented counterclockwise, the line integral around $C$ of $\\mathbf{F} \\cdot d\\mathbf{r}$ is equal to the double integral over $D$ of $(\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y}) dA$.",
                "answer": "True",
                "explanation": "Green's Theorem relates a line integral around a simple closed curve $C$ to a double integral over the region $D$ it encloses. Specifically, for a vector field $\\mathbf{F} = \\langle P, Q \\rangle$ with continuous partial derivatives, the theorem states: $$\\oint_C \\mathbf{F} \\cdot d\\mathbf{r} = \\oint_C (P dx + Q dy) = \\iint_D \\left( \\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y} \\right) dA.$$ This means the circulation of $\\mathbf{F}$ around $C$ is equal to the sum of the curl of $\\mathbf{F}$ over the area $D$. For example, if $\\mathbf{F} = \\langle -y, x \\rangle$, then $P = -y$ and $Q = x$, and the theorem simplifies to: $$\\oint_C (-y dx + x dy) = \\iint_D (1 + 1) dA = 2 \\iint_D dA.$$"
            },
            {
                "question": "According to Green's Theorem in flux form, for a vector field $\\mathbf{F} = \\langle P, Q \\rangle$ with continuous partial derivatives on an open region containing $D$, the flux of $\\mathbf{F}$ across the boundary curve $C$ of $D$ is given by $\\oint_C \\mathbf{F} \\cdot \\mathbf{N} \\, ds = \\iint_D (P_x + Q_y) \\, dA$.",
                "answer": "True",
                "explanation": "Green's Theorem in flux form relates the flux of a vector field $\\mathbf{F} = \\langle P, Q \\rangle$ across a simple closed curve $C$ to a double integral over the region $D$ enclosed by $C$. Specifically, it states that $\\oint_C \\mathbf{F} \\cdot \\mathbf{N} \\, ds = \\iint_D (P_x + Q_y) \\, dA$, where $\\mathbf{N}$ is the outward-pointing unit normal vector to $C$, and $P_x$ and $Q_y$ are the partial derivatives of $P$ and $Q$ with respect to $x$ and $y$, respectively. This theorem requires that $D$ be an open, simply connected region with a piecewise smooth, simple closed curve $C$ oriented counterclockwise. For example, if $\\mathbf{F} = \\langle x^2, y^2 \\rangle$, then $P = x^2$ and $Q = y^2$, and the flux form of Green's Theorem would involve computing $\\iint_D (2x + 2y) \\, dA$."
            }
        ]
    },
    "Differentiation of Functions of Several Variables": {
        "4-2-limits-and-continuity": [
            {
                "question": "A $\\delta$ disk centered at point $(a,b)$ in $\\mathbb{R}^2$ includes all points $(x,y)$ such that the Euclidean distance from $(x,y)$ to $(a,b)$ is less than $\\delta$.",
                "answer": "True",
                "explanation": "The definition of a $\\delta$ disk centered at point $(a,b)$ in $\\mathbb{R}^2$ is an open disk of radius $\\delta$ centered at $(a,b)$. This means it includes all points $(x,y)$ such that the Euclidean distance from $(x,y)$ to $(a,b)$ is less than $\\delta$. Mathematically, this is represented as $\\{(x,y) \\in \\mathbb{R}^2 \\mid (x-a)^2 + (y-b)^2 < \\delta^2\\}$. For example, if $(a,b) = (0,0)$ and $\\delta = 1$, the $\\delta$ disk includes all points $(x,y)$ such that $x^2 + y^2 < 1$, which is the interior of a circle with radius 1 centered at the origin."
            },
            {
                "question": "The limit of a function $f(x,y)$ as $(x,y)$ approaches $(a,b)$ is $L$ if for every $\\varepsilon > 0$, there exists a $\\delta > 0$ such that for all points $(x,y)$ within a $\\delta$-disk around $(a,b)$, the value of $f(x,y)$ is exactly $L$.",
                "answer": "False",
                "explanation": "The correct definition of the limit of a function $f(x,y)$ as $(x,y)$ approaches $(a,b)$ is that for every $\\varepsilon > 0$, there exists a $\\delta > 0$ such that for all points $(x,y)$ within a $\\delta$-disk around $(a,b)$, the value of $f(x,y)$ is within $\\varepsilon$ of $L$, not exactly $L$. This means $|f(x,y) - L| < \\varepsilon$ whenever $0 < (x-a)^2 + (y-b)^2 < \\delta$. For example, if $f(x,y) = x + y$ and we are considering the limit as $(x,y)$ approaches $(1,1)$, then for any $\\varepsilon > 0$, we can find a $\\delta$ such that $|f(x,y) - 2| < \\varepsilon$ for all $(x,y)$ within the $\\delta$-disk around $(1,1)$. The function values are close to 2, but not necessarily exactly 2."
            },
            {
                "question": "If $\\lim_{(x,y) \\to (a,b)} f(x,y) = L$ and $\\lim_{(x,y) \\to (a,b)} g(x,y) = M$, then $\\lim_{(x,y) \\to (a,b)} (f(x,y) + g(x,y)) = L + M$.",
                "answer": "True",
                "explanation": "This statement is true and is an application of the Sum Law for limits of functions of two variables. According to the Sum Law, if the limits of $f(x,y)$ and $g(x,y)$ as $(x,y)$ approaches $(a,b)$ are $L$ and $M$ respectively, then the limit of their sum is the sum of their limits. For example, if $\\lim_{(x,y) \\to (1,2)} f(x,y) = 3$ and $\\lim_{(x,y) \\to (1,2)} g(x,y) = 4$, then $\\lim_{(x,y) \\to (1,2)} (f(x,y) + g(x,y)) = 3 + 4 = 7$."
            },
            {
                "question": "If a point $P_0$ is an interior point of a subset $S$ of $\\mathbb{R}^2$, then there exists a $\\delta$-disk centered around $P_0$ that is completely contained within $S$.",
                "answer": "True",
                "explanation": "By definition, a point $P_0$ is an interior point of a subset $S$ of $\\mathbb{R}^2$ if there exists a $\\delta$-disk centered around $P_0$ that is completely contained within $S$. This means that all points within the $\\delta$-disk are also elements of $S$. For example, if $S$ is a circle and $P_0$ is a point inside this circle, then we can find a small enough $\\delta$-disk around $P_0$ that lies entirely within the circle $S$."
            },
            {
                "question": "A set $S$ in $\\mathbb{R}^2$ can be both open and closed simultaneously.",
                "answer": "True",
                "explanation": "In the context of topology, a set $S$ in $\\mathbb{R}^2$ can indeed be both open and closed simultaneously. Such sets are called 'clopen' sets. The most common examples of clopen sets in $\\mathbb{R}^2$ are the empty set $\\emptyset$ and the entire space $\\mathbb{R}^2$ itself. For instance, the empty set is trivially open because it has no points, and it is also closed because it contains all its (non-existent) boundary points. Similarly, $\\mathbb{R}^2$ is open because every point is an interior point, and it is closed because it contains all its boundary points (which are none, as it is unbounded)."
            },
            {
                "question": "A region in $\\mathbb{R}^2$ can be represented as the union of two or more disjoint, nonempty open subsets.",
                "answer": "False",
                "explanation": "A region in $\\mathbb{R}^2$ is defined as an open, connected, and nonempty set. By definition, a connected set cannot be represented as the union of two or more disjoint, nonempty open subsets. For example, the set $S = \\{(x,y) \\in \\mathbb{R}^2 : x^2 + y^2 < 1\\}$ is a region because it is open, connected, and nonempty. If we try to represent it as the union of two disjoint, nonempty open subsets, we would violate its connectedness."
            },
            {
                "question": "For a function $f(x,y)$, if $(a,b)$ is on the boundary of the domain of $f$, then $\\lim_{(x,y) \\to (a,b)} f(x,y) = L$ means that for any $\\varepsilon > 0$, there exists a $\\delta > 0$ such that for any point $(x,y)$ inside the domain of $f$ and within a distance $\\delta$ of $(a,b)$, the value of $f(x,y)$ is within $\\varepsilon$ of $L$.",
                "answer": "True",
                "explanation": "The definition of the limit of a function of two variables $f(x,y)$ as $(x,y)$ approaches $(a,b)$ on the boundary of the domain states that $\\lim_{(x,y) \\to (a,b)} f(x,y) = L$ if for any $\\varepsilon > 0$, there exists a $\\delta > 0$ such that for any point $(x,y)$ within the domain of $f$ and within a distance $\\delta$ of $(a,b)$, the value of $f(x,y)$ is within $\\varepsilon$ of $L$. This means $|f(x,y) - L| < \\varepsilon$ whenever $0 < (x - a)^2 + (y - b)^2 < \\delta^2$. For example, if $f(x,y) = x + y$ and $(a,b) = (1,1)$, then $\\lim_{(x,y) \\to (1,1)} f(x,y) = 2$ means that for any $\\varepsilon > 0$, there exists a $\\delta > 0$ such that if $(x,y)$ is within $\\delta$ of $(1,1)$, then $|f(x,y) - 2| < \\varepsilon$."
            },
            {
                "question": "For a function $f(x,y)$ to be continuous at a point $(a,b)$, it is sufficient that $f(a,b)$ exists and $\\lim_{(x,y) \\to (a,b)} f(x,y)$ exists.",
                "answer": "False",
                "explanation": "For a function $f(x,y)$ to be continuous at a point $(a,b)$, three conditions must be satisfied: 1) $f(a,b)$ exists, 2) $\\lim_{(x,y) \\to (a,b)} f(x,y)$ exists, and 3) $\\lim_{(x,y) \\to (a,b)} f(x,y) = f(a,b)$. Simply having $f(a,b)$ and the limit exist is not sufficient; the limit must also equal the function value at that point. For example, consider the function $f(x,y) = \\frac{xy}{x^2 + y^2}$ at the point $(0,0)$. Here, $f(0,0) = 0$ and $\\lim_{(x,y) \\to (0,0)} f(x,y) = 0$, so the function is continuous at $(0,0)$. However, if $f(0,0)$ were defined as 1 instead of 0, the function would not be continuous at $(0,0)$ despite the limit existing."
            },
            {
                "question": "If $f(x,y)$ and $g(x,y)$ are continuous at $(x_0, y_0)$, then $f(x,y) + g(x,y)$ is also continuous at $(x_0, y_0)$.",
                "answer": "True",
                "explanation": "The sum of two continuous functions is continuous. If $f(x,y)$ and $g(x,y)$ are continuous at $(x_0, y_0)$, it means that for any $\\epsilon > 0$, there exists a $\\delta > 0$ such that if $\\sqrt{(x - x_0)^2 + (y - y_0)^2} < \\delta$, then $|f(x,y) - f(x_0, y_0)| < \\epsilon/2$ and $|g(x,y) - g(x_0, y_0)| < \\epsilon/2$. Therefore, $|f(x,y) + g(x,y) - (f(x_0, y_0) + g(x_0, y_0))| \\leq |f(x,y) - f(x_0, y_0)| + |g(x,y) - g(x_0, y_0)| < \\epsilon/2 + \\epsilon/2 = \\epsilon$. Hence, $f(x,y) + g(x,y)$ is continuous at $(x_0, y_0)$. For example, if $f(x,y) = x + y$ and $g(x,y) = x - y$, both are continuous everywhere, and their sum $f(x,y) + g(x,y) = 2x$ is also continuous everywhere."
            },
            {
                "question": "If $g(x)$ is continuous at $x_0$ and $h(y)$ is continuous at $y_0$, then the function $f(x,y) = g(x)h(y)$ is continuous at $(x_0, y_0)$.",
                "answer": "True",
                "explanation": "The product of two continuous functions is continuous. Given that $g(x)$ is continuous at $x_0$ and $h(y)$ is continuous at $y_0$, the function $f(x,y) = g(x)h(y)$ will be continuous at $(x_0, y_0)$. This is because the limit of the product of two functions is the product of their limits, i.e., $\\lim_{(x,y) \\to (x_0,y_0)} f(x,y) = \\lim_{(x,y) \\to (x_0,y_0)} g(x)h(y) = (\\lim_{x \\to x_0} g(x)) (\\lim_{y \\to y_0} h(y)) = g(x_0)h(y_0)$. For example, if $g(x) = x$ and $h(y) = y^2$, both are continuous at any point, and thus $f(x,y) = xy^2$ is continuous at any point $(x_0, y_0)$. Therefore, the statement is true."
            },
            {
                "question": "If $g$ is a continuous function from a domain $D \\subseteq \\mathbb{R}^2$ to a range $R \\subseteq \\mathbb{R}$ and $f$ is a continuous function from $\\mathbb{R}$ to $\\mathbb{R}$, then the composition $f \\circ g$ is continuous at any point $(x_0, y_0) \\in D$ where $z_0 = g(x_0, y_0)$ and $z_0$ is in the domain of $f$.",
                "answer": "True",
                "explanation": "The composition of two continuous functions is continuous. Given that $g$ is continuous at $(x_0, y_0) \\in D$ and $f$ is continuous at $z_0 = g(x_0, y_0)$, the composition $f \\circ g$ is continuous at $(x_0, y_0)$. For example, if $g(x, y) = x + y$ and $f(z) = z^2$, both functions are continuous. Therefore, $f \\circ g(x, y) = (x + y)^2$ is also continuous at any point $(x_0, y_0) \\in D$."
            },
            {
                "question": "A $\\delta$ ball in $\\mathbb{R}^3$ centered at $(x_0, y_0, z_0)$ includes all points $(x, y, z)$ such that $(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 < \\delta$.",
                "answer": "False",
                "explanation": "The correct definition of a $\\delta$ ball in $\\mathbb{R}^3$ centered at $(x_0, y_0, z_0)$ includes all points $(x, y, z)$ such that $(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 < \\delta^2$. The inequality should compare the sum of squared differences to $\\delta^2$, not $\\delta$. For example, if $\\delta = 2$, the $\\delta$ ball includes points within a radius of 2 units from $(x_0, y_0, z_0)$, meaning $(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 < 4$."
            }
        ],
        "4-3-partial-derivatives": [
            {
                "question": "The partial derivative of a function $f(x,y)$ with respect to $x$ is defined as $\\frac{\\partial f}{\\partial x} = \\lim_{h \\to 0} \\frac{f(x+h,y) - f(x,y)}{h}$, and the partial derivative of $f$ with respect to $y$ is defined as $\\frac{\\partial f}{\\partial y} = \\lim_{k \\to 0} \\frac{f(x,y+k) - f(x,y)}{k}$.",
                "answer": "True",
                "explanation": "The partial derivative of a function $f(x,y)$ with respect to $x$ measures how $f$ changes as $x$ changes while keeping $y$ constant. It is defined as $\\frac{\\partial f}{\\partial x} = \\lim_{h \\to 0} \\frac{f(x+h,y) - f(x,y)}{h}$. Similarly, the partial derivative with respect to $y$ measures how $f$ changes as $y$ changes while keeping $x$ constant, and is defined as $\\frac{\\partial f}{\\partial y} = \\lim_{k \\to 0} \\frac{f(x,y+k) - f(x,y)}{k}$. For example, if $f(x,y) = x^2 + y^2$, then $\\frac{\\partial f}{\\partial x} = 2x$ and $\\frac{\\partial f}{\\partial y} = 2y$, illustrating how the function changes with respect to each variable independently."
            },
            {
                "question": "The partial derivative of a function $f(x,y,z)$ with respect to $x$ is given by $\\frac{\\partial f}{\\partial x} = \\lim_{h \\to 0} \\frac{f(x+h,y,z) - f(x,y,z)}{h}$.",
                "answer": "True",
                "explanation": "The partial derivative of a function $f(x,y,z)$ with respect to $x$ measures how $f$ changes as $x$ changes while keeping $y$ and $z$ constant. It is defined as $\\frac{\\partial f}{\\partial x} = \\lim_{h \\to 0} \\frac{f(x+h,y,z) - f(x,y,z)}{h}$. This definition captures the rate of change of $f$ in the $x$ direction. For example, if $f(x,y,z) = x^2 + y + z$, then $\\frac{\\partial f}{\\partial x} = 2x$, which shows how $f$ changes with respect to $x$ while $y$ and $z$ remain constant."
            },
            {
                "question": "If the mixed partial derivatives $f_{xy}$ and $f_{yx}$ of a function $f(x,y)$ are continuous on an open disk $D$ containing the point $(a,b)$, then $f_{xy} = f_{yx}$ at $(a,b)$.",
                "answer": "True",
                "explanation": "Clairaut's Theorem states that if the mixed partial derivatives $f_{xy}$ and $f_{yx}$ are continuous on an open disk $D$ containing the point $(a,b)$, then these mixed partial derivatives are equal at $(a,b)$. This means $f_{xy}(a,b) = f_{yx}(a,b)$. For example, if $f(x,y) = x^2y + y^3$, then $f_x = 2xy$, $f_{xy} = 2x$, $f_y = x^2 + 3y^2$, and $f_{yx} = 2x$. Since $f_{xy}$ and $f_{yx}$ are continuous and equal, Clairaut's Theorem holds true."
            }
        ],
        "4-6-directional-derivatives-and-the-gradient": [
            {
                "question": "The directional derivative of a function $f(x,y)$ at a point $(a,b)$ in the direction of a unit vector $u = \\cos(\\theta)i + \\sin(\\theta)j$ is given by $D_u f(a,b) = \\lim_{h \\to 0} \\frac{f(a+h\\cos(\\theta), b+h\\sin(\\theta)) - f(a,b)}{h}$, provided the limit exists.",
                "answer": "True",
                "explanation": "The directional derivative $D_u f(a,b)$ measures the rate at which the function $f(x,y)$ changes at the point $(a,b)$ in the direction of the unit vector $u$. The formula $D_u f(a,b) = \\lim_{h \\to 0} \\frac{f(a+h\\cos(\\theta), b+h\\sin(\\theta)) - f(a,b)}{h}$ captures this by considering the change in $f$ as we move a small distance $h$ in the direction specified by $u$. Here, $u = \\cos(\\theta)i + \\sin(\\theta)j$ ensures that the movement is along the direction of $u$. For example, if $f(x,y) = x^2 + y^2$ and $(a,b) = (1,1)$, and we want the directional derivative in the direction of $u = \\frac{1}{\\sqrt{2}}i + \\frac{1}{\\sqrt{2}}j$ (i.e., $\\theta = \\frac{\\pi}{4}$), we would use the given formula to find the rate of change of $f$ in that direction."
            },
            {
                "question": "The directional derivative of a function $f(x,y)$ in the direction of a unit vector $u = \\cos(\\theta)i + \\sin(\\theta)j$ is given by $D_u f(x,y) = f_x(x,y) \\cos(\\theta) + f_y(x,y) \\sin(\\theta)$, where $f_x$ and $f_y$ are the partial derivatives of $f$ with respect to $x$ and $y$, respectively.",
                "answer": "True",
                "explanation": "The directional derivative of a function $f(x,y)$ in the direction of a unit vector $u = \\cos(\\theta)i + \\sin(\\theta)j$ is indeed given by $D_u f(x,y) = f_x(x,y) \\cos(\\theta) + f_y(x,y) \\sin(\\theta)$. This formula combines the rates of change of $f$ in the $x$ and $y$ directions, weighted by the components of the direction vector $u$. For example, if $f(x,y) = x^2 + y^2$, then $f_x = 2x$ and $f_y = 2y$. In the direction of $u = \\cos(\\pi/4)i + \\sin(\\pi/4)j$, the directional derivative at $(1,1)$ would be $D_u f(1,1) = 2 \\cdot 1 \\cdot \\cos(\\pi/4) + 2 \\cdot 1 \\cdot \\sin(\\pi/4) = 2\\sqrt{2}/2 + 2\\sqrt{2}/2 = 2\\sqrt{2}$. This confirms the given formula."
            },
            {
                "question": "The gradient of a function $f(x,y)$, denoted as $\\nabla f(x,y)$, is a vector that points in the direction of the steepest ascent of the function and is defined as $\\nabla f(x,y) = f_x(x,y)\\mathbf{i} + f_y(x,y)\\mathbf{j}$.",
                "answer": "True",
                "explanation": "The gradient $\\nabla f(x,y)$ of a function $f(x,y)$ is indeed a vector that points in the direction of the steepest ascent of the function. It is defined as $\\nabla f(x,y) = f_x(x,y)\\mathbf{i} + f_y(x,y)\\mathbf{j}$, where $f_x$ and $f_y$ are the partial derivatives of $f$ with respect to $x$ and $y$, respectively. For example, if $f(x,y) = x^2 + y^2$, then $f_x = 2x$ and $f_y = 2y$, so $\\nabla f(x,y) = 2x\\mathbf{i} + 2y\\mathbf{j}$, which points away from the origin in the direction of increasing $f$."
            },
            {
                "question": "If the gradient of a differentiable function $f(x,y)$ at a point $(x_0, y_0)$ is zero, then the directional derivative of $f$ at $(x_0, y_0)$ in any direction is also zero.",
                "answer": "True",
                "explanation": "The gradient $\\nabla f(x_0, y_0)$ represents the vector of partial derivatives of $f$ at $(x_0, y_0)$. If $\\nabla f(x_0, y_0) = 0$, it means that all partial derivatives of $f$ at $(x_0, y_0)$ are zero. The directional derivative $D_u f(x_0, y_0)$ in the direction of a unit vector $u$ is given by the dot product $\\nabla f(x_0, y_0) \\cdot u$. Since $\\nabla f(x_0, y_0) = 0$, this dot product is zero for any $u$, hence $D_u f(x_0, y_0) = 0$. For example, if $f(x,y) = x^2 + y^2$ and $(x_0, y_0) = (0,0)$, then $\\nabla f(0,0) = (0,0)$, and the directional derivative in any direction at $(0,0)$ is zero."
            },
            {
                "question": "If a function $z=f(x,y)$ has continuous first-order partial derivatives in an open disk centered at a point $(x_0, y_0)$ and $\\nabla f(x_0, y_0) \\neq 0$, then $\\nabla f(x_0, y_0)$ is tangent to the level curve of $f$ at $(x_0, y_0)$.",
                "answer": "False",
                "explanation": "The gradient vector $\\nabla f(x_0, y_0)$ is actually normal (perpendicular) to the level curve of $f$ at $(x_0, y_0)$, not tangent. The level curve of a function $f(x, y)$ at a point $(x_0, y_0)$ is defined by the set of points where $f(x, y)$ is constant. The gradient $\\nabla f(x_0, y_0)$ points in the direction of the steepest ascent of the function and is orthogonal to the level curve at that point. For example, if $f(x, y) = x^2 + y^2$, the level curves are circles centered at the origin, and the gradient $\\nabla f(x, y) = (2x, 2y)$ is perpendicular to these circles."
            },
            {
                "question": "The gradient of a function $f(x,y,z)$, denoted as $\\nabla f(x,y,z)$, is a vector that consists of the partial derivatives of $f$ with respect to $x$, $y$, and $z$, and can also be written as $\\text{grad} f(x,y,z)$.",
                "answer": "True",
                "explanation": "The gradient of a function $f(x,y,z)$, denoted as $\\nabla f(x,y,z)$, is indeed a vector composed of the partial derivatives of $f$ with respect to $x$, $y$, and $z$. Mathematically, it is expressed as $\\nabla f(x,y,z) = f_x(x,y,z)\\mathbf{i} + f_y(x,y,z)\\mathbf{j} + f_z(x,y,z)\\mathbf{k}$, where $f_x$, $f_y$, and $f_z$ are the partial derivatives of $f$ with respect to $x$, $y$, and $z$, respectively. This vector points in the direction of the greatest rate of increase of the function. The notation $\\text{grad} f(x,y,z)$ is an alternative way to represent the gradient. For example, if $f(x,y,z) = x^2 + y^2 + z^2$, then $\\nabla f(x,y,z) = 2x\\mathbf{i} + 2y\\mathbf{j} + 2z\\mathbf{k}$."
            },
            {
                "question": "The directional derivative of a function $f(x,y,z)$ in the direction of a unit vector $u = \\cos \\alpha \\, i + \\cos \\beta \\, j + \\cos \\gamma \\, k$ at the point $(x_0, y_0, z_0)$ is given by $D_u f(x_0, y_0, z_0) = \\lim_{t \\to 0} \\frac{f(x_0 + t \\cos \\alpha, y_0 + t \\cos \\beta, z_0 + t \\cos \\gamma) - f(x_0, y_0, z_0)}{t}$, provided the limit exists.",
                "answer": "True",
                "explanation": "The directional derivative of a function $f(x,y,z)$ in the direction of a unit vector $u = \\cos \\alpha \\, i + \\cos \\beta \\, j + \\cos \\gamma \\, k$ at a point $(x_0, y_0, z_0)$ is defined as the rate at which the function changes as one moves from $(x_0, y_0, z_0)$ in the direction of $u$. Mathematically, it is given by $D_u f(x_0, y_0, z_0) = \\lim_{t \\to 0} \\frac{f(x_0 + t \\cos \\alpha, y_0 + t \\cos \\beta, z_0 + t \\cos \\gamma) - f(x_0, y_0, z_0)}{t}$, provided the limit exists. This formula captures the change in $f$ along the direction specified by the unit vector $u$. For example, if $f(x,y,z) = x^2 + y^2 + z^2$ and $u = \\frac{1}{\\sqrt{3}}i + \\frac{1}{\\sqrt{3}}j + \\frac{1}{\\sqrt{3}}k$, the directional derivative at $(1,1,1)$ would be computed using this limit definition."
            },
            {
                "question": "The directional derivative of a differentiable function $f(x,y,z)$ in the direction of a unit vector $u = \\cos(\\alpha)i + \\cos(\\beta)j + \\cos(\\gamma)k$ is given by $D_u f(x,y,z) = \\nabla f(x,y,z) \\cdot u = f_x(x,y,z) \\cos(\\alpha) + f_y(x,y,z) \\cos(\\beta) + f_z(x,y,z) \\cos(\\gamma)$.",
                "answer": "True",
                "explanation": "The directional derivative of a function $f(x,y,z)$ in the direction of a unit vector $u$ is calculated as the dot product of the gradient of $f$ and the unit vector $u$. The gradient $\\nabla f(x,y,z)$ is a vector of partial derivatives $(f_x, f_y, f_z)$. The unit vector $u$ is given by its components $(\\cos(\\alpha), \\cos(\\beta), \\cos(\\gamma))$. Therefore, the directional derivative $D_u f(x,y,z)$ is computed as $\\nabla f(x,y,z) \\cdot u = f_x(x,y,z) \\cos(\\alpha) + f_y(x,y,z) \\cos(\\beta) + f_z(x,y,z) \\cos(\\gamma)$. This formula shows how the rate of change of $f$ in the direction of $u$ depends on the partial derivatives of $f$ and the direction cosines of $u$."
            }
        ],
        "4-7-maxima-minima-problems": [
            {
                "question": "For a function $z = f(x, y)$ defined on an open set containing the point $(x_0, y_0)$, the point $(x_0, y_0)$ is a critical point if $f_x(x_0, y_0) = 0$ and $f_y(x_0, y_0) = 0$.",
                "answer": "True",
                "explanation": "A critical point of a function $f(x, y)$ is defined as a point $(x_0, y_0)$ where either both partial derivatives $f_x(x_0, y_0)$ and $f_y(x_0, y_0)$ are zero, or at least one of these partial derivatives does not exist. In this case, since $f_x(x_0, y_0) = 0$ and $f_y(x_0, y_0) = 0$, the point $(x_0, y_0)$ satisfies the first condition for being a critical point. For example, if $f(x, y) = x^2 + y^2$, then at the point $(0, 0)$, we have $f_x(0, 0) = 2x = 0$ and $f_y(0, 0) = 2y = 0$, making $(0, 0)$ a critical point."
            },
            {
                "question": "If a function $f(x, y)$ has a local maximum at $(x_0, y_0)$, then $f(x_0, y_0) \\geq f(x, y)$ for all points $(x, y)$ in the domain of $f$.",
                "answer": "False",
                "explanation": "A local maximum at $(x_0, y_0)$ means that $f(x_0, y_0) \\geq f(x, y)$ for all points $(x, y)$ within some disk centered at $(x_0, y_0)$, not necessarily for all points in the domain of $f$. If the inequality holds for all points in the domain, then $f$ has a global maximum at $(x_0, y_0)$. For example, consider $f(x, y) = -x^2 - y^2$. The function has a global maximum at $(0, 0)$ because $f(0, 0) = 0$ and $f(x, y) \\leq 0$ for all $(x, y)$. However, if we consider $f(x, y) = -x^2 - y^2 + 1$ within a small disk around $(0, 0)$, it has a local maximum at $(0, 0)$, but not a global maximum since $f(x, y)$ can be greater than $f(0, 0)$ outside this disk."
            },
            {
                "question": "If a function $z = f(x, y)$ has a local extremum at the point $(x_0, y_0)$, then the partial derivatives $f_x$ and $f_y$ at $(x_0, y_0)$ must both be zero.",
                "answer": "True",
                "explanation": "According to Fermat's Theorem for Functions of Two Variables, if a function $z = f(x, y)$ has a local extremum at the point $(x_0, y_0)$, then $(x_0, y_0)$ is a critical point of $f$. This means that the partial derivatives $f_x$ and $f_y$ must both be zero at $(x_0, y_0)$. For example, consider the function $f(x, y) = x^2 + y^2$. At the point $(0, 0)$, which is a local minimum, both partial derivatives $f_x = 2x$ and $f_y = 2y$ are zero, confirming that $(0, 0)$ is a critical point."
            },
            {
                "question": "For a function $z = f(x, y)$, the point $(x_0, y_0, f(x_0, y_0))$ is a saddle point if both $f_x(x_0, y_0) = 0$ and $f_y(x_0, y_0) = 0$, but $f$ does not have a local extremum at $(x_0, y_0)$.",
                "answer": "True",
                "explanation": "A saddle point occurs at $(x_0, y_0, f(x_0, y_0))$ if the partial derivatives $f_x(x_0, y_0) = 0$ and $f_y(x_0, y_0) = 0$, indicating a critical point, but the function $f$ does not have a local extremum at $(x_0, y_0)$. This means that in some directions, the function increases, while in others, it decreases. For example, the function $f(x, y) = x^2 - y^2$ has a saddle point at $(0, 0)$ because $f_x(0, 0) = 0$ and $f_y(0, 0) = 0$, but $(0, 0)$ is not a local extremum since $f$ increases along the $x$-axis and decreases along the $y$-axis."
            },
            {
                "question": "If $D = f_{xx}(x_0, y_0) f_{yy}(x_0, y_0) - (f_{xy}(x_0, y_0))^2 > 0$ and $f_{xx}(x_0, y_0) < 0$, then the function $f$ has a local minimum at $(x_0, y_0)$.",
                "answer": "False",
                "explanation": "According to the Second Derivative Test, if $D > 0$ and $f_{xx}(x_0, y_0) < 0$, then the function $f$ has a local maximum at $(x_0, y_0)$. The condition for a local minimum is $D > 0$ and $f_{xx}(x_0, y_0) > 0$. For example, consider $f(x, y) = -x^2 - y^2$ at $(0, 0)$. Here, $f_{xx}(0, 0) = -2$, $f_{yy}(0, 0) = -2$, and $f_{xy}(0, 0) = 0$. Thus, $D = (-2)(-2) - 0^2 = 4 > 0$ and $f_{xx}(0, 0) < 0$, indicating a local maximum, not a minimum."
            },
            {
                "question": "According to the Extreme Value Theorem, a continuous function defined on an open and unbounded set in the plane will always attain an absolute maximum and minimum value.",
                "answer": "False",
                "explanation": "The Extreme Value Theorem states that a continuous function $f(x,y)$ on a closed and bounded set $D$ in the plane attains an absolute maximum value at some point of $D$ and an absolute minimum value at some point of $D$. The key concepts here are 'closed' and 'bounded'. A set is closed if it contains all its boundary points, and it is bounded if it can be enclosed within a finite region. For example, the interval $[0,1]$ is closed and bounded, so a continuous function on this interval will have a maximum and minimum. However, an open set like $(0,1)$ or an unbounded set like $(-\\infty, \\infty)$ does not guarantee the existence of such extrema. For instance, the function $f(x) = x$ on $(-\\infty, \\infty)$ does not have a maximum or minimum."
            },
            {
                "question": "For a differentiable function $z = f(x, y)$ defined on a closed, bounded set $D$, the absolute maximum and minimum values of $f$ can only be found at the critical points of $f$ within $D$.",
                "answer": "False",
                "explanation": "The absolute maximum and minimum values of a differentiable function $z = f(x, y)$ defined on a closed, bounded set $D$ can be found either at the critical points of $f$ within $D$ or on the boundary of $D$. Critical points are where the partial derivatives of $f$ with respect to $x$ and $y$ are zero, indicating potential local maxima, minima, or saddle points. However, the boundary of $D$ must also be checked because the extreme values could occur there. For example, if $f(x, y) = x^2 + y^2$ on the set $D$ defined by $x^2 + y^2 \\leq 1$, the minimum value is at the critical point $(0,0)$, but the maximum value occurs on the boundary where $x^2 + y^2 = 1$."
            }
        ],
        "4-4-tangent-planes-and-linear-approximations": [
            {
                "question": "If the tangent lines to all curves passing through a point $P_0$ on a surface $S$ lie in the same plane, then this plane is called the tangent plane to $S$ at $P_0$.",
                "answer": "True",
                "explanation": "The tangent plane to a surface $S$ at a point $P_0 = (x_0, y_0, z_0)$ is defined as the plane in which the tangent lines to all curves passing through $P_0$ and lying entirely in $S$ reside. This means that if you take any curve $C$ on the surface $S$ that passes through $P_0$, the tangent line to this curve at $P_0$ will lie in the tangent plane. For example, consider a sphere with a point $P_0$ on its surface. Any curve on the sphere passing through $P_0$ will have its tangent line at $P_0$ lying in the plane that is tangent to the sphere at $P_0$. This plane is the tangent plane to the sphere at $P_0$."
            },
            {
                "question": "The equation of the tangent plane to a surface defined by a differentiable function $z=f(x,y)$ at a point $P_0=(x_0,y_0)$ is given by $z=f(x_0,y_0)+f_x(x_0,y_0)(x-x_0)+f_y(x_0,y_0)(y-y_0)$.",
                "answer": "True",
                "explanation": "The equation of the tangent plane to a surface $S$ defined by a differentiable function $z=f(x,y)$ at a point $P_0=(x_0,y_0)$ is indeed given by $z=f(x_0,y_0)+f_x(x_0,y_0)(x-x_0)+f_y(x_0,y_0)(y-y_0)$. This formula is derived from the linear approximation of the function $f(x,y)$ at the point $(x_0,y_0)$. Here, $f_x(x_0,y_0)$ and $f_y(x_0,y_0)$ are the partial derivatives of $f$ with respect to $x$ and $y$ at $(x_0,y_0)$, respectively. These partial derivatives represent the slopes of the tangent plane in the $x$ and $y$ directions. For example, if $f(x,y) = x^2 + y^2$ and $P_0 = (1,1)$, then $f_x(1,1) = 2$ and $f_y(1,1) = 2$, so the equation of the tangent plane at $(1,1)$ is $z = 2 + 2(x-1) + 2(y-1) = 2x + 2y - 2$."
            },
            {
                "question": "The linear approximation of a function $z = f(x, y)$ at the point $(x_0, y_0)$, given that the partial derivatives $f_x$ and $f_y$ are continuous at $(x_0, y_0)$, is $L(x, y) = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0)$.",
                "answer": "True",
                "explanation": "The linear approximation (or linearization) of a function $z = f(x, y)$ at a point $(x_0, y_0)$ is a method to approximate the function near that point using a linear function. This approximation is given by $L(x, y) = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0)$, where $f_x$ and $f_y$ are the partial derivatives of $f$ with respect to $x$ and $y$, respectively. These partial derivatives must be continuous at $(x_0, y_0)$ for the approximation to be valid. For example, if $f(x, y) = x^2 + y^2$ and we want to approximate it at $(1, 1)$, we find $f_x(1, 1) = 2$, $f_y(1, 1) = 2$, and $f(1, 1) = 2$. Thus, the linear approximation is $L(x, y) = 2 + 2(x - 1) + 2(y - 1) = 2x + 2y - 2$."
            },
            {
                "question": "A function $f(x,y)$ is differentiable at a point $P(x_0,y_0)$ if, for all points $(x,y)$ in a $\\delta$ disk around $P$, we can write $f(x,y) = f(x_0,y_0) + f_x(x_0,y_0)(x - x_0) + f_y(x_0,y_0)(y - y_0) + E(x,y)$, where the error term $E(x,y)$ satisfies $\\lim_{(x,y) \\to (x_0,y_0)} \\frac{E(x,y)}{(x - x_0)^2 + (y - y_0)^2} = 0$.",
                "answer": "True",
                "explanation": "The definition of differentiability for a function $f(x,y)$ at a point $P(x_0,y_0)$ requires that the function can be approximated by a linear function plus an error term $E(x,y)$ that becomes negligible as $(x,y)$ approaches $(x_0,y_0)$. Specifically, $f(x,y)$ can be expressed as $f(x_0,y_0) + f_x(x_0,y_0)(x - x_0) + f_y(x_0,y_0)(y - y_0) + E(x,y)$, where $E(x,y)$ satisfies $\\lim_{(x,y) \\to (x_0,y_0)} \\frac{E(x,y)}{(x - x_0)^2 + (y - y_0)^2} = 0$. This condition ensures that the error term $E(x,y)$ becomes insignificant compared to the linear terms as $(x,y)$ gets closer to $(x_0,y_0)$. For example, if $E(x,y) = (x - x_0)^2 + (y - y_0)^2$, then $\\frac{E(x,y)}{(x - x_0)^2 + (y - y_0)^2} = 1$, which does not approach 0. However, if $E(x,y) = (x - x_0)^3 + (y - y_0)^3$, then $\\frac{E(x,y)}{(x - x_0)^2 + (y - y_0)^2}$ approaches 0 as $(x,y)$ approaches $(x_0,y_0)$, satisfying the condition for differentiability."
            },
            {
                "question": "If a function $z = f(x, y)$ is differentiable at a point $(x_0, y_0)$, then it must also be continuous at that point.",
                "answer": "True",
                "explanation": "Differentiability at a point $(x_0, y_0)$ implies that the function $f(x, y)$ can be well-approximated by a linear function near $(x_0, y_0)$. This linear approximation requires that the function does not have any abrupt changes or discontinuities at $(x_0, y_0)$. Therefore, if $f(x, y)$ is differentiable at $(x_0, y_0)$, it must also be continuous at that point. For example, consider the function $f(x, y) = x^2 + y^2$. This function is differentiable everywhere, and hence it is also continuous everywhere."
            },
            {
                "question": "If a function $f(x,y)$ has continuous first partial derivatives $f_x(x,y)$ and $f_y(x,y)$ at a point $(x_0, y_0)$, then $f(x,y)$ is differentiable at $(x_0, y_0)$.",
                "answer": "True",
                "explanation": "The statement is true because the continuity of the first partial derivatives $f_x$ and $f_y$ at a point $(x_0, y_0)$ implies that the function $f(x,y)$ is differentiable at that point. Differentiability at a point means that the function can be well-approximated by a linear function at that point. For example, if $f(x,y) = x^2 + y^2$, the partial derivatives $f_x = 2x$ and $f_y = 2y$ are continuous everywhere, thus $f(x,y)$ is differentiable everywhere. This is a direct application of the theorem that states the continuity of first partials implies differentiability."
            },
            {
                "question": "If a function $z = f(x, y)$ is differentiable at the point $(x_0, y_0)$, then the total differential $dz$ at $(x_0, y_0)$ can be expressed as $dz = f_x(x_0, y_0) \\Delta x + f_y(x_0, y_0) \\Delta y$ where $dx = \\Delta x$ and $dy = \\Delta y$.",
                "answer": "False",
                "explanation": "The correct expression for the total differential $dz$ at $(x_0, y_0)$ is $dz = f_x(x_0, y_0) dx + f_y(x_0, y_0) dy$, where $dx = \\Delta x$ and $dy = \\Delta y$. The given statement incorrectly uses $\\Delta x$ and $\\Delta y$ directly in the expression for $dz$ instead of $dx$ and $dy$. For example, if $f(x, y) = x^2 + y^2$ and $(x_0, y_0) = (1, 1)$, then $f_x(1, 1) = 2$ and $f_y(1, 1) = 2$. The total differential $dz$ would be $dz = 2 dx + 2 dy$, not $dz = 2 \\Delta x + 2 \\Delta y$."
            },
            {
                "question": "A function $f(x,y,z)$ is differentiable at a point $P(x_0,y_0,z_0)$ if it can be expressed as $f(x,y,z) = f(x_0,y_0,z_0) + f_x(x_0,y_0,z_0)(x - x_0) + f_y(x_0,y_0,z_0)(y - y_0) + f_z(x_0,y_0,z_0)(z - z_0) + E(x,y,z)$, where the error term $E(x,y,z)$ satisfies $\\lim_{(x,y,z) \\to (x_0,y_0,z_0)} \\frac{E(x,y,z)}{(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2} = 0$.",
                "answer": "True",
                "explanation": "The definition of differentiability for a function $f(x,y,z)$ at a point $P(x_0,y_0,z_0)$ requires that $f(x,y,z)$ can be approximated by a linear function plus an error term $E(x,y,z)$ that becomes negligible faster than the square of the distance from $(x,y,z)$ to $(x_0,y_0,z_0)$. Specifically, the error term $E(x,y,z)$ must satisfy $\\lim_{(x,y,z) \\to (x_0,y_0,z_0)} \\frac{E(x,y,z)}{(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2} = 0$. This ensures that the linear approximation accurately represents the function near the point $P$. For example, if $f(x,y,z) = x^2 + y^2 + z^2$, then at $P(0,0,0)$, the function can be approximated as $f(x,y,z) \\approx 0 + 0(x - 0) + 0(y - 0) + 0(z - 0) + E(x,y,z)$, where $E(x,y,z) = x^2 + y^2 + z^2$ satisfies the required limit condition."
            }
        ],
        "4-5-the-chain-rule": [
            {
                "question": "If $x = g(t)$ and $y = h(t)$ are differentiable functions of $t$, and $z = f(x, y)$ is a differentiable function of $x$ and $y$, then $z = f(x(t), y(t))$ is a differentiable function of $t$ and $\\frac{dz}{dt} = \\frac{\\partial z}{\\partial x} \\cdot \\frac{dx}{dt} + \\frac{\\partial z}{\\partial y} \\cdot \\frac{dy}{dt}$.",
                "answer": "True",
                "explanation": "The Chain Rule for one independent variable states that if $x = g(t)$ and $y = h(t)$ are differentiable functions of $t$, and $z = f(x, y)$ is a differentiable function of $x$ and $y$, then $z = f(x(t), y(t))$ is a differentiable function of $t$. The derivative of $z$ with respect to $t$ can be found using the chain rule: $\\frac{dz}{dt} = \\frac{\\partial z}{\\partial x} \\cdot \\frac{dx}{dt} + \\frac{\\partial z}{\\partial y} \\cdot \\frac{dy}{dt}$. This formula combines the partial derivatives of $z$ with respect to $x$ and $y$ with the ordinary derivatives of $x$ and $y$ with respect to $t$. For example, if $x = t^2$, $y = \\sin(t)$, and $z = x + y$, then $\\frac{\\partial z}{\\partial x} = 1$, $\\frac{\\partial z}{\\partial y} = 1$, $\\frac{dx}{dt} = 2t$, and $\\frac{dy}{dt} = \\cos(t)$. Thus, $\\frac{dz}{dt} = 1 \\cdot 2t + 1 \\cdot \\cos(t) = 2t + \\cos(t)$."
            },
            {
                "question": "If $x = g(u,v)$ and $y = h(u,v)$ are differentiable functions of $u$ and $v$, and $z = f(x,y)$ is a differentiable function of $x$ and $y$, then $z = f(g(u,v), h(u,v))$ is a differentiable function of $u$ and $v$, and the partial derivatives of $z$ with respect to $u$ and $v$ are given by $\\frac{\\partial z}{\\partial u} = \\frac{\\partial z}{\\partial x} \\frac{\\partial x}{\\partial u} + \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial u}$ and $\\frac{\\partial z}{\\partial v} = \\frac{\\partial z}{\\partial x} \\frac{\\partial x}{\\partial v} + \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial v}$.",
                "answer": "True",
                "explanation": "The Chain Rule for functions of two independent variables states that if $x = g(u,v)$ and $y = h(u,v)$ are differentiable functions of $u$ and $v$, and $z = f(x,y)$ is a differentiable function of $x$ and $y$, then $z = f(g(u,v), h(u,v))$ is a differentiable function of $u$ and $v$. The partial derivatives of $z$ with respect to $u$ and $v$ can be found using the chain rule: $\\frac{\\partial z}{\\partial u} = \\frac{\\partial z}{\\partial x} \\frac{\\partial x}{\\partial u} + \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial u}$ and $\\frac{\\partial z}{\\partial v} = \\frac{\\partial z}{\\partial x} \\frac{\\partial x}{\\partial v} + \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial v}$. For example, if $x = u^2 + v$ and $y = uv$, and $z = x + y$, then $\\frac{\\partial z}{\\partial u} = 1 \\cdot 2u + 1 \\cdot v = 2u + v$ and $\\frac{\\partial z}{\\partial v} = 1 \\cdot 1 + 1 \\cdot u = 1 + u$."
            },
            {
                "question": "The Generalized Chain Rule states that if $w = f(x_1, x_2, \\ldots, x_m)$ is a differentiable function of $m$ independent variables, and each $x_i = x_i(t_1, t_2, \\ldots, t_n)$ is a differentiable function of $n$ independent variables, then the partial derivative of $w$ with respect to $t_j$ is given by $\\frac{\\partial w}{\\partial t_j} = \\frac{\\partial w}{\\partial x_1} \\frac{\\partial x_1}{\\partial t_j} + \\frac{\\partial w}{\\partial x_2} \\frac{\\partial x_2}{\\partial t_j} + \\cdots + \\frac{\\partial w}{\\partial x_m} \\frac{\\partial x_m}{\\partial t_j}$ for any $j \\in \\{1, 2, \\ldots, n\\}$.",
                "answer": "True",
                "explanation": "The Generalized Chain Rule allows us to compute the derivative of a composite function. Here, $w$ is a function of $m$ variables $x_1, x_2, \\ldots, x_m$, each of which is a function of $n$ variables $t_1, t_2, \\ldots, t_n$. The rule states that to find the partial derivative of $w$ with respect to $t_j$, we sum the products of the partial derivatives of $w$ with respect to each $x_i$ and the partial derivatives of each $x_i$ with respect to $t_j$. For example, if $w = f(x_1, x_2)$ and $x_1 = g(t_1, t_2)$, $x_2 = h(t_1, t_2)$, then $\\frac{\\partial w}{\\partial t_1} = \\frac{\\partial w}{\\partial x_1} \\frac{\\partial x_1}{\\partial t_1} + \\frac{\\partial w}{\\partial x_2} \\frac{\\partial x_2}{\\partial t_1}$. This illustrates how changes in $t_1$ affect $w$ through both $x_1$ and $x_2$."
            },
            {
                "question": "If the function $f(x, y) = 0$ implicitly defines $y$ as a function of $x$, then the derivative $\\frac{dy}{dx}$ can be found using $\\frac{dy}{dx} = -\\frac{\\partial f / \\partial x}{\\partial f / \\partial y}$, provided $\\frac{\\partial f}{\\partial y} \\neq 0$.",
                "answer": "True",
                "explanation": "Implicit differentiation is used when a function is defined implicitly rather than explicitly. For a function $f(x, y) = 0$ that implicitly defines $y$ as a function of $x$, the derivative $\\frac{dy}{dx}$ can be found using the formula $\\frac{dy}{dx} = -\\frac{\\partial f / \\partial x}{\\partial f / \\partial y}$. This formula is valid as long as $\\frac{\\partial f}{\\partial y} \\neq 0$, ensuring that $y$ can be differentiated with respect to $x$. For example, if $f(x, y) = x^2 + y^2 - 1$, then $\\frac{\\partial f}{\\partial x} = 2x$ and $\\frac{\\partial f}{\\partial y} = 2y$. Thus, $\\frac{dy}{dx} = -\\frac{2x}{2y} = -\\frac{x}{y}$, provided $y \\neq 0$."
            }
        ],
        "4-1-functions-of-several-variables": [
            {
                "question": "The domain of a function $z = f(x, y)$ is the set of all real numbers $z$ that the function can output.",
                "answer": "False",
                "explanation": "The domain of a function $z = f(x, y)$ is the set of all ordered pairs $(x, y)$ in a subset $D$ of the real plane $\\mathbb{R}^2$ for which the function is defined. The range of the function is the set of all real numbers $z$ that the function can output. For example, if $f(x, y) = x^2 + y^2$, the domain could be all $(x, y) \\in \\mathbb{R}^2$, and the range would be all $z \\geq 0$ since $x^2 + y^2$ is always non-negative."
            },
            {
                "question": "A level curve of a function $f(x,y)$ for a value $c$ is the set of points $(x,y)$ that satisfy the equation $f(x,y) = c$.",
                "answer": "True",
                "explanation": "A level curve of a function $f(x,y)$ for a given value $c$ is defined as the set of all points $(x,y)$ such that $f(x,y) = c$. This means that for each point on the level curve, the function $f$ evaluates to the constant value $c$. For example, if $f(x,y) = x^2 + y^2$ and $c = 1$, the level curve is the set of points $(x,y)$ such that $x^2 + y^2 = 1$, which represents a circle with radius 1 centered at the origin."
            },
            {
                "question": "A vertical trace of the function $z = f(x, y)$ can be obtained by fixing either $x = a$ or $y = b$ and solving for $z$.",
                "answer": "True",
                "explanation": "A vertical trace of the function $z = f(x, y)$ is defined as the set of points that solve the equation $f(a, y) = z$ for a given constant $x = a$ or $f(x, b) = z$ for a given constant $y = b$. This means that by fixing either $x$ or $y$ and solving for $z$, we obtain a vertical trace. For example, if we fix $x = 2$, then the vertical trace is given by $z = f(2, y)$. Similarly, if we fix $y = 3$, the vertical trace is given by $z = f(x, 3)$. Both methods yield a set of points that represent the vertical trace of the function."
            },
            {
                "question": "A level surface of a function $f(x,y,z)$ is the set of points $(x,y,z)$ that satisfy the equation $f(x,y,z) = c$ for some constant $c$ within the range of $f$.",
                "answer": "True",
                "explanation": "A level surface is defined as the set of points $(x,y,z)$ that satisfy the equation $f(x,y,z) = c$, where $c$ is a constant within the range of the function $f$. This means that for any point on the level surface, the function $f$ evaluates to the same constant value $c$. For example, if $f(x,y,z) = x^2 + y^2 + z^2$ and $c = 1$, the level surface would be the set of points $(x,y,z)$ such that $x^2 + y^2 + z^2 = 1$, which describes a sphere of radius 1 centered at the origin."
            }
        ],
        "4-8-lagrange-multipliers": [
            {
                "question": "If a function $f(x, y)$ has a local extremum at the point $(x_0, y_0)$ on the curve defined by $g(x, y) = 0$, and $\\nabla g(x_0, y_0) \\neq 0$, then there exists a Lagrange multiplier $\\lambda$ such that $\\nabla f(x_0, y_0) = \\lambda \\nabla g(x_0, y_0)$.",
                "answer": "True",
                "explanation": "The method of Lagrange multipliers is used to find local extrema of a function $f(x, y)$ subject to a constraint $g(x, y) = 0$. If $f$ has a local extremum at $(x_0, y_0)$ on the curve $g(x, y) = 0$ and $\\nabla g(x_0, y_0) \\neq 0$, then there exists a scalar $\\lambda$ (the Lagrange multiplier) such that $\\nabla f(x_0, y_0) = \\lambda \\nabla g(x_0, y_0)$. This condition ensures that the gradients of $f$ and $g$ are parallel at the extremum point, indicating that the direction of the steepest ascent of $f$ is constrained by $g$. For example, if $f(x, y) = x^2 + y^2$ and $g(x, y) = x + y - 1$, at the extremum point $(x_0, y_0)$ on the curve $x + y = 1$, the gradients $\\nabla f$ and $\\nabla g$ must be parallel, confirming the existence of $\\lambda$ such that $\\nabla f = \\lambda \\nabla g$."
            }
        ]
    },
    "Vector-Valued Functions": {
        "3-1-vector-valued-functions-and-space-curves": [
            {
                "question": "A vector-valued function can be represented as $r(t) = \\langle f(t), g(t) \\rangle$ for a two-dimensional vector or $r(t) = \\langle f(t), g(t), h(t) \\rangle$ for a three-dimensional vector, where $f(t)$, $g(t)$, and $h(t)$ are real-valued functions of the parameter $t$.",
                "answer": "True",
                "explanation": "A vector-valued function is a function where each component is a real-valued function of a parameter $t$. For a two-dimensional vector-valued function, it can be written as $r(t) = f(t)i + g(t)j$ or equivalently $r(t) = \\langle f(t), g(t) \\rangle$. For a three-dimensional vector-valued function, it can be written as $r(t) = f(t)i + g(t)j + h(t)k$ or equivalently $r(t) = \\langle f(t), g(t), h(t) \\rangle$. For example, if $f(t) = t$, $g(t) = t^2$, and $h(t) = t^3$, then $r(t) = \\langle t, t^2, t^3 \\rangle$ is a three-dimensional vector-valued function."
            },
            {
                "question": "For a vector-valued function $\\mathbf{r}(t)$ to approach the limit $\\mathbf{L}$ as $t$ approaches $a$, it is necessary that $\\lim_{t \\to a} \\| \\mathbf{r}(t) - \\mathbf{L} \\| = 0$.",
                "answer": "True",
                "explanation": "The definition states that $\\lim_{t \\to a} \\mathbf{r}(t) = \\mathbf{L}$ if and only if $\\lim_{t \\to a} \\| \\mathbf{r}(t) - \\mathbf{L} \\| = 0$. This means that the distance between $\\mathbf{r}(t)$ and $\\mathbf{L}$ must approach zero as $t$ approaches $a$. For example, if $\\mathbf{r}(t) = \\langle t, t^2 \\rangle$ and $\\mathbf{L} = \\langle 1, 1 \\rangle$, then $\\| \\mathbf{r}(t) - \\mathbf{L} \\| = \\sqrt{(t-1)^2 + (t^2-1)^2}$. As $t$ approaches 1, this distance approaches 0, satisfying the condition."
            },
            {
                "question": "The limit of a vector-valued function $\\mathbf{r}(t) = f(t)\\mathbf{i} + g(t)\\mathbf{j} + h(t)\\mathbf{k}$ as $t$ approaches $a$ is given by $\\lim_{t \\to a} \\mathbf{r}(t) = [\\lim_{t \\to a} f(t)]\\mathbf{i} + [\\lim_{t \\to a} g(t)]\\mathbf{j} + [\\lim_{t \\to a} h(t)]\\mathbf{k}$, provided the limits $\\lim_{t \\to a} f(t)$, $\\lim_{t \\to a} g(t)$, and $\\lim_{t \\to a} h(t)$ exist.",
                "answer": "True",
                "explanation": "The limit of a vector-valued function $\\mathbf{r}(t) = f(t)\\mathbf{i} + g(t)\\mathbf{j} + h(t)\\mathbf{k}$ as $t$ approaches $a$ is indeed given by $\\lim_{t \\to a} \\mathbf{r}(t) = [\\lim_{t \\to a} f(t)]\\mathbf{i} + [\\lim_{t \\to a} g(t)]\\mathbf{j} + [\\lim_{t \\to a} h(t)]\\mathbf{k}$, provided the individual limits $\\lim_{t \\to a} f(t)$, $\\lim_{t \\to a} g(t)$, and $\\lim_{t \\to a} h(t)$ exist. This is because the limit of a vector-valued function is determined component-wise. For example, if $\\mathbf{r}(t) = (t^2)\\mathbf{i} + (\\sin(t))\\mathbf{j} + (\\frac{1}{t})\\mathbf{k}$, as $t$ approaches 1, the limits of the components are $\\lim_{t \\to 1} t^2 = 1$, $\\lim_{t \\to 1} \\sin(t) = \\sin(1)$, and $\\lim_{t \\to 1} \\frac{1}{t} = 1$. Therefore, $\\lim_{t \\to 1} \\mathbf{r}(t) = 1\\mathbf{i} + \\sin(1)\\mathbf{j} + 1\\mathbf{k}$."
            },
            {
                "question": "For a vector-valued function $\\mathbf{r}(t) = f(t)\\mathbf{i} + g(t)\\mathbf{j} + h(t)\\mathbf{k}$ to be continuous at $t = a$, it is sufficient that $f(t)$, $g(t)$, and $h(t)$ are continuous at $t = a$.",
                "answer": "True",
                "explanation": "For the vector-valued function $\\mathbf{r}(t) = f(t)\\mathbf{i} + g(t)\\mathbf{j} + h(t)\\mathbf{k}$ to be continuous at $t = a$, the following conditions must hold: 1) $\\mathbf{r}(a)$ exists, 2) $\\lim_{t \\to a} \\mathbf{r}(t)$ exists, and 3) $\\lim_{t \\to a} \\mathbf{r}(t) = \\mathbf{r}(a)$. Since $\\mathbf{r}(t)$ is composed of the component functions $f(t)$, $g(t)$, and $h(t)$, the continuity of $\\mathbf{r}(t)$ at $t = a$ depends on the continuity of these component functions at $t = a$. If $f(t)$, $g(t)$, and $h(t)$ are continuous at $t = a$, then $\\mathbf{r}(t)$ will also be continuous at $t = a$. For example, if $f(t) = t$, $g(t) = t^2$, and $h(t) = \\sin(t)$, all these functions are continuous at any point $t = a$, thus making $\\mathbf{r}(t)$ continuous at $t = a$."
            }
        ],
        "3-3-arc-length-and-curvature": [
            {
                "question": "The arc length of a smooth plane curve defined by $r(t) = f(t)i + g(t)j$ over the interval $[a, b]$ can be calculated using the formula $s = \\int_a^b \\sqrt{[f'(t)]^2 + [g'(t)]^2} \\, dt$.",
                "answer": "True",
                "explanation": "The arc length of a smooth plane curve $C$ defined by $r(t) = f(t)i + g(t)j$ over the interval $[a, b]$ is given by the integral $s = \\int_a^b \\sqrt{[f'(t)]^2 + [g'(t)]^2} \\, dt$. This formula is derived from the Pythagorean theorem applied to the infinitesimal segments of the curve. For example, if $r(t) = t i + t^2 j$, then $f(t) = t$ and $g(t) = t^2$, and the arc length from $t = 0$ to $t = 1$ would be $s = \\int_0^1 \\sqrt{1 + 4t^2} \\, dt$."
            },
            {
                "question": "If the magnitude of the derivative of a smooth curve $r(t)$, denoted as $\\Vert r'(t) \\Vert$, is equal to 1 for all $t \\geq a$, then the parameter $t$ represents the arc length from the starting point at $t = a$.",
                "answer": "True",
                "explanation": "The arc-length function $s(t)$ for a smooth curve $r(t)$ is given by $s(t) = \\int_a^t \\Vert r'(u) \\Vert du$. If $\\Vert r'(t) \\Vert = 1$ for all $t \\geq a$, then $ds/dt = \\Vert r'(t) \\Vert = 1$. This implies that the rate of change of the arc length with respect to $t$ is constant and equal to 1. Therefore, the arc length $s(t)$ from the starting point at $t = a$ is simply $t - a$, meaning $t$ directly represents the arc length from $t = a$. For example, if $t = a + 5$, the arc length from $t = a$ is 5 units."
            },
            {
                "question": "The curvature $\\kappa$ of a smooth curve $C$ parameterized by arc-length $s$ is given by the magnitude of the derivative of the unit tangent vector $T(s)$ with respect to $s$, i.e., $\\kappa = \\Vert T'(s) \\Vert$.",
                "answer": "True",
                "explanation": "The curvature $\\kappa$ of a smooth curve $C$ parameterized by the arc-length $s$ is indeed defined as the magnitude of the derivative of the unit tangent vector $T(s)$ with respect to $s$. This means that $\\kappa = \\Vert T'(s) \\Vert$. The unit tangent vector $T(s)$ describes the direction of the curve at each point, and its derivative $T'(s)$ indicates how this direction changes as one moves along the curve. The magnitude of this derivative, $\\Vert T'(s) \\Vert$, quantifies the rate of change of the direction, which is precisely the curvature. For example, for a circle of radius $r$, the curvature is constant and equal to $1/r$, reflecting the constant rate of change of the direction of the tangent vector as one moves along the circle."
            },
            {
                "question": "For a smooth curve given by $r(t)$, the curvature $\\kappa$ at $t$ can be expressed as $\\kappa = \\Vert T'(t) \\Vert \\Vert r'(t) \\Vert$.",
                "answer": "True",
                "explanation": "The curvature $\\kappa$ of a smooth curve $C$ given by $r(t)$ can indeed be expressed as $\\kappa = \\Vert T'(t) \\Vert \\Vert r'(t) \\Vert$. Here, $T(t)$ is the unit tangent vector to the curve at $t$, and $T'(t)$ is its derivative with respect to $t$. The magnitude of $T'(t)$ gives the rate of change of the tangent vector, and multiplying it by the magnitude of $r'(t)$ (the speed of the curve) gives the curvature. For example, if $r(t)$ represents a circle of radius $R$, then $\\kappa = \\frac{1}{R}$, which can be derived using this formula."
            },
            {
                "question": "The principal unit normal vector $N(t)$ is defined as the normalized derivative of the unit tangent vector $T(t)$, and the binormal vector $B(t)$ is the cross product of $T(t)$ and $N(t)$.",
                "answer": "True",
                "explanation": "The principal unit normal vector $N(t)$ is indeed defined as $N(t) = \\frac{T'(t)}{\\Vert T'(t) \\Vert}$, which means it is the normalized derivative of the unit tangent vector $T(t)$. The binormal vector $B(t)$ is defined as $B(t) = T(t) \\times N(t)$, which is the cross product of the unit tangent vector $T(t)$ and the principal unit normal vector $N(t)$. For example, if $T(t)$ is a unit tangent vector at a point on a curve, then $T'(t)$ gives the rate of change of $T(t)$, and normalizing $T'(t)$ gives $N(t)$. The binormal vector $B(t)$ is orthogonal to both $T(t)$ and $N(t)$, providing a complete orthonormal basis for the space at that point on the curve."
            }
        ],
        "3-2-calculus-of-vector-valued-functions": [
            {
                "question": "For a vector-valued function $r(t)$ to be differentiable over a closed interval $[a,b]$, it is sufficient for the derivative $r'(t)$ to exist for all $t$ in the open interval $(a,b)$.",
                "answer": "False",
                "explanation": "For a vector-valued function $r(t)$ to be differentiable over a closed interval $[a,b]$, it is not sufficient for the derivative $r'(t)$ to exist only for all $t$ in the open interval $(a,b)$. The limits defining the derivatives at the endpoints must also exist. Specifically, $r'(a) = \\lim_{\\Delta t \\to 0^+} \\frac{r(a + \\Delta t) - r(a)}{\\Delta t}$ and $r'(b) = \\lim_{\\Delta t \\to 0^-} \\frac{r(b + \\Delta t) - r(b)}{\\Delta t}$ must exist. This ensures that the function is differentiable at the endpoints $a$ and $b$ as well."
            },
            {
                "question": "If $r(t) = f(t)i + g(t)j + h(t)k$, then the derivative $r'(t)$ is given by $r'(t) = f'(t)i + g'(t)j + h'(t)k$.",
                "answer": "True",
                "explanation": "The differentiation of vector-valued functions follows the rule that the derivative of each component function is taken separately. For a vector-valued function $r(t) = f(t)i + g(t)j + h(t)k$, the derivative $r'(t)$ is obtained by differentiating each component function with respect to $t$. Thus, $r'(t) = f'(t)i + g'(t)j + h'(t)k$. For example, if $r(t) = t^2i + \\sin(t)j + e^t k$, then $r'(t) = 2ti + \\cos(t)j + e^t k$."
            },
            {
                "question": "If $r(t) \\cdot r(t) = c$, where $r$ is a differentiable vector-valued function of $t$ and $c$ is a constant, then $r(t) \\cdot r'(t) = 0$.",
                "answer": "True",
                "explanation": "Given $r(t) \\cdot r(t) = c$, we differentiate both sides with respect to $t$. Using the product rule for dot products, we get $\\frac{d}{dt}[r(t) \\cdot r(t)] = r'(t) \\cdot r(t) + r(t) \\cdot r'(t)$. Since $c$ is a constant, its derivative is $0$. Therefore, $0 = r'(t) \\cdot r(t) + r(t) \\cdot r'(t)$. Simplifying, we get $0 = 2[r(t) \\cdot r'(t)]$, which implies $r(t) \\cdot r'(t) = 0$. This means the vector $r(t)$ is orthogonal to its derivative $r'(t)$. For example, if $r(t)$ represents the position vector of a particle moving on a circle, then $r(t) \\cdot r'(t) = 0$ indicates that the velocity vector is always perpendicular to the position vector."
            },
            {
                "question": "The principal unit tangent vector $T(t)$ at a point $t=t_0$ on a curve $C$ defined by a vector-valued function $r(t)$ is given by $T(t_0) = \\frac{r'(t_0)}{\\|r'(t_0)\\|}$, provided that $\\|r'(t_0)\\| \\neq 0$.",
                "answer": "True",
                "explanation": "The principal unit tangent vector $T(t)$ at a point $t=t_0$ on a curve $C$ is defined as $T(t) = \\frac{r'(t)}{\\|r'(t)\\|}$, provided that $\\|r'(t)\\| \\neq 0$. This definition ensures that $T(t)$ is a unit vector (i.e., it has a magnitude of 1) and is tangent to the curve at the point $r(t_0)$. For example, if $r(t) = \\langle t, t^2 \\rangle$, then $r'(t) = \\langle 1, 2t \\rangle$. At $t=1$, $r'(1) = \\langle 1, 2 \\rangle$ and $\\|r'(1)\\| = \\sqrt{1^2 + 2^2} = \\sqrt{5}$. Thus, $T(1) = \\frac{\\langle 1, 2 \\rangle}{\\sqrt{5}} = \\langle \\frac{1}{\\sqrt{5}}, \\frac{2}{\\sqrt{5}} \\rangle$."
            },
            {
                "question": "The definite integral of a vector-valued function $r(t) = f(t)i + g(t)j + h(t)k$ over the interval $[a, b]$ is given by $\\int_{a}^{b} [f(t)i + g(t)j + h(t)k] \\, dt = [\\int_{a}^{b} f(t) \\, dt]i + [\\int_{a}^{b} g(t) \\, dt]j + [\\int_{a}^{b} h(t) \\, dt]k$.",
                "answer": "True",
                "explanation": "The definite integral of a vector-valued function $r(t) = f(t)i + g(t)j + h(t)k$ over the interval $[a, b]$ is computed by integrating each component function separately. This means $\\int_{a}^{b} [f(t)i + g(t)j + h(t)k] \\, dt$ is equal to $[\\int_{a}^{b} f(t) \\, dt]i + [\\int_{a}^{b} g(t) \\, dt]j + [\\int_{a}^{b} h(t) \\, dt]k$. For example, if $f(t) = t$, $g(t) = t^2$, and $h(t) = t^3$, then $\\int_{0}^{1} [t i + t^2 j + t^3 k] \\, dt = [\\int_{0}^{1} t \\, dt]i + [\\int_{0}^{1} t^2 \\, dt]j + [\\int_{0}^{1} t^3 \\, dt]k = \\left[ \\frac{1}{2} \\right]i + \\left[ \\frac{1}{3} \\right]j + \\left[ \\frac{1}{4} \\right]k$."
            }
        ],
        "3-4-motion-in-space": [
            {
                "question": "If $r(t)$ is a twice-differentiable vector-valued function representing the position of an object as a function of time, then the speed of the object is given by the magnitude of the first derivative of $r(t)$ with respect to time.",
                "answer": "True",
                "explanation": "The speed of an object is defined as the magnitude of its velocity vector. Given that the velocity vector $v(t)$ is the first derivative of the position vector $r(t)$ with respect to time, i.e., $v(t) = r'(t)$, the speed is the magnitude of this velocity vector. Mathematically, this is expressed as $ \\text{Speed} = \\|v(t)\\| = \\|r'(t)\\| $. For example, if $r(t) = \\langle t, t^2, t^3 \\rangle$, then $r'(t) = \\langle 1, 2t, 3t^2 \\rangle$ and the speed is $\\|r'(t)\\| = \\sqrt{1 + 4t^2 + 9t^4}$."
            },
            {
                "question": "The acceleration vector $a(t)$ of an object moving along a curve $C$ traced out by a twice-differentiable function $r(t)$ always lies in the plane formed by the unit tangent vector $T(t)$ and the principal unit normal vector $N(t)$ to $C$.",
                "answer": "True",
                "explanation": "The acceleration vector $a(t)$ of an object moving along a curve $C$ can be expressed as $a(t) = v'(t)T(t) + [v(t)]^2 \\kappa N(t)$, where $v(t)$ is the speed of the object and $\\kappa$ is the curvature of $C$. This expression shows that $a(t)$ is a linear combination of the unit tangent vector $T(t)$ and the principal unit normal vector $N(t)$. Since both $T(t)$ and $N(t)$ lie in the plane tangent to the curve at a given point, $a(t)$ must also lie in this plane. For example, if an object is moving along a circular path, the acceleration vector will have components in the direction of the tangent to the circle (due to changing speed) and towards the center of the circle (due to curvature), both of which lie in the plane of the circle."
            },
            {
                "question": "The tangential component of acceleration $a_T$ is given by the dot product of the velocity vector $v(t)$ and the acceleration vector $a(t)$ divided by the magnitude of the velocity vector $v(t)$.",
                "answer": "True",
                "explanation": "The tangential component of acceleration $a_T$ is indeed given by the formula $a_T = \\frac{v \\cdot a}{\\|v\\|}$. This formula represents the projection of the acceleration vector onto the direction of the velocity vector, which gives the rate of change of the speed of the object along its path. For example, if an object is moving in a straight line and speeding up, the tangential component of acceleration will be positive, indicating an increase in speed. Conversely, if the object is slowing down, the tangential component will be negative."
            },
            {
                "question": "According to Kepler's Laws of Planetary Motion, the path of any planet about the Sun is circular, with the center of the Sun located at the center of the circle.",
                "answer": "False",
                "explanation": "Kepler's First Law, also known as the law of ellipses, states that the path of any planet about the Sun is elliptical in shape, with the center of the Sun located at one focus of the ellipse. This means that the orbit is not a perfect circle but an ellipse, which is an elongated circle. For example, Earth's orbit around the Sun is slightly elliptical, not perfectly circular."
            }
        ]
    },
    "Multiple Integration": {
        "5-7-change-of-variables-in-multiple-integrals": [
            {
                "question": "A transformation $T: G \\rightarrow R$ defined as $T(u,v) = (x,y)$ is one-to-one if and only if for any two distinct points $(u_1, v_1)$ and $(u_2, v_2)$ in $G$, $T(u_1, v_1) \\neq T(u_2, v_2)$.",
                "answer": "True",
                "explanation": "A transformation $T: G \\rightarrow R$ is one-to-one if no two distinct points in the domain $G$ map to the same point in the range $R$. This means that if $(u_1, v_1) \\neq (u_2, v_2)$, then $T(u_1, v_1) \\neq T(u_2, v_2)$. For example, consider $T(u,v) = (u+1, v+1)$. If $(u_1, v_1) \\neq (u_2, v_2)$, then $(u_1+1, v_1+1) \\neq (u_2+1, v_2+1)$, ensuring that $T$ is one-to-one. Conversely, if $T(u_1, v_1) = T(u_2, v_2)$, then $(u_1, v_1)$ must equal $(u_2, v_2)$, which confirms the one-to-one nature of the transformation."
            },
            {
                "question": "The Jacobian determinant of the transformation $T(u,v) = (g(u,v), h(u,v))$ is given by $J(u,v) = \\left| \\frac{\\partial (x,y)}{\\partial (u,v)} \\right| = \\left| \\begin{array}{cc} \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\ \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v} \\end{array} \\right| = \\frac{\\partial x}{\\partial u} \\frac{\\partial y}{\\partial v} - \\frac{\\partial x}{\\partial v} \\frac{\\partial y}{\\partial u}$.",
                "answer": "True",
                "explanation": "The Jacobian determinant $J(u,v)$ of the transformation $T(u,v) = (g(u,v), h(u,v))$ is indeed defined as the determinant of the matrix formed by the partial derivatives of $x$ and $y$ with respect to $u$ and $v$. Specifically, $J(u,v) = \\left| \\frac{\\partial (x,y)}{\\partial (u,v)} \\right| = \\left| \\begin{array}{cc} \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\ \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v} \\end{array} \\right| = \\frac{\\partial x}{\\partial u} \\frac{\\partial y}{\\partial v} - \\frac{\\partial x}{\\partial v} \\frac{\\partial y}{\\partial u}$. This determinant measures how the area changes under the transformation $T$. For example, if $T$ maps a small rectangle in the $(u,v)$-plane to a parallelogram in the $(x,y)$-plane, the absolute value of the Jacobian determinant gives the area scaling factor of this transformation."
            },
            {
                "question": "The change of variables formula for double integrals states that if $T(u,v) = (x,y)$ is a one-to-one $C^1$ transformation with a nonzero Jacobian on the interior of the region $S$ in the $uv$-plane, mapping $S$ into the region $R$ in the $xy$-plane, then for a continuous function $f$ on $R$, the double integral over $R$ can be expressed as $\\iint_R f(x,y) \\, dA = \\iint_S f(g(u,v), h(u,v)) \\left| \\frac{\\partial(x,y)}{\\partial(u,v)} \\right| \\, du \\, dv$.",
                "answer": "True",
                "explanation": "The change of variables formula for double integrals allows us to transform an integral over a region $R$ in the $xy$-plane to an integral over a region $S$ in the $uv$-plane using a one-to-one $C^1$ transformation $T(u,v) = (x,y)$. The Jacobian determinant $\\left| \\frac{\\partial(x,y)}{\\partial(u,v)} \\right|$ accounts for the change in area element due to the transformation. For example, if $x = u^2$ and $y = v^2$, the Jacobian determinant would be $\\left| \\frac{\\partial(x,y)}{\\partial(u,v)} \\right| = 4uv$, and this factor would be included in the transformed integral."
            },
            {
                "question": "The Jacobian determinant $J(u,v,w)$ in three variables can be represented as $J(u,v,w) = \\left| \\begin{matrix} \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} & \\frac{\\partial x}{\\partial w} \\\\ \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v} & \\frac{\\partial y}{\\partial w} \\\\ \\frac{\\partial z}{\\partial u} & \\frac{\\partial z}{\\partial v} & \\frac{\\partial z}{\\partial w} \\end{matrix} \\right|$.",
                "answer": "True",
                "explanation": "The Jacobian determinant $J(u,v,w)$ in three variables is a measure of how a transformation from $(u,v,w)$ to $(x,y,z)$ changes volume. It is represented by the determinant of a $3 \\times 3$ matrix where each element is a partial derivative of the new variables $(x,y,z)$ with respect to the original variables $(u,v,w)$. Specifically, $J(u,v,w) = \\left| \\begin{matrix} \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} & \\frac{\\partial x}{\\partial w} \\\\ \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v} & \\frac{\\partial y}{\\partial w} \\\\ \\frac{\\partial z}{\\partial u} & \\frac{\\partial z}{\\partial v} & \\frac{\\partial z}{\\partial w} \\end{matrix} \\right|$. This determinant encapsulates how the transformation scales and skews the volume element in the new coordinate system. For example, if $u = x$, $v = y$, and $w = z$, then the Jacobian determinant would be 1, indicating no change in volume."
            },
            {
                "question": "The change of variables for triple integrals involves transforming a region G in uvw-space to a region R in xyz-space using a one-to-one $C^1$ transformation with a nonzero Jacobian, and the integral of a function F over R can be computed by integrating the transformed function over G multiplied by the absolute value of the Jacobian determinant.",
                "answer": "True",
                "explanation": "The change of variables for triple integrals allows us to transform the region of integration from one coordinate system to another. Given a one-to-one $C^1$ transformation $T(u,v,w) = (x,y,z)$ with a nonzero Jacobian determinant, the integral of a function $F$ over a region $R$ in $xyz$-space can be computed by integrating the transformed function $G(u,v,w) = F(g(u,v,w), h(u,v,w), k(u,v,w))$ over the region $G$ in $uvw$-space, multiplied by the absolute value of the Jacobian determinant $|J(u,v,w)|$. This is expressed mathematically as:  $$\\iiint_R F(x,y,z) \\, dV = \\iiint_G F(g(u,v,w), h(u,v,w), k(u,v,w)) \\left| \\frac{\\partial(x,y,z)}{\\partial(u,v,w)} \\right| \\, du \\, dv \\, dw.$$  For example, if we have a transformation $T(u,v,w) = (u^2, v^2, w^2)$, the Jacobian determinant would be computed and used to transform the integral from $uvw$-space to $xyz$-space accordingly."
            }
        ],
        "5-4-triple-integrals": [
            {
                "question": "The triple integral of a function $f(x,y,z)$ over a rectangular box $B$ can be approximated by summing the values of the function at specific points within sub-rectangles of $B$, multiplied by the volume of these sub-rectangles, and taking the limit as the number of sub-rectangles approaches infinity.",
                "answer": "True",
                "explanation": "The triple integral $\\iiint_B f(x,y,z) \\, dV$ represents the volume under the surface defined by $f(x,y,z)$ over the region $B$. This can be approximated by dividing $B$ into smaller sub-rectangles, evaluating $f$ at specific points $(x_{ijk}^*, y_{ijk}^*, z_{ijk}^*)$ within each sub-rectangle, and summing the products of these function values and the volumes of the sub-rectangles, $\\Delta x \\Delta y \\Delta z$. As the number of sub-rectangles increases (i.e., $l, m, n \\to \\infty$), this sum approaches the exact value of the triple integral, provided the limit exists. For example, if $B$ is a cube and $f(x,y,z) = x + y + z$, dividing $B$ into smaller cubes and summing the function values at the center of each small cube, multiplied by the volume of each small cube, will approximate the integral $\\iiint_B (x + y + z) \\, dV$."
            },
            {
                "question": "According to Fubini's Theorem for Triple Integrals, if $f(x,y,z)$ is continuous on a rectangular box $B=[a,b] \\times [c,d] \\times [e,f]$, then the triple integral $\\iiint_B f(x,y,z) \\, dV$ can be computed as an iterated integral in any order of integration.",
                "answer": "True",
                "explanation": "Fubini's Theorem for Triple Integrals states that if $f(x,y,z)$ is continuous on a rectangular box $B=[a,b] \\times [c,d] \\times [e,f]$, then the triple integral $\\iiint_B f(x,y,z) \\, dV$ can be computed as an iterated integral in any order. This means that the integral can be expressed as $\\int_e^f \\int_c^d \\int_a^b f(x,y,z) \\, dx \\, dy \\, dz$ or any of the other five possible orderings of integration. For example, it can also be written as $\\int_a^b \\int_c^d \\int_e^f f(x,y,z) \\, dz \\, dy \\, dx$. This flexibility in the order of integration is particularly useful in simplifying the computation of triple integrals."
            },
            {
                "question": "The triple integral of a continuous function $f(x,y,z)$ over a three-dimensional region $E = \\{(x,y,z) | (x,y) \\in D, u_1(x,y) \\leq z \\leq u_2(x,y)\\}$ in $\\mathbb{R}^3$, where $D$ is the projection of $E$ onto the $xy$-plane, can be expressed as $\\iiint_E f(x,y,z) \\, dV = \\iint_D \\left[ \\int_{u_1(x,y)}^{u_2(x,y)} f(x,y,z) \\, dz \\right] \\, dA$.",
                "answer": "True",
                "explanation": "The given statement is true. The triple integral of a continuous function $f(x,y,z)$ over a three-dimensional region $E$ can be computed by first integrating $f$ with respect to $z$ from $u_1(x,y)$ to $u_2(x,y)$, and then integrating the result over the projection $D$ of $E$ onto the $xy$-plane. This method leverages the concept of iterated integrals, where the integration is performed in stages. For example, if $E$ is a region bounded by $0 \\leq x \\leq 1$, $0 \\leq y \\leq 1$, and $0 \\leq z \\leq x+y$, then $D$ is the region $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$, and the triple integral can be computed as $\\iiint_E f(x,y,z) \\, dV = \\iint_D \\left[ \\int_0^{x+y} f(x,y,z) \\, dz \\right] \\, dA$."
            },
            {
                "question": "The average value of an integrable function $f(x,y,z)$ over a solid bounded region $E$ with positive volume $V(E)$ is given by $f_{ave} = \\frac{1}{V(E)} \\iiint_E f(x,y,z) \\, dV$, where $V(E) = \\iiint_E 1 \\, dV$.",
                "answer": "True",
                "explanation": "The average value of a function $f(x,y,z)$ over a region $E$ is calculated by integrating the function over the region and then dividing by the volume of the region. The volume $V(E)$ is found by integrating the constant function 1 over the region $E$. For example, if $E$ is a cube with side length 2, then $V(E) = \\iiint_E 1 \\, dV = 2^3 = 8$. If $f(x,y,z) = x + y + z$ over this cube, then $f_{ave} = \\frac{1}{8} \\iiint_E (x + y + z) \\, dV$."
            }
        ],
        "5-2-double-integrals-over-general-regions": [
            {
                "question": "A region $D$ in the $(x,y)$-plane is of Type I if it lies between two horizontal lines and the graphs of two continuous functions $g_1(x)$ and $g_2(x)$.",
                "answer": "False",
                "explanation": "A region $D$ in the $(x,y)$-plane is of Type I if it lies between two vertical lines and the graphs of two continuous functions $g_1(x)$ and $g_2(x)$. Specifically, it is defined as $D = \\{(x,y) | a \\leq x \\leq b, g_1(x) \\leq y \\leq g_2(x)\\}$. In contrast, a region $D$ is of Type II if it lies between two horizontal lines and the graphs of two continuous functions $h_1(y)$ and $h_2(y)$, defined as $D = \\{(x,y) | c \\leq y \\leq d, h_1(y) \\leq x \\leq h_2(y)\\}$. For example, if $g_1(x) = x^2$ and $g_2(x) = x + 2$, and the region is bounded by $x = 1$ and $x = 3$, then $D$ is of Type I. Conversely, if $h_1(y) = \\sqrt{y}$ and $h_2(y) = y + 1$, and the region is bounded by $y = 0$ and $y = 2$, then $D$ is of Type II."
            },
            {
                "question": "If $f(x,y)$ is an integrable function defined on a region $D$ inside a rectangle $R$, and $g(x,y)$ is the extension of $f(x,y)$ to the entire rectangle $R$, then the double integral of $f(x,y)$ over $D$ is equal to the double integral of $g(x,y)$ over $R$.",
                "answer": "True",
                "explanation": "The statement is true because by definition, $g(x,y)$ is an extension of $f(x,y)$ such that $g(x,y) = f(x,y)$ on the region $D$ and $g(x,y) = 0$ outside $D$ but within $R$. Therefore, the double integral of $f(x,y)$ over $D$ is equal to the double integral of $g(x,y)$ over $R$. This is mathematically represented as $\\iint_D f(x,y) \\, dA = \\iint_R g(x,y) \\, dA$. For example, if $D$ is a circular region inside a square $R$, and $f(x,y)$ is defined on $D$, then $g(x,y)$ would be $f(x,y)$ within the circle and $0$ outside the circle but within the square. Integrating $g(x,y)$ over the entire square $R$ would yield the same result as integrating $f(x,y)$ over the circular region $D$."
            },
            {
                "question": "According to Fubini's Theorem (Strong Form), for a function $f(x,y)$ that is continuous on a region $D$ of Type I, the double integral $\\iint_D f(x,y) \\, dA$ can be computed as $\\int_a^b \\left[ \\int_{g_1(x)}^{g_2(x)} f(x,y) \\, dy \\right] dx$, and for a region $D$ of Type II, the double integral $\\iint_D f(x,y) \\, dA$ can be computed as $\\int_c^d \\left[ \\int_{h_1(y)}^{h_2(y)} f(x,y) \\, dx \\right] dy$.",
                "answer": "True",
                "explanation": "Fubini's Theorem (Strong Form) states that for a continuous function $f(x,y)$ on a region $D$ of Type I, the double integral $\\iint_D f(x,y) \\, dA$ can be computed by iterated integrals as $\\iint_D f(x,y) \\, dy \\, dx = \\int_a^b \\left[ \\int_{g_1(x)}^{g_2(x)} f(x,y) \\, dy \\right] dx$. Similarly, for a region $D$ of Type II, the double integral $\\iint_D f(x,y) \\, dA$ can be computed as $\\iint_D f(x,y) \\, dx \\, dy = \\int_c^d \\left[ \\int_{h_1(y)}^{h_2(y)} f(x,y) \\, dx \\right] dy$. This allows us to evaluate double integrals by integrating one variable at a time. For example, if $D$ is a rectangle where $a \\leq x \\leq b$ and $c \\leq y \\leq d$, then $\\iint_D f(x,y) \\, dA = \\int_a^b \\left[ \\int_c^d f(x,y) \\, dy \\right] dx = \\int_c^d \\left[ \\int_a^b f(x,y) \\, dx \\right] dy$."
            },
            {
                "question": "If a region $D$ can be decomposed into two non-overlapping regions $D_1$ and $D_2$ (except at their boundaries), then the double integral of a function $f(x,y)$ over $D$ is equal to the sum of the double integrals of $f(x,y)$ over $D_1$ and $D_2$.",
                "answer": "True",
                "explanation": "The statement is true because the property of double integrals allows for the decomposition of a region into smaller, non-overlapping regions. Mathematically, if $D = D_1 \\cup D_2$ and $D_1 \\cap D_2$ is only at the boundaries, then $\\iint_D f(x,y) \\, dA = \\iint_{D_1} f(x,y) \\, dA + \\iint_{D_2} f(x,y) \\, dA$. This is analogous to the additivity property of integrals, where the integral over a whole region can be split into integrals over subregions. For example, if $D$ is a rectangle that can be split into two smaller rectangles $D_1$ and $D_2$, the total integral over $D$ is the sum of the integrals over $D_1$ and $D_2$."
            },
            {
                "question": "The area of a plane-bounded region $D$ can be found by evaluating the double integral $\\iint_D 1 \\, dA$.",
                "answer": "True",
                "explanation": "The area of a plane-bounded region $D$ is indeed found by evaluating the double integral $\\iint_D 1 \\, dA$. This integral sums up the infinitesimal areas $dA$ over the entire region $D$. For example, if $D$ is a rectangle with sides of length $a$ and $b$, the double integral $\\iint_D 1 \\, dA$ simplifies to $ab$, which is the area of the rectangle. Similarly, for more complex regions, the double integral accounts for the entire area by integrating over all infinitesimal elements within $D$."
            },
            {
                "question": "The average value of a function $f(x,y)$ over a plane-bounded region $D$ with positive area $A(D)$ is given by $f_{ave} = \\frac{1}{A(D)} \\iint_D f(x,y) \\, dA$, where $A(D) = \\iint_D 1 \\, dA$.",
                "answer": "True",
                "explanation": "The average value of a function $f(x,y)$ over a region $D$ is calculated by dividing the integral of the function over the region by the area of the region. Mathematically, this is expressed as $f_{ave} = \\frac{1}{A(D)} \\iint_D f(x,y) \\, dA$. The area $A(D)$ of the region $D$ is given by $A(D) = \\iint_D 1 \\, dA$. For example, if $f(x,y) = x + y$ and $D$ is a unit square with vertices at $(0,0)$, $(1,0)$, $(1,1)$, and $(0,1)$, then $A(D) = 1$ and $f_{ave} = \\frac{1}{1} \\iint_D (x + y) \\, dA = \\iint_D (x + y) \\, dA$. This confirms the given formula for the average value of the function."
            },
            {
                "question": "According to Fubini's Theorem for Improper Integrals, if $D$ is a bounded rectangle or simple region in the plane and $f$ is a nonnegative function with finitely many discontinuities in the interior of $D$, then the double integral of $f$ over $D$ can be computed as an iterated integral in either order.",
                "answer": "True",
                "explanation": "Fubini's Theorem for Improper Integrals states that if $D$ is a bounded rectangle or simple region in the plane defined by $\\{(x,y):a \\leq x \\leq b, g(x) \\leq y \\leq h(x)\\}$ and also by $\\{(x,y):c \\leq y \\leq d, j(y) \\leq x \\leq k(y)\\}$, and $f$ is a nonnegative function on $D$ with finitely many discontinuities in the interior of $D$, then the double integral of $f$ over $D$ can be computed as an iterated integral in either order. This means $\\iint_D f dA = \\int_{x=a}^{b} \\int_{y=g(x)}^{h(x)} f(x,y) dy dx = \\int_{y=c}^{d} \\int_{x=j(y)}^{k(y)} f(x,y) dx dy$. For example, if $D$ is the region bounded by $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$, and $f(x,y) = x + y$, then $\\iint_D (x + y) dA$ can be computed as $\\int_{0}^{1} \\int_{0}^{1} (x + y) dy dx$ or $\\int_{0}^{1} \\int_{0}^{1} (x + y) dx dy$, both yielding the same result."
            },
            {
                "question": "For an unbounded rectangle $R = \\{(x,y) : a \\leq x < \\infty, c \\leq y < \\infty \\}$, the improper integral $\\iint_R f(x,y) \\, dA$ can be evaluated as $\\lim_{(b,d) \\to (\\infty, \\infty)} \\int_a^b \\left( \\int_c^d f(x,y) \\, dy \\right) dx = \\lim_{(b,d) \\to (\\infty, \\infty)} \\int_c^d \\left( \\int_a^b f(x,y) \\, dx \\right) dy$ when the limit exists.",
                "answer": "True",
                "explanation": "The statement is true because for an unbounded region $R$ defined as $\\{(x,y) : a \\leq x < \\infty, c \\leq y < \\infty \\}$, the improper integral $\\iint_R f(x,y) \\, dA$ can be evaluated by taking the limit of the iterated integrals as the bounds $b$ and $d$ approach infinity. This means that $\\iint_R f(x,y) \\, dA$ is equal to $\\lim_{(b,d) \\to (\\infty, \\infty)} \\int_a^b \\left( \\int_c^d f(x,y) \\, dy \\right) dx$ and also equal to $\\lim_{(b,d) \\to (\\infty, \\infty)} \\int_c^d \\left( \\int_a^b f(x,y) \\, dx \\right) dy$, provided the limits exist. This property allows us to interchange the order of integration for the improper integral over the unbounded region. For example, if $f(x,y) = e^{-x-y}$, both iterated integrals will converge to the same value, demonstrating the equality."
            },
            {
                "question": "For a pair of continuous random variables $X$ and $Y$ with a joint density function $f(x,y)$, the function $f(x,y)$ must always be non-negative and the integral of $f(x,y)$ over the entire plane must equal 1.",
                "answer": "True",
                "explanation": "The joint density function $f(x,y)$ of continuous random variables $X$ and $Y$ must satisfy two main conditions: 1) $f(x,y) \\geq 0$ for all $x$ and $y$, ensuring that probabilities are never negative, and 2) $\\iint_{\\mathbb{R}^2} f(x,y) \\, dA = 1$, ensuring that the total probability over the entire plane is 1. For example, if $X$ and $Y$ represent the birthdays of two people, the joint density function must be non-negative for all possible dates and the total probability of all possible birthday combinations must sum to 1."
            },
            {
                "question": "If the joint density function of two random variables X and Y is given by $f(x,y) = f_1(x)f_2(y)$, then X and Y are independent random variables.",
                "answer": "True",
                "explanation": "Two random variables X and Y are considered independent if the joint density function $f(x,y)$ can be expressed as the product of their individual density functions $f_1(x)$ and $f_2(y)$. This means that the occurrence of X does not affect the occurrence of Y and vice versa. For example, if $f(x,y) = f_1(x)f_2(y)$, then knowing the value of X provides no information about the value of Y, confirming their independence."
            },
            {
                "question": "The expected value $E(X)$ of a random variable $X$ is the most likely outcome of the event $X$.",
                "answer": "False",
                "explanation": "The expected value $E(X)$ of a random variable $X$ is not necessarily the most likely outcome of the event $X$. Instead, it is the weighted average of all possible values that $X$ can take, with the weights being the probabilities of those values. For example, if $X$ represents the outcome of rolling a fair six-sided die, the expected value $E(X)$ is $3.5$, which is not an actual outcome of the die roll. The most likely outcome in this case would be any of the numbers $1$ through $6$, each with equal probability."
            }
        ],
        "5-6-calculating-centers-of-mass-and-moments-of-inertia": [
            {
                "question": "The center of mass coordinates $(\\bar{x}, \\bar{y}, \\bar{z})$ of a solid object with density function $\\rho(x,y,z)$ are given by $\\bar{x} = \\frac{M_{yz}}{m}$, $\\bar{y} = \\frac{M_{xz}}{m}$, and $\\bar{z} = \\frac{M_{xy}}{m}$, where $M_{xy}$, $M_{xz}$, and $M_{yz}$ are the moments about the $xy$-plane, $xz$-plane, and $yz$-plane respectively, and $m$ is the mass of the object.",
                "answer": "True",
                "explanation": "The center of mass $(\\bar{x}, \\bar{y}, \\bar{z})$ of a solid object with a density function $\\rho(x,y,z)$ is calculated using the moments about the coordinate planes and the mass of the object. Specifically, $\\bar{x} = \\frac{M_{yz}}{m}$, $\\bar{y} = \\frac{M_{xz}}{m}$, and $\\bar{z} = \\frac{M_{xy}}{m}$, where $M_{xy} = \\iiint_Q z \\rho(x,y,z) \\, dV$, $M_{xz} = \\iiint_Q y \\rho(x,y,z) \\, dV$, and $M_{yz} = \\iiint_Q x \\rho(x,y,z) \\, dV$ are the moments about the $xy$-plane, $xz$-plane, and $yz$-plane respectively, and $m = \\iiint_Q \\rho(x,y,z) \\, dV$ is the mass of the object. For example, if the density function is constant, the center of mass coincides with the centroid of the solid."
            }
        ],
        "5-1-double-integrals-over-rectangular-regions": [
            {
                "question": "The double integral of a function $f(x,y)$ over a rectangular region $R$ in the $xy$-plane can be approximated by summing the values of $f$ at specific points $(x_i^*, y_j^*)$ within subrectangles of $R$, multiplied by the area of each subrectangle, and taking the limit as the number of subrectangles approaches infinity.",
                "answer": "True",
                "explanation": "The double integral $\\iint_R f(x,y) \\, dA$ over a rectangular region $R$ is defined as the limit of a double sum as the number of subrectangles approaches infinity. Specifically, it is given by $\\iint_R f(x,y) \\, dA = \\lim_{m,n \\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f(x_i^*, y_j^*) \\Delta A$, where $\\Delta A$ is the area of each subrectangle and $(x_i^*, y_j^*)$ are points within each subrectangle. This definition captures the idea of approximating the integral by summing the contributions from each subrectangle and refining the approximation by increasing the number of subrectangles. For example, if $R$ is divided into $m \\times n$ subrectangles, each with area $\\Delta A$, and $f$ is evaluated at the center of each subrectangle, the sum $\\sum_{i=1}^m \\sum_{j=1}^n f(x_i^*, y_j^*) \\Delta A$ approximates the integral, and the approximation improves as $m$ and $n$ increase."
            },
            {
                "question": "If $f(x,y)$ can be factored as a product of a function $g(x)$ of $x$ only and a function $h(y)$ of $y$ only, then over the region $R = \\{(x,y) | a \\leq x \\leq b, c \\leq y \\leq d\\}$, the double integral $\\iint_R f(x,y) \\, dA$ can be written as $(\\int_a^b g(x) \\, dx)(\\int_c^d h(y) \\, dy)$.",
                "answer": "True",
                "explanation": "The property of double integrals states that if $f(x,y)$ can be expressed as $f(x,y) = g(x)h(y)$, where $g(x)$ is a function of $x$ only and $h(y)$ is a function of $y$ only, then the double integral over a rectangular region $R = \\{(x,y) | a \\leq x \\leq b, c \\leq y \\leq d\\}$ can be separated into the product of two single integrals: $\\iint_R f(x,y) \\, dA = (\\int_a^b g(x) \\, dx)(\\int_c^d h(y) \\, dy)$. For example, if $f(x,y) = x^2 y$, then $g(x) = x^2$ and $h(y) = y$, and the double integral over $R$ can be computed as $(\\int_a^b x^2 \\, dx)(\\int_c^d y \\, dy)$."
            },
            {
                "question": "The iterated integral of a function $f(x,y)$ over a rectangular region $R = [a,b] \\times [c,d]$ can be computed by integrating $f(x,y)$ with respect to $y$ first and then with respect to $x$, or by integrating $f(x,y)$ with respect to $x$ first and then with respect to $y$.",
                "answer": "True",
                "explanation": "The iterated integral of a function $f(x,y)$ over a rectangular region $R = [a,b] \\times [c,d]$ can be computed in two ways: $\\int_a^b \\int_c^d f(x,y) \\, dy \\, dx = \\int_a^b \\left[ \\int_c^d f(x,y) \\, dy \\right] \\, dx$ and $\\int_c^d \\int_a^b f(x,y) \\, dx \\, dy = \\int_c^d \\left[ \\int_a^b f(x,y) \\, dx \\right] \\, dy$. This means that you can integrate with respect to $y$ first and then $x$, or with respect to $x$ first and then $y$. For example, if $f(x,y) = x + y$ over the region $[0,1] \\times [0,1]$, both methods will yield the same result: $\\int_0^1 \\int_0^1 (x + y) \\, dy \\, dx = \\int_0^1 \\left[ \\int_0^1 (x + y) \\, dy \\right] \\, dx = \\int_0^1 \\left[ x + \\frac{y^2}{2} \\bigg|_0^1 \\right] \\, dx = \\int_0^1 \\left( x + \\frac{1}{2} \\right) \\, dx = \\left( \\frac{x^2}{2} + \\frac{x}{2} \\bigg|_0^1 \\right) = 1$. Similarly, $\\int_0^1 \\int_0^1 (x + y) \\, dx \\, dy = \\int_0^1 \\left[ \\int_0^1 (x + y) \\, dx \\right] \\, dy = \\int_0^1 \\left[ \\frac{x^2}{2} + yx \\bigg|_0^1 \\right] \\, dy = \\int_0^1 \\left( \\frac{1}{2} + y \\right) \\, dy = \\left( \\frac{y}{2} + \\frac{y^2}{2} \\bigg|_0^1 \\right) = 1$."
            },
            {
                "question": "According to Fubini's Theorem, if a function $f(x,y)$ is continuous over a rectangular region $R = \\{(x,y) \\in \\mathbb{R}^2 | a \\leq x \\leq b, c \\leq y \\leq d\\}$, then the double integral of $f$ over $R$ can be computed as an iterated integral in either order.",
                "answer": "True",
                "explanation": "Fubini's Theorem states that if $f(x,y)$ is continuous over a rectangular region $R = \\{(x,y) \\in \\mathbb{R}^2 | a \\leq x \\leq b, c \\leq y \\leq d\\}$, then the double integral of $f$ over $R$ can be computed as an iterated integral in either order. This means $\\iint_R f(x,y) \\, dA = \\int_a^b \\int_c^d f(x,y) \\, dy \\, dx = \\int_c^d \\int_a^b f(x,y) \\, dx \\, dy$. For example, if $f(x,y) = x + y$ and $R = \\{(x,y) \\in \\mathbb{R}^2 | 0 \\leq x \\leq 1, 0 \\leq y \\leq 1\\}$, then $\\iint_R (x + y) \\, dA$ can be computed as $\\int_0^1 \\int_0^1 (x + y) \\, dy \\, dx$ or $\\int_0^1 \\int_0^1 (x + y) \\, dx \\, dy$."
            },
            {
                "question": "The area of a region $R$ can be found by evaluating the double integral $\\iint_R 1 \\, dA$.",
                "answer": "True",
                "explanation": "The area of a region $R$ is given by the double integral $\\iint_R 1 \\, dA$. This integral sums up the 'height' of 1 over the entire region $R$, effectively counting the number of infinitesimal area elements $dA$ within $R$. For example, if $R$ is a rectangle with sides of length $a$ and $b$, the area can be computed as $\\iint_R 1 \\, dA = \\int_0^a \\int_0^b 1 \\, dy \\, dx = ab$, which matches the formula for the area of a rectangle."
            },
            {
                "question": "The average value of a function $f(x,y)$ over a region $R$ is given by $f_{ave} = \\frac{1}{\\text{Area}(R)} \\iint_R f(x,y) \\, dA$.",
                "answer": "True",
                "explanation": "The average value of a function $f(x,y)$ over a region $R$ is indeed given by $f_{ave} = \\frac{1}{\\text{Area}(R)} \\iint_R f(x,y) \\, dA$. This formula calculates the mean value of the function over the specified region by integrating the function over the region and then dividing by the area of the region. For example, if $f(x,y) = x + y$ over a rectangular region $R$ with vertices at $(0,0)$, $(1,0)$, $(1,1)$, and $(0,1)$, the area of $R$ is 1. The integral $\\iint_R (x + y) \\, dA$ would be evaluated over this region, and the result would be divided by the area (1) to find the average value."
            }
        ],
        "5-3-double-integrals-in-polar-coordinates": [
            {
                "question": "The double integral of a function $f(r, \\theta)$ over a polar rectangular region $R$ in the $r\\theta$-plane can be expressed as $\\iint_R f(r, \\theta) \\, dA = \\lim_{m,n \\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f(r_{ij}^*, \\theta_{ij}^*) \\Delta A = \\lim_{m,n \\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f(r_{ij}^*, \\theta_{ij}^*) r_{ij}^* \\Delta r \\Delta \\theta$.",
                "answer": "True",
                "explanation": "The double integral of a function $f(r, \\theta)$ over a polar rectangular region $R$ in the $r\\theta$-plane is indeed expressed as $\\iint_R f(r, \\theta) \\, dA = \\lim_{m,n \\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f(r_{ij}^*, \\theta_{ij}^*) \\Delta A = \\lim_{m,n \\to \\infty} \\sum_{i=1}^m \\sum_{j=1}^n f(r_{ij}^*, \\theta_{ij}^*) r_{ij}^* \\Delta r \\Delta \\theta$. This expression represents the limit of a double Riemann sum, where $r_{ij}^*$ and $\\theta_{ij}^*$ are sample points in the subrectangles, $\\Delta r$ and $\\Delta \\theta$ are the widths of the subrectangles in the $r$ and $\\theta$ directions, respectively, and $r_{ij}^* \\Delta r \\Delta \\theta$ represents the area element in polar coordinates. For example, if $f(r, \\theta) = r$ over a region $R$ defined by $0 \\leq r \\leq 1$ and $0 \\leq \\theta \\leq 2\\pi$, the double integral would compute the area of a unit circle."
            },
            {
                "question": "If $f(r,\\theta)$ is continuous on a general polar region $D$, then the double integral over $D$ can be expressed as $\\iint_D f(r,\\theta) \\, r \\, dr \\, d\\theta = \\int_{\\alpha}^{\\beta} \\int_{h_1(\\theta)}^{h_2(\\theta)} f(r,\\theta) \\, r \\, dr \\, d\\theta$.",
                "answer": "True",
                "explanation": "The statement is true. When dealing with double integrals over a general polar region $D$, the integral can be transformed into polar coordinates. The region $D$ is described by $\\alpha \\leq \\theta \\leq \\beta$ and $h_1(\\theta) \\leq r \\leq h_2(\\theta)$. The double integral in Cartesian coordinates is converted to polar coordinates by including the Jacobian determinant $r$, resulting in the integral $\\iint_D f(r,\\theta) \\, r \\, dr \\, d\\theta$. For example, if $D$ is a circular region, the limits for $r$ and $\\theta$ would be adjusted accordingly to describe the circle in polar coordinates."
            }
        ],
        "5-5-triple-integrals-in-cylindrical-and-spherical-coordinates": [
            {
                "question": "The triple integral of a continuous function $f(r, \\theta, z)$ over a cylindrical box $B = \\{(r, \\theta, z) | a \\leq r \\leq b, \\alpha \\leq \\theta \\leq \\beta, c \\leq z \\leq d\\}$ can be defined as the limit of a triple Riemann sum, provided the limit exists.",
                "answer": "True",
                "explanation": "The triple integral in cylindrical coordinates is defined as the limit of a triple Riemann sum if the function $f(r, \\theta, z)$ is continuous over the cylindrical box $B$. This means that as the number of subboxes increases (i.e., as $l, m, n \\to \\infty$), the sum of the function values at sample points within each subbox, multiplied by the volume of each subbox, approaches the exact value of the integral. For example, if $f(r, \\theta, z) = r$ and $B$ is defined by $1 \\leq r \\leq 2$, $0 \\leq \\theta \\leq \\pi$, and $0 \\leq z \\leq 1$, the triple Riemann sum would approximate the volume under the surface $r$ within the specified bounds, and the limit of this sum would give the exact volume."
            },
            {
                "question": "According to Fubini's Theorem in cylindrical coordinates, if $g(x,y,z)$ is continuous on a portion of a circular cylinder $B$ described by $B = \\{(r, \\theta, z) | a \\leq r \\leq b, \\alpha \\leq \\theta \\leq \\beta, c \\leq z \\leq d \\}$, then the triple integral of $g(x,y,z)$ over $B$ can be expressed as $\\iiint_B g(x,y,z) \\, dV = \\int_c^d \\int_\\alpha^\\beta \\int_a^b f(r, \\theta, z) \\, r \\, dr \\, d\\theta \\, dz$ where $g(x,y,z) = f(r, \\theta, z)$.",
                "answer": "True",
                "explanation": "Fubini's Theorem allows us to evaluate a triple integral by iteratively integrating over each variable. In cylindrical coordinates, the volume element $dV$ is given by $r \\, dr \\, d\\theta \\, dz$. Given that $g(x,y,z)$ is continuous and can be expressed as $f(r, \\theta, z)$ in cylindrical coordinates, the integral over the region $B$ can be transformed accordingly. The limits of integration correspond to the bounds of $r$, $\\theta$, and $z$ as specified. For example, if $B$ is a cylinder with $a = 0$, $b = 1$, $\\alpha = 0$, $\\beta = 2\\pi$, $c = 0$, and $d = 1$, the integral would be $\\iiint_B g(x,y,z) \\, dV = \\int_0^1 \\int_0^{2\\pi} \\int_0^1 f(r, \\theta, z) \\, r \\, dr \\, d\\theta \\, dz$."
            },
            {
                "question": "The triple integral in spherical coordinates can be expressed as the limit of a triple Riemann sum, where the integrand is multiplied by $(\\rho^2 \\sin \\varphi)$ and the differential volume element is $\\Delta \\rho \\Delta \\theta \\Delta \\varphi$.",
                "answer": "True",
                "explanation": "The triple integral in spherical coordinates is indeed expressed as the limit of a triple Riemann sum. In spherical coordinates, the volume element $dV$ is given by $(\\rho^2 \\sin \\varphi) d\\rho d\\theta d\\varphi$. This accounts for the Jacobian determinant when converting from Cartesian to spherical coordinates. For example, if we want to integrate a function $f(\\rho, \\theta, \\varphi)$ over a spherical region, we sum up the contributions of small volume elements $(\\rho^2 \\sin \\varphi) \\Delta \\rho \\Delta \\theta \\Delta \\varphi$ weighted by the function value at each point. Thus, the integral is approximated by the sum $\\sum_{i=1}^{l} \\sum_{j=1}^{m} \\sum_{k=1}^{n} f(\\rho_{ijk}^*, \\theta_{ijk}^*, \\varphi_{ijk}^*) (\\rho_{ijk}^*)^2 \\sin \\varphi_{ijk}^* \\Delta \\rho \\Delta \\theta \\Delta \\varphi$, and taking the limit as $l, m, n \\to \\infty$ gives the exact value of the integral."
            },
            {
                "question": "According to Fubini's Theorem for Spherical Coordinates, if $f(\\rho, \\theta, \\varphi)$ is continuous on a spherical solid box $B = [a, b] \\times [\\alpha, \\beta] \\times [\\gamma, \\psi]$, then the triple integral $\\iiint_B f(\\rho, \\theta, \\varphi) \\rho^2 \\sin \\varphi \\, d\\rho \\, d\\varphi \\, d\\theta$ can be computed as an iterated integral in any order of integration.",
                "answer": "True",
                "explanation": "Fubini's Theorem states that if a function is continuous on a given domain, the multiple integral over that domain can be computed as an iterated integral in any order. For spherical coordinates, this means that the triple integral $\\iiint_B f(\\rho, \\theta, \\varphi) \\rho^2 \\sin \\varphi \\, d\\rho \\, d\\varphi \\, d\\theta$ can be expressed as $\\int_{\\alpha}^{\\beta} \\int_{\\gamma}^{\\psi} \\int_{a}^{b} f(\\rho, \\theta, \\varphi) \\rho^2 \\sin \\varphi \\, d\\rho \\, d\\varphi \\, d\\theta$ or in any other order of integration. For example, it could also be written as $\\int_{a}^{b} \\int_{\\gamma}^{\\psi} \\int_{\\alpha}^{\\beta} f(\\rho, \\theta, \\varphi) \\rho^2 \\sin \\varphi \\, d\\theta \\, d\\varphi \\, d\\rho$. This flexibility is a direct consequence of the continuity of $f$ on the domain $B$."
            }
        ]
    }
}