{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0e0670e5-d5ec-4145-9f77-d632a67fa623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b7532d96-6698-43af-8a08-1c343fdf4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = dict()\n",
    "for i in range(1, 8):\n",
    "    entries = os.listdir(f\"./data/LinearAlgebraSlides/Chapter{i}/\")\n",
    "    all_matches[f\"Chapter{i}\"] = {}\n",
    "    for a in entries:\n",
    "        all_matches[f\"Chapter{i}\"][a] = []\n",
    "\n",
    "        if (a[-3:] != \"tex\"):\n",
    "            continue;\n",
    "        f = open(f\"./data/LinearAlgebraSlides/Chapter{i}/\" + a, \"r\")\n",
    "        content = f.read()\n",
    "        frame_regex = r'(\\\\begin\\{center\\}(?:(?!\\\\end\\{center\\}).)*(Theorem|Definition).*?\\\\end\\{center\\})'\n",
    "    \n",
    "        matches = re.findall(frame_regex, content, re.DOTALL)\n",
    "        for match in matches:\n",
    "            all_matches[f\"Chapter{i}\"][a].append(match[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "963af8ef-81f1-4427-961e-287a4ecb8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = []\n",
    "for chapter in all_matches:\n",
    "    for sec in all_matches[chapter]:\n",
    "        for i in range(len(all_matches[chapter][sec])):\n",
    "            theorem_regex = r'(?<=\\n)(.*)(?=\\\\end\\{minipage\\})'\n",
    "            matches = re.findall(theorem_regex, all_matches[chapter][sec][i], re.DOTALL)\n",
    "            all_matches[chapter][sec][i] = (matches[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ba5ff850-f69f-419c-8d2d-d8bd17e2e570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chapter1': {'1_7_1.tex': [],\n",
       "  '1_2_1.tex': [],\n",
       "  '1_8_1.tex': [],\n",
       "  '1_5_2.tex': ['Linear systems of the form $A\\\\vec x = \\\\vec 0$ are \\\\Emph{homogeneous}. \\\\\\\\[12pt]\\n        Linear systems of the form $A\\\\vec x = \\\\vec b, \\\\ \\\\vec b \\\\ne \\\\vec 0$, are \\\\Emph{inhomogeneous}.'],\n",
       "  '1_1_1.tex': ['The set of all possible values of $x_1, x_2, \\\\ldots x_n$ that satisfy all equations is the \\\\Emph{solution set} of the system. \\\\pause One point in the solution set is a \\\\Emph{solution}.',\n",
       "   'The solution set to a system of linear equations can only have\\n    \\\\begin{itemize}\\n        \\\\item<2-> exactly one point (there is a unique solution), or\\n        \\\\item<3-> infinitely many points (there are many solutions), or\\n        \\\\item<4-> no points (there are no solutions)\\n    \\\\end{itemize}'],\n",
       "  '1_2_2.tex': [],\n",
       "  '1_7_2.tex': [],\n",
       "  '1_3_2.tex': ['Given vectors $ \\\\vec v_1, \\\\vec v_2 ,\\\\dotsc, \\\\vec v_p \\\\in \\\\mathbb R ^{n} $, and scalars $ c_1 , c_2, \\\\dotsc, c_p$,  the vector $\\\\vec y$, where\\n        \\\\begin{equation*}\\n        \\\\vec y = c_1 \\\\vec v_1 + c_2 \\\\vec v_2 + \\\\cdots + c_p \\\\vec v_p\\n        \\\\end{equation*}\\\\pause \\n        is called a \\\\Emph{linear combination} of $\\\\vec v_1, \\\\vec v_2 ,\\\\dotsc, \\\\vec v_p $ with weights $ c_1 , c_2 ,\\\\dotsc, c_p$.'],\n",
       "  '1_9_2.tex': ['%     Let $  T \\\\;:\\\\;  \\\\mathbb R ^n \\\\mapsto \\\\mathbb R ^m $ be a linear transformation.  \\n%     Then there is a unique matrix $ A$ such that \\n%     \\\\begin{equation*}\\n%         T ( \\\\vec x ) = A \\\\vec x, \\\\qquad \\\\vec x\\\\in \\\\mathbb R ^{n}. \\n%     \\\\end{equation*}\\n%     In fact, $ A$ is a $ m \\\\times n$, and its $ j^{th}$ column is the vector $ T (\\\\vec e _j)$.  \\n%     \\\\begin{equation*}\\n%         A = \\\\begin{pmatrix}\\n%         T (\\\\vec e_1) & T(\\\\vec e_2)  & \\\\cdots  & T (\\\\vec e_n)\\n%     \\\\end{pmatrix}\\n%     \\\\end{equation*}\\n\\n%'],\n",
       "  '1_5_1.tex': ['Linear systems of the form $A\\\\vec x = \\\\vec 0$ are \\\\Emph{homogeneous}. \\\\\\\\[12pt]\\n        Linear systems of the form $A\\\\vec x = \\\\vec b, \\\\ \\\\vec b \\\\ne \\\\vec 0$, are \\\\Emph{inhomogeneous}.'],\n",
       "  '1_9_1.tex': ['\\\\vspace{4pt}\\n\\n    Let $  T $ be a linear transformation that maps $ \\\\mathbb R ^n$ to $\\\\mathbb R ^m$. Then there is a unique matrix $ A$ such that \\n    \\\\onslide<2->{\\n    \\\\begin{equation*}\\n        T ( \\\\vec x ) = A \\\\vec x, \\\\qquad \\\\vec x\\\\in \\\\mathbb R ^{n}. \\n    \\\\end{equation*}\\n    } \\\\onslide<3->{\\n    \\\\hspace{-.4cm}Also, $ A$ is a $ m \\\\times n$, and column $j$ is the vector $ T (\\\\vec e _j)$.} \\\\onslide<4->{In other words, $A = \\\\begin{pmatrix} T (\\\\vec e_1) & T(\\\\vec e_2)  & \\\\cdots  & T (\\\\vec e_n) \\\\end{pmatrix}$.}'],\n",
       "  '1_2_3.tex': ['A linear system is consistent if and only if (exactly when) the last column of the \\\\Emph{augmented} matrix does not have a pivot. This is the same as saying that the RREF of the augmented matrix does \\\\Emph{not} have a row of the form\\n$$\\\\spalignmat{0 , 0, 0,  \\\\cdots, 0 | 1}$$\\nMoreover, if a linear system is consistent, then it has\\n\\\\begin{enumerate}\\n    \\\\item a unique solution if and only if there are no free variables, and\\n    \\\\item infinitely many solutions that are parameterized by free variables. \\n\\\\end{enumerate}'],\n",
       "  '1_9_3.tex': ['A linear transformation $ T \\\\;:\\\\; \\\\mathbb R ^{n} \\\\to \\\\mathbb R ^{m} $ is \\\\Emph{onto} if for all $ \\\\vec b \\\\in \\\\mathbb R ^{m}$ there is a $ \\\\vec x\\\\in \\\\mathbb R ^{n}$ so that $ T (\\\\vec x) = A\\\\vec x = \\\\vec b$.',\n",
       "   'A linear transformation $ T \\\\;:\\\\; \\\\mathbb R ^{n} \\\\to \\\\mathbb R ^{m} $ is \\\\Emph{one-to-one}  \\n if \\n for all $ \\\\vec b \\\\in \\\\mathbb R ^{m}$ there is at most one (possibly no) $ \\\\vec x\\\\in \\\\mathbb R ^{n}$ so that $ T\\\\left( \\\\vec x \\\\right)= A\\\\vec x = \\\\vec b$.',\n",
       "   'For a linear transformation $ T \\\\;:\\\\; \\\\mathbb R ^{n} \\\\to \\\\mathbb R ^{m}$ with standard matrix $ A$, these are equivalent statements.  \\n    %%  ENUMERATE\\n    \\\\begin{enumerate}\\n    \\\\item  $ T$ is onto. \\n    \\n    \\\\item $ A$ has  columns that span $ \\\\mathbb R ^{m}$. \\n    \\n    \\\\item Every row of $A$ is pivotal.  \\n    \\\\end{enumerate}\\n    %% ENUMERATE',\n",
       "   'For a linear transformation $ T \\\\;:\\\\; \\\\mathbb R ^{n} \\\\to \\\\mathbb R ^{m}$ with standard matrix $ A$, these are equivalent statements.  \\n    \\n    \\\\begin{enumerate}\\n    \\\\item  $ T$ is one-to-one. \\n    \\n    \\\\item The unique solution to $ T \\\\left( \\\\vec x \\\\right) = \\\\vec 0$ is the trivial one. \\n    \\n    \\\\item $A$ has linearly independent columns.  \\n    \\n    \\\\item Each column of $A $ is pivotal.  \\n    \\\\end{enumerate}'],\n",
       "  '1_4_2.tex': ['The equation $ A \\\\vec x = \\\\vec b $ has a solution if and only if $ \\\\vec b$ is a linear combination of the columns of $ A$.'],\n",
       "  '1_1_2.tex': ['A linear system is \\\\Emph{consistent} if it has at least one solution.',\n",
       "   'Two matrices are \\\\Emph{row equivalent} if a sequence of row operations transforms one matrix into the other.'],\n",
       "  'images': [],\n",
       "  '1_3_3.tex': ['Given vectors $ \\\\vec v_1, \\\\vec v_2 ,\\\\dotsc, \\\\vec v_p \\\\in \\\\mathbb R ^{n} $, and scalars $ c_1 , c_2, \\\\dotsc, c_p$. The set of all linear combinations of $ \\\\vec v_1, \\\\vec v_2 ,\\\\dotsc, \\\\vec v_p $ is called the \\\\Emph{span} of $ \\\\vec v_1, \\\\vec v_2 ,\\\\dotsc, \\\\vec v_p $.'],\n",
       "  '1_4_1.tex': ['If $ A \\\\in \\\\mathbb R^{m \\\\times n}$ has columns $ \\\\vec a_1 ,\\\\dotsc, \\\\vec a_n$ and $\\\\vec x \\\\in \\\\mathbb R ^{n}$, then the \\\\Emph{matrix vector product} $A \\\\vec x$ is a linear combination of the columns of $A$.\\n    \\\\begin{equation*}\\n    A \\\\vec x \\n    = \\n    \\\\begin{pmatrix*}\\n    \\\\vert & \\\\vert & \\\\cdots & \\\\vert  \\n    \\\\\\\\\\n    \\\\vec a_1 & \\\\vec a_2 & \\\\cdots & \\\\vec a_n\\n    \\\\\\\\\\n    \\\\vert & \\\\vert & \\\\cdots & \\\\vert  \\n    \\\\end{pmatrix*} \\n    \\\\begin{pmatrix*}\\n    x_1 \\\\\\\\ x_2 \\\\\\\\ \\\\vdots \\\\\\\\ x_n\\n    \\\\end{pmatrix*} \\n    = x_1 \\\\vec a_1 + x_2 \\\\vec a_2 + \\\\cdots + x_n \\\\vec a_n\\n    \\\\end{equation*}\\n    Note that $ A \\\\vec x$ is in the span of the columns of $ A$.'],\n",
       "  '1_3_1.tex': [],\n",
       "  '1_8_2.tex': []},\n",
       " 'Chapter2': {'2_9_1.tex': [],\n",
       "  '2_8_1.tex': ['A \\\\Emph{subset of $\\\\mathbb R^n$} is any collection of vectors that are in $\\\\mathbb R^n$.',\n",
       "   'A subset $ H $ of $ \\\\mathbb R ^{n}$ is a \\\\Emph{subspace} if it is closed under scalar multiplies and vector addition.  That is: for any $c\\\\in\\\\mathbb R$ and for $\\\\vec u,  \\\\vec v\\\\in H$, \\n\\n    \\\\begin{enumerate}\\n        \\\\item $c \\\\,\\\\vec u  \\\\in H$\\n        \\\\item $\\\\vec u + \\\\vec v \\\\in H$\\n    \\\\end{enumerate}'],\n",
       "  '2_1_3.tex': [],\n",
       "  '2_8_3.tex': ['A \\\\Emph{basis} for a subspace $ H$ is a set of linearly independent vectors in $H$ that span $ H$.'],\n",
       "  '2_5_1.tex': [\"\\\\vspace{2pt}\\n\\n        If $ A$ is an $ m \\\\times n$ matrix that can be row reduced to echelon form without row exchanges, then $ A = L U $. $ L $ is a lower triangular $ m \\\\times m$ matrix with $ 1$'s on the diagonal, $ U$ is an \\\\Emph{echelon} form of $ A$.\"],\n",
       "  '2_7_2.tex': [],\n",
       "  '2_4_2.tex': ['% Let $ A$ be $ m \\\\times n$ and $ B$ be $ n \\\\times p$ matrix. Then,  \\n% \\\\begin{align*}\\n%  AB &= \\n%  \\\\begin{pmatrix}\\n% \\\\operatorname {col}_1 A & \\\\cdots & \\\\operatorname {col}_n A \\n% \\\\end{pmatrix}\\n%  \\\\begin{pmatrix}\\n% \\\\operatorname {row}_1 B \\\\\\\\ \\\\vdots \\\\\\\\  \\\\operatorname {row}_n B \\n% \\\\end{pmatrix}\\n% \\\\\\\\&= \\n% \\\\underbrace{\\n% \\\\operatorname {col}_1 A \\\\operatorname {row}_1 B + \\\\cdots \\\\operatorname {col}_n A \\\\operatorname {row}_n B } \\n% _{\\\\textup{$ m \\\\times p$ matrices}} \\n% \\\\end{align*}\\n% This is the \\\\Emph{Column Row Method} for matrix multiplication.\\n\\n%'],\n",
       "  '2_5_2.tex': [],\n",
       "  '2_2_3.tex': ['Matrix $A$ is invertible if and only if it is row equivalent to the identity. In this case, the any sequence of elementary row operations that transforms $ A$ into $ I$, applied to $ I$, generates $ A ^{-1} $.'],\n",
       "  '2_3_1.tex': ['\\\\item If $A$ and $B $ are $ n \\\\times n $ matrices and $ AB=I$, then $ A$ and $ B$ are invertible, and $ B = A ^{-1} $ and $ A = B ^{-1} $.'],\n",
       "  'images': [],\n",
       "  '2_1_2.tex': ['Let $ A $ be an $ m \\\\times n $ matrix, and $ B$ be an $ n \\\\times p$ matrix. \\\\onslide<2->{ The product  $ A B  $ is an $ m \\\\times p$ matrix,} \\\\onslide<3->{equal to} \\\\onslide<4->{$$ A B = A \\n    \\\\begin{pmatrix}\\n    \\\\vec b_1 & \\\\cdots & \\\\vec b_p\\n    \\\\end{pmatrix} = \\n    \\\\begin{pmatrix}\\n    A \\\\vec b_1 & \\\\cdots & A \\\\vec b_p\\n    \\\\end{pmatrix}\\n    $$ }'],\n",
       "  '2_2_2.tex': ['$A \\\\in \\\\R^{n\\\\times n}$ has an inverse if and only if for all $ \\\\vec b \\\\in \\\\mathbb R ^{n}$, $ A \\\\vec x= \\\\vec b$ has a unique solution.  And, in this case, $ \\\\vec  x = A ^{-1} \\\\vec b$.'],\n",
       "  '2_7_1.tex': [],\n",
       "  '2_1_1.tex': ['% Let $ A $ be a $ m \\\\times n $ matrix, and $ B$ be a $ n \\\\times p$ matrix. The product is  $ A B  $ a $ m \\\\times p$ matrix, equal to $$ A B = A \\n% \\\\begin{pmatrix}\\n% \\\\vec b_1 & \\\\cdots & \\\\vec b_p\\n% \\\\end{pmatrix} = \\n% \\\\begin{pmatrix}\\n% A \\\\vec b_1 & \\\\cdots & A \\\\vec b_p\\n% \\\\end{pmatrix}\\n% $$ \\n%'],\n",
       "  '2_6_1.tex': [],\n",
       "  '2_4_1.tex': ['Let $ A$ be $ m \\\\times n$ and $ B$ be $ n \\\\times p$ matrix. Then, the $ (i,j)$ entry of $ AB$ is \\n\\\\begin{equation*}\\n\\\\operatorname {row}_i A  \\\\cdot   \\\\operatorname {col}_j B . \\n\\\\end{equation*}\\nThis is the \\\\Emph{Row Column Method} for matrix multiplication.',\n",
       "   '% Let $ A$ be $ m \\\\times n$ and $ B$ be $ n \\\\times p$ matrix. Then,  \\n% \\\\begin{align*}\\n%  AB &= \\n%  \\\\begin{pmatrix}\\n% \\\\operatorname {col}_1 A & \\\\cdots & \\\\operatorname {col}_n A \\n% \\\\end{pmatrix}\\n%  \\\\begin{pmatrix}\\n% \\\\operatorname {row}_1 B \\\\\\\\ \\\\vdots \\\\\\\\  \\\\operatorname {row}_n B \\n% \\\\end{pmatrix}\\n% \\\\\\\\&= \\n% \\\\underbrace{\\n% \\\\operatorname {col}_1 A \\\\operatorname {row}_1 B + \\\\cdots \\\\operatorname {col}_n A \\\\operatorname {row}_n B } \\n% _{\\\\textup{$ m \\\\times p$ matrices}} \\n% \\\\end{align*}\\n% This is the \\\\Emph{Column Row Method} for matrix multiplication.\\n\\n%'],\n",
       "  '2_2_1.tex': ['$A \\\\in \\\\R^{n\\\\times n}$ is \\\\Emph{invertible} (or \\\\Emph{non-singular}) if there is a $C \\\\in \\\\R^{n\\\\times n}$ so that $$AC = CA = I_n.$$  If there is, we write $C= A ^{-1}$.',\n",
       "   'The  $ 2 \\\\times 2 $ matrix  $  \\\\begin{pmatrix*}[r]\\na & b \\\\\\\\ c & d \\n\\\\end{pmatrix*}$ is non-singular if and only if $ ad - bc \\\\neq 0$, and \\n\\\\begin{equation*}\\n \\\\begin{pmatrix*}[r]\\na & b \\\\\\\\ c & d \\n\\\\end{pmatrix*} ^{-1} = \\\\frac 1 {ad-bc} \\n \\\\begin{pmatrix*}[r]\\nd & -b \\\\\\\\ -c & a  \\n\\\\end{pmatrix*}\\n\\\\end{equation*}'],\n",
       "  '2_9_2.tex': ['The \\\\Emph{dimension} (or cardinality) of a non-zero subspace $H$, $ \\\\operatorname {dim} H $, is the number of vectors in a basis of $H$.\\n    We define $ \\\\operatorname {dim} \\\\{\\\\vec 0\\\\}$ = 0.',\n",
       "   'Suppose $H$ is a $p$-dimensional subspace of $\\\\mathbb R^n$. Any set of $p$ independent vectors that are in $H$ are automatically a basis for $H$.'],\n",
       "  '2_8_2.tex': ['Given an $ m \\\\times n $ matrix $ A = \\\\begin{bmatrix}\\n    \\\\vec a_1 & \\\\cdots & \\\\vec a _{n}\\n    \\\\end{bmatrix}$ \\\\vspace{2pt}\\n    \\\\begin{itemize}\\n        \\\\item  The \\\\Emph{column space of $ A$}, $ \\\\operatorname {Col} A $, is the subspace of $ \\\\mathbb R ^{m}$ spanned by $ \\\\vec a_1 ,\\\\dotsc, \\\\vec a_n$.  \\\\vspace{2pt}\\n        \\\\item The \\\\Emph{null space of $A$}, $ \\\\operatorname {Null} A $, is the subspace of $\\\\mathbb R^n$ spanned by the set of all vectors $ \\\\vec x$ that solve $ A \\\\vec x= \\\\vec 0$. \\n    \\\\end{itemize}'],\n",
       "  '2_9_3.tex': ['The \\\\Emph{rank} of a matrix is the dimension of its column space.',\n",
       "   'If a matrix $ A$ has $ n$ columns, then $ \\\\operatorname {Rank} A  + \\\\operatorname {dim(Nul} A) = n$.']},\n",
       " 'Chapter3': {'3_2_1.tex': ['Let $ A$ be a square matrix. \\n\\n%%  ENUMERATE\\n\\\\begin{enumerate}\\n\\\\item<1-> If a multiple of a row of $ A$ is added to another row to produce $ B$, then \\n$ \\\\operatorname {det} B = \\\\operatorname {det} A $. \\n\\n\\\\item<2-> If two rows are interchanged to produce $ B$, then $  \\\\operatorname {det} B = -\\\\operatorname {det} A $. \\n\\n\\\\item<3-> If one row of $ A$ is multiplied by a scalar $ k$ to produce $ B$, then \\n$  \\\\operatorname {det} B = k\\\\operatorname {det} A $. \\n\\\\end{enumerate}\\n%% ENUMERATE'],\n",
       "  '3_3_2.tex': ['%\\n%Let $ A$ be an invertible $ n \\\\times n $ matrix. For any $ \\\\vec b \\\\in \\\\mathbb R ^{n}$, the unique solution $\\\\vec x$ of the equation $ A \\\\vec x = \\\\vec b$ has the $ i$th entry given by \\n%\\\\begin{equation*}\\n%x_i = \\\\frac { \\\\operatorname {det} A_i (\\\\vec b)} {\\\\operatorname {det} A} , \\\\qquad i=1 ,\\\\dotsc, n. \\n%\\\\end{equation*}\\n%\\n%',\n",
       "   '%\\n%\\\\begin{equation*}\\n%A ^{-1} = \\\\frac 1 {\\\\operatorname {det} A} \\n%= \\n%\\\\begin{bmatrix*}[r]\\n%C _{11}  & C _{21} & \\\\cdots & C _{n1} \\n%\\\\\\\\\\n%C _{12} &  C _{22} & \\\\cdots & C _{n2} \\n%\\\\\\\\\\n%\\\\vdots  & \\\\vdots & \\\\ddots & \\\\vdots \\n%\\\\\\\\\\n%C _{1n} & C _{2n} & \\\\cdots & C _{nn}\\n%\\\\end{bmatrix*}\\n%\\\\end{equation*}\\n%\\n%',\n",
       "   'The volume of the parallelpiped spanned by the columns of an $n\\\\times n$ matrix $ A$ is $ \\\\lvert  \\\\operatorname {det} A\\\\rvert $.'],\n",
       "  '3_1_1.tex': [],\n",
       "  'images': [],\n",
       "  '3_2_2.tex': [],\n",
       "  '3_1_2.tex': ['The $ (i,j)$ cofactor of an $ n \\\\times n $ matrix $ A$ is  \\\\begin{equation*} C _{ij} = (-1) ^{i+j} \\\\operatorname {det} A _{ij}    \\\\end{equation*}',\n",
       "   'The determinant of a matrix $ A$ can be computed down any row or column of the matrix. For instance, \\n    down the $j^{th}$ column, the determinant is \\n    \\\\begin{equation*}\\n    \\\\operatorname {det} A = \\n    a _{1j} C _{1j} + a _{2j} C _{2j} + \\\\cdots + a _{nj} C _{nj} . \\n    \\\\end{equation*}',\n",
       "   'If $ A$ is a triangular matrix then $\\\\operatorname {det} A = a _{11} a _{22} a _{33} \\\\cdots a _{nn}$.'],\n",
       "  '3_3_1.tex': ['The absolute value of the determinant of a $2\\\\times 2$ matrix, whose columns  determine adjacent edges of a parallelogram, will give the area of the parallelogram.'],\n",
       "  '3_3_3.tex': ['If $T_A \\\\ : \\\\R^n \\\\mapsto \\\\R^n$, and $S$ is some parallelogram in $\\\\R^n$, then $$\\\\operatorname{volume}\\\\left(T_A(S)\\\\right) = \\\\left|\\\\det(A)\\\\right| \\\\cdot \\\\operatorname{volume}(S)$$\\n    where $T_A (\\\\vec x) = A \\\\vec x$.']},\n",
       " 'Chapter4': {'4_9_1.tex': [],\n",
       "  '4_9_2.tex': ['A stochastic matrix $P$ is \\\\Emph{regular} if there is some $k$ such that $P^k$ only contains strictly positive entries.',\n",
       "   'If $P$ is a regular stochastic matrix, then $P$ has a unique steady-state vector $\\\\vec q$, and $\\\\vec x_{k+1} = P\\\\vec x_k$ converges to $\\\\vec q$ as $k \\\\rightarrow \\\\infty$.']},\n",
       " 'Chapter5': {'5_1_1.tex': [],\n",
       "  '5_PR_3.tex': [],\n",
       "  '5_5_2.tex': ['Every polynomial of degree $n$ has exactly $n$ complex roots, counting multiplicity.',\n",
       "   'If $\\\\lambda \\\\in \\\\mathbb C$ is a root of a real polynomial $p (x)$, then the conjugate $\\\\overline{\\\\lambda}$ is also a root of $p(x)$.'],\n",
       "  '5_3_4.tex': [],\n",
       "  '5_2_2.tex': ['The \\\\Emph{algebraic multiplicity} of an eigenvalue is its multiplicity as a root of the characteristic polynomial.',\n",
       "   'The \\\\Emph{geometric multiplicity} of an eigenvalue $\\\\lambda$  is  the dimension of $ \\\\operatorname{Null} (A - \\\\lambda I)$.'],\n",
       "  '5_3_3.tex': [],\n",
       "  '5_1_3.tex': [],\n",
       "  '5_5_4.tex': ['If $A$ is a real $2 \\\\times 2$ matrix with eigenvalue $\\\\lambda = a - bi$ (where $b \\\\neq 0$) and associated eigenvector $\\\\vec v$, then we may construct the decomposition\\n    \\n    \\\\[ A = PCP^{-1} \\\\]\\n    where\\n    \\\\[ P = (\\\\textrm{Re}\\\\, \\\\vec v\\\\ \\\\ \\\\  \\\\textrm{Im}\\\\, \\\\vec v) \\\\quad \\\\text{and} \\\\quad C = \\\\spalignmat{ a -b ; b  a }. \\\\]'],\n",
       "  '5_2_3.tex': [],\n",
       "  '5_PR_1.tex': ['A stochastic matrix $P$ is \\\\Emph{regular} if there is some $k$ such that $P^k$ only contains strictly positive entries.',\n",
       "   '\\\\vspace{4pt} \\n\\n    If $P$ is a regular $m \\\\times m$ stochastic matrix with $m \\\\ge 2$, then:\\n    \\n    \\\\begin{itemize}\\n        \\\\item for any initial probability vector $\\\\vec x_0$, $\\\\displaystyle \\\\lim_{n \\\\rightarrow \\\\infty} P^n \\\\vec x_0 = \\\\vec q$ \\\\pause\\n        \\\\item $P$ has a unique eigenvector, $\\\\vec q$, which has eigenvalue $\\\\lambda = 1$ \\\\pause    \\n        \\\\item there is a stochastic matrix $\\\\Pi$ such that $\\\\displaystyle \\\\lim_{n \\\\rightarrow \\\\infty} P^n = \\\\Pi$ \\\\pause\\n        \\\\item each column of $\\\\Pi$  is the same probability vector $\\\\vec q$ \\\\pause\\n        \\\\item the eigenvalues of $P$ satisfy $|\\\\lambda| \\\\le 1$ \\n    \\\\end{itemize}'],\n",
       "  '5_5_1.tex': [],\n",
       "  '5_PR_2.tex': [],\n",
       "  '5_3_2.tex': ['If $A$ is $n\\\\times n$ and has $n$ distinct eigenvalues, then $A$ is diagonalizable.'],\n",
       "  '5_2_4.tex': ['$n \\\\times n$ matrices $A$ and $B$ are \\\\Emph{similar} if there is a $P$ so that $A = PBP^{-1}$.',\n",
       "   'If $A$ and $B$ similar, then they have the same characteristic polynomial.'],\n",
       "  '5_3_1.tex': ['A matrix is \\\\Emph{diagonal} if the only non-zero elements, if any, are on the main diagonal.',\n",
       "   'Suppose $A \\\\in \\\\R^{n \\\\times n}$. We say that $A$ is \\\\Emph{diagonalizable} if it is similar to a diagonal matrix, $D$. That is, we can write $A = PDP^{-1}$.',\n",
       "   'If $ A$ is diagonalizable $\\\\Leftrightarrow A$ has $n$ linearly independent eigenvectors.'],\n",
       "  'images': [],\n",
       "  '5_2_1.tex': [],\n",
       "  '5_1_2.tex': ['Suppose $A \\\\in \\\\R^{n \\\\times n}$. The eigenvectors for a given $\\\\lambda$ span a subspace of $\\\\R^n$ called the $\\\\lambda$-\\\\Emph{eigenspace} of $A$.'],\n",
       "  '5_5_3.tex': ['A matrix of the form $C =  \\\\spalignmat{ a  -b ; b  a }$ is a \\\\Emph{rotation-dilation matrix} \\\\pause because it is the composition of a rotation by $\\\\phi$ and dilation by $r$, \\\\pause where \\n        $$r^2 = a^2 + b^2, \\\\quad \\\\tan \\\\phi = \\\\frac ba$$\\n        \\\\pause Moreover, the eigenvalues of $C$ are $\\\\lambda = a \\\\pm bi$.']},\n",
       " 'Chapter6': {'6_2_3.tex': ['An $ m \\\\times n$ matrix $ U$ has orthonormal columns if and only if $ U ^{T} U = I_n $.',\n",
       "   'Suppose  $ m \\\\times n$ matrix $U$ has orthonormal columns and $\\\\vec x$ and $\\\\vec y$ are vectors in $\\\\mathbb R^n$. \\n\\n    \\\\begin{enumerate}\\n        \\\\item<2-> $ \\\\lVert U \\\\vec x\\\\rVert = \\\\lVert \\\\vec x \\\\rVert$\\n        \\\\item<3-> $ (U \\\\vec x  ) \\\\cdot (U \\\\vec y) = \\\\vec x \\\\cdot \\\\vec y$\\n        \\\\item<4-> $ (U \\\\vec x  ) \\\\cdot (U \\\\vec y) = 0$ if and only if $\\\\vec x \\\\cdot \\\\vec y = 0$\\n    \\\\end{enumerate}'],\n",
       "  '6_1_2.tex': ['Two vectors $ \\\\vec u$ and $ \\\\vec v$ are \\\\Emph{orthogonal} if $ \\\\vec u \\\\cdot \\\\vec v =0$.  \\n    This is equivalent to: \\n    \\\\begin{equation*}\\n    \\\\lVert \\\\vec u + \\\\vec v \\\\rVert ^2 =  \\\\lVert \\\\vec u  \\\\lVert^2  +  \\\\lVert  \\\\vec v \\\\rVert ^2\\n    \\\\end{equation*}'],\n",
       "  '6_4_1.tex': [],\n",
       "  '6_6_3.tex': [],\n",
       "  '6_1_4.tex': ['\\\\begin{tikzpicture} \\\\node [mybox](box){\\\\begin{minipage}{0.75\\\\textwidth}\\n        \\\\vspace{2pt}\\n        \\n        Row$A$ is the space spanned by the rows of matrix $A$.',\n",
       "   'For any $ A \\\\in \\\\mathbb R^{m\\\\times n}$,  the orthogonal complement of $\\\\Row A$ is $ \\\\Null A$, and the orthogonal complement of $ \\\\Col A$ is  $ \\\\Null A ^{T}$.'],\n",
       "  '6_4_3.tex': ['A set of vectors form an \\\\Emph{orthonormal basis} if the vectors are mutually orthogonal and have unit length.',\n",
       "   '\\\\vspace{2pt}\\n\\n    Any  $ m \\\\times n $ matrix $A$ with linearly independent columns has the \\\\Emph{QR factorization}\\n    \\\\begin{equation*}\\n        A = Q R \\n    \\\\end{equation*}\\n    where \\n\\n    \\\\begin{itemize}\\n        \\\\item $ Q$ is $ m \\\\times n$, its columns are an orthonormal basis for $ \\\\operatorname {Col} A$. \\n        \\\\item $ R$ is $ n \\\\times n$, upper triangular, with positive entries on its diagonal % and \\n    \\\\end{itemize}'],\n",
       "  '6_5_3.tex': ['If $A \\\\in \\\\mathbb R^{m \\\\times n}$ has linearly independent columns, then $A = QR$, and for every $ \\\\vec b\\\\in \\\\mathbb R ^{m}$, $ A \\\\vec x=\\\\vec b$ has the unique least-squares solution \\\\onslide<2->{\\n        \\\\begin{equation*}\\n            R\\\\widehat x =  Q ^{T} \\\\vec b.\\n        \\\\end{equation*}}\\n    \\\\vspace{-12pt}'],\n",
       "  '6_2_1.tex': ['A set of vectors $ \\\\{\\\\vec u_1 ,\\\\dotsc, \\\\vec u_p\\\\}$ are an \\\\Emph{orthogonal set} of vectors if for each $ j\\\\neq k$, $ \\\\vec u_j \\\\perp \\\\vec u_k$.',\n",
       "   'Let  $S = \\\\{\\\\vec u_1 ,\\\\dotsc, \\\\vec u_p\\\\}$ be an \\\\Emph{orthogonal set} of vectors.  %Then, for scalars $ c_1 ,\\\\dotsc, c_p$, \\n    % \\\\begin{equation*}\\n    % \\\\bigl\\\\lVert c_1 \\\\vec u_1 + \\\\cdots + c_p \\\\vec u_p  \\\\bigr\\\\rVert ^2 \\n    % = c_1 ^2 \\\\lVert \\\\vec u_1 \\\\rVert ^2 + \\\\cdots + c_p ^2 \\\\lVert \\\\vec u_p\\\\rVert ^2 . \\n    % \\\\end{equation*}    In particular, \\n    If $ \\\\vec u_i$ are non-zero, the then $S$ is a set of \\\\Emph{linearly independent} vectors.',\n",
       "   'Let  $ \\\\{\\\\vec u_1 ,\\\\dotsc, \\\\vec u_p\\\\}$ be an orthogonal  basis for a subspace $ W$ of $ \\\\mathbb R ^{n}$. Then, for any vector $ \\\\vec w\\\\in W$, \\n        \\\\begin{equation*}\\n            \\\\vec w= c_1  \\\\vec u_1   + \\\\cdots + c_p   \\\\vec u_p  . \\n        \\\\end{equation*}\\n        Above, the scalars are $ \\\\displaystyle c_ q = \\\\frac { \\\\vec w \\\\, \\\\cdot \\\\, \\\\vec u_q } { \\\\vec u _{q} \\\\cdot \\\\, \\\\vec u_q }$.',\n",
       "   'An \\\\Emph{orthonormal basis} for a subspace $ W$ is an orthogonal basis $ \\\\{\\\\vec u_1 ,\\\\dotsc, \\\\vec u_p\\\\}$ \\n        in which every vector $ \\\\vec u_q$ has unit length.  In this case, for each $ \\\\vec w\\\\in W$,  \\n        \\\\begin{gather*}\\n        \\\\vec w = (\\\\vec w \\\\cdot \\\\vec u_1) \\\\vec u_1 + \\\\cdots +  (\\\\vec w \\\\cdot \\\\vec u_p ) \\\\vec u_p\\n        \\\\\\\\\\n        \\\\lVert \\\\vec w \\\\rVert  =  \\\\sqrt{(\\\\vec w \\\\cdot \\\\vec u_1) ^2 + \\\\cdots +  (\\\\vec w \\\\cdot \\\\vec u_p) ^2} \\n    \\\\end{gather*}'],\n",
       "  '6_3_1.tex': ['\\\\vspace{4pt}\\n        Let $ W$ be a subspace of $ \\\\mathbb R ^{n}$.   Then, each vector $ \\\\vec y \\\\in \\\\mathbb R ^{n}$ has the \\\\Emph{unique} decomposition \\n        \\\\begin{equation*}\\n            \\\\vec y =   \\\\widehat y  +  z, \\\\quad  \\\\widehat y  \\\\in W, \\\\quad   z \\\\in W ^{\\\\perp}. \\n        \\\\end{equation*}\\n    \\n        And, if $  \\\\vec u_1 ,\\\\dotsc, \\\\vec u_p$ is any orthogonal basis for $ W$, \\n        \\\\begin{equation*}\\n            \\\\widehat y =  \\\\frac {\\\\vec y \\\\cdot \\\\vec u_1} {\\\\vec u_1 \\\\cdot \\\\vec u_1} \\\\vec u_1 + \\\\cdots + \\n            \\\\frac {\\\\vec y \\\\cdot \\\\vec u_p} {\\\\vec u_p \\\\cdot \\\\vec u_p} \\\\vec u_p. \\n        \\\\end{equation*}\\n        We say that $ \\\\widehat y  $ is the \\\\Emph{orthogonal projection of $ \\\\vec y$ onto $ W$.}'],\n",
       "  '6_5_2.tex': ['The least-squares solutions to $ A \\\\vec x = \\\\vec b $ coincide with the solutions to \\n    $$\\n        A ^{T} A \\\\widehat x = A ^{T} \\\\vec b\\n    $$\\n    This linear system is referred to as the \\\\Emph{Normal Equations}.',\n",
       "   'Let $A$ be any $ m \\\\times n$ matrix.  These statements are equivalent.  \\n    %%  itemize\\n    \\\\begin{itemize}\\n    \\\\item<2-> The columns of $ A$ are linearly independent. \\n    \\\\item<3-> The matrix $  A ^{T} A $ is invertible.  \\n    \\\\item<4-> The equation $ A \\\\vec x = \\\\vec b $  has a unique least-squares solution for each $ \\\\vec b \\\\in \\\\mathbb R ^{m}$. \\n    \\\\end{itemize}\\n    %% itemize\\n    \\\\vspace{4pt} \\n    \\\\onslide<5->{If the above statements hold, the least square solution is} $$\\\\onslide<5->{\\\\widehat x = ( A ^{T} A ) ^{-1} A ^{T} \\\\vec b.}$$\\n    \\\\vspace{-24pt}'],\n",
       "  '6_1_3.tex': ['\\\\vspace{2pt} \\n\\n    Let $W$ be a subspace of $\\\\mathbb R ^{n}$.  Vector $\\\\vec z \\\\in \\\\mathbb R ^{n}$ is \\\\Emph{orthogonal} to $W$ if $\\\\vec z$ is orthogonal to every vector in $W$.\\n\\n    \\\\vspace{12pt} \\n\\n    The set of all vectors orthogonal to $ W$ is a subspace, the \\\\Emph{orthogonal compliment} of $W$, or $ W ^{\\\\perp}$.\\n    \\\\begin{equation*}\\n        W ^{\\\\perp} = \\\\{ \\\\vec z \\\\in \\\\mathbb R ^{n}  \\\\;:\\\\;  \\\\vec z \\\\cdot  \\\\vec w = 0 \\\\ \\\\text{for all } \\\\vec w \\\\in W \\\\} \\n    \\\\end{equation*}'],\n",
       "  '6_5_1.tex': ['Let $ A$ be an $ m \\\\times n $ matrix. \\n        A \\\\Emph{least-squares solution to $ A \\\\vec x = \\\\vec b$} is \\\\onslide<2->{ the solution $ \\\\widehat x $ for which} \\\\onslide<3->{ \\n        \\\\begin{equation*}\\n            \\\\lVert \\\\, \\\\vec b - A \\\\widehat x \\\\, \\\\rVert \\\\leq \\\\lVert \\\\, \\\\vec b - A  \\\\vec x \\\\, \\\\rVert \\n        \\\\end{equation*}\\n        for all $\\\\vec x\\\\in \\\\mathbb R ^{n}$.}'],\n",
       "  'images': [],\n",
       "  '6_3_2.tex': ['Let $ W$ be a subspace of $ \\\\mathbb R ^{n}$,  $ \\\\vec y \\\\in \\\\mathbb R ^{n}$, and $ \\\\widehat y $ is the orthogonal projection of $ \\\\vec y$ onto $ W$.  \\\\onslide<2->{ Then for \\\\Emph{any} $ \\\\vec v \\\\neq \\\\hat y$, $\\\\vec v  \\\\in W$, we have\\n    \\\\begin{equation*}\\n    \\\\lVert \\\\vec y - \\\\widehat y \\\\rVert< \\\\lVert \\\\vec y - \\\\vec v \\\\rVert\\n    \\\\end{equation*}\\n    }\\n    \\\\onslide<3->{That is, $ \\\\widehat y $ is the unique vector in $ W$ that is closest to $ \\\\vec y$.  }'],\n",
       "  '6_6_2.tex': [],\n",
       "  '6_2_2.tex': ['Let $ \\\\vec u$ be a non-zero vector in $\\\\mathbb R^n$, and let $ \\\\vec y$ be any vector in $\\\\mathbb R^n$.  The \\\\Emph{orthogonal projection of $ \\\\vec y$ onto $ \\\\vec u$} is the vector in the span of $ \\\\vec u$ that is closest to $ \\\\vec y$. \\n    \\\\begin{equation*}\\n        \\\\textup{proj} _{\\\\vec u} \\\\, \\\\vec y = \\\\frac {\\\\vec y \\\\cdot \\\\vec u} {\\\\vec u \\\\cdot \\\\vec u} \\\\vec u \\n    \\\\end{equation*}\\n    Moreover, $\\\\vec y = \\\\widehat y + \\\\vec z$, where $\\\\vec z \\\\in W\\\\Perp$.'],\n",
       "  '6_4_2.tex': [],\n",
       "  '6_6_1.tex': [],\n",
       "  '6_1_1.tex': ['The \\\\Emph{length} of a vector $\\\\vec u \\\\in \\\\mathbb R^n$ is  \\\\begin{equation*}\\n            \\\\lVert \\\\vec u\\\\rVert = \\\\sqrt { \\\\vec u \\\\cdot \\\\vec u} = \\n            \\\\sqrt {  u_1 ^2 + u_2 ^2 + \\\\cdots + u_n ^2 }\\n        \\\\end{equation*}',\n",
       "   'If $ \\\\vec v \\\\in \\\\mathbb R^n$ has length one, we say that it is a \\\\Emph{unit vector.}',\n",
       "   'For $ \\\\vec u, \\\\vec v \\\\in \\\\mathbb R ^{n}$, the \\\\Emph{distance} between $ \\\\vec u$ and $ \\\\vec v$ is given by the formula $||\\\\vec u - \\\\vec v ||$.',\n",
       "   '\\\\begin{tikzpicture} \\\\node [mybox](box){\\\\begin{minipage}{0.65\\\\textwidth}\\n        \\\\vspace{2pt}\\n        \\n        $ \\\\vec a \\\\cdot \\\\vec b= ||\\\\vec a|| \\\\, ||\\\\vec b|| \\\\,  \\\\cos\\\\theta$. Thus, if $\\\\vec a \\\\cdot \\\\vec b = 0$, then: \\n        \\\\begin{itemize} \\\\setlength\\\\itemsep{0.25em}\\n            \\\\item<2-> $ \\\\vec a$ and/or $ \\\\vec b$ are zero vectors, or \\n            \\\\item<3-> $ \\\\vec a$ are $ \\\\vec b$ are perpendicular to each other. % orthogonal \\n        \\\\end{itemize}']},\n",
       " 'Chapter7': {'7_4_5_FourFund.tex': [],\n",
       "  '7_1_3.tex': [],\n",
       "  '7_3_2.tex': [],\n",
       "  '7_4_5_Cond.tex': [],\n",
       "  '7_1_1.tex': ['If matrix $ A = A^T$, then $A$ is \\\\Emph{symmetric}.'],\n",
       "  '7_4_4.tex': [],\n",
       "  '7_2_2.tex': ['If $A$ is a symmetric matrix then there exists an orthogonal change of variable $\\\\vec x = P \\\\vec y$ that transforms $\\\\vec x^{\\\\,T} A \\\\vec x$ to $\\\\vec y^{\\\\,T} D \\\\vec y$ with no cross-product terms.'],\n",
       "  '7_2_1.tex': ['A \\\\Emph{quadratic form} is a function $ Q \\\\;:\\\\; \\\\mathbb R ^{n} \\\\to \\\\mathbb R $, given by \\n    \\\\begin{equation*}\\n        Q (\\\\vec x ) =  \\\\vec x ^{\\\\, T} A \\\\vec x   = \\n    \\\\begin{pmatrix}\\n        x_1 & x _2 & \\\\cdots & x_n \\n    \\\\end{pmatrix} \\\\begin{pmatrix}\\n        a_ {11} & a _{12} & \\\\cdots & a _{1n} \\n        \\\\\\\\\\n        a _{12} & a _{22}  & \\\\cdots & a _{2n} \\n        \\\\\\\\ \\n        \\\\vdots &   \\\\vdots & \\\\ddots &   \\\\vdots \\n        \\\\\\\\\\n        a _{1n} & a _{2n} & \\\\cdots & a _{nn}\\n    \\\\end{pmatrix}\\n    \\\\begin{pmatrix}\\n        x_1 \\\\\\\\ x _2\\\\\\\\ \\\\vdots \\\\\\\\ x_n \\n    \\\\end{pmatrix}\\n    \\\\end{equation*}\\n    Matrix $ A$ is $n \\\\times n$ and symmetric.'],\n",
       "  '7_1_2.tex': ['If $ A$ is a symmetric matrix, with eigenvectors $ \\\\vec v_1$ and $ \\\\vec v_2$ corresponding to two distinct eigenvalues, then $\\\\vec v_1$ and $\\\\vec v_2$ are orthogonal.  \\\\\\\\\\n    \\n    More generally, eigenspaces associated to distinct eigenvalues are orthogonal subspaces.',\n",
       "   'An $ n \\\\times n $ symmetric matrix $A$ has the following properties.\\n    \\n    \\\\vspace{6pt}\\n\\n    \\\\begin{itemize} \\\\setlength\\\\itemsep{4pt}\\n        \\\\item All eigenvalues of $ A$ are real.\\n        \\\\item The eigenspaces are mutually orthogonal. \\n        \\\\item $ A$ can be diagonalized as $  A = P D P ^{T}$, where $D$ is diagonal and $ P$ is orthogonal.\\n    \\\\end{itemize}'],\n",
       "  'images': [],\n",
       "  '7_4_5_Spectral.tex': [],\n",
       "  '7_4_3.tex': ['Suppose $A$ is an $ m \\\\times n$ matrix with singular values $ \\\\sigma_1 \\\\geq \\\\sigma _2 \\\\geq \\\\cdots \\\\geq \\\\sigma _n  $ and $m \\\\ge n$. \\\\onslide<2->{Then $A$ has the decomposition $A = U \\\\Sigma V ^{T}$ where }\\\\onslide<3->{\\n        \\\\begin{equation*}\\n            \\\\Sigma = \\\\spalignmat{D;\\\\mathbf{0}_{m-n,n}}, \\\\\\n            D = \\n            \\\\begin{pmatrix}\\n                \\\\sigma _1 & 0 & \\\\ldots & 0   \\n                \\\\\\\\\\n                0 & \\\\sigma _2 & \\\\ldots   &  \\\\vdots \\n                \\\\\\\\\\n                \\\\vdots & \\\\vdots & \\\\ddots & \\\\vdots\\n                \\\\\\\\\\n                0 & 0& \\\\ldots & \\\\sigma _n  \\n            \\\\end{pmatrix}\\n        \\\\end{equation*} }\\n        \\\\onslide<4->{$U$ is a $ m \\\\times m $ orthogonal matrix, and $ V $ is a $ n \\\\times n$ orthogonal matrix. }\\\\onslide<5->{If $m < n$, then $\\\\Sigma = \\\\spalignmat{D \\\\mathbf0_{m,n-m}}$ with everything else the same. }'],\n",
       "  '7_3_3.tex': ['Suppose $Q = \\\\vec x^{\\\\, T} A \\\\vec x$, where $A \\\\in \\\\mathbb R^{n\\\\times n}$ is symmetric and has eigenvalues\\n        $$\\\\lambda_1 \\\\ge \\\\lambda_2 \\\\ldots \\\\ge \\\\lambda_n$$\\n        and associated eigenvectors\\n        $$\\\\vec u_1, \\\\vec u_2, \\\\ldots , \\\\vec u_n$$\\n        \\\\onslide<2->{Subject to the constraints $||\\\\vec x ||=1$ and} \\\\onslide<3->{$\\\\vec x \\\\cdot \\\\vec u_1 = 0$,}\\n        \\\\begin{itemize}\\n            \\\\item<4-> the maximum value of $Q(\\\\vec x) = \\\\lambda_{2}$, attained at $\\\\vec x = \\\\vec u_{2}$\\n            \\\\item<5-> the minimum value of $Q(\\\\vec x) = \\\\lambda_n$, attained at $\\\\vec x = \\\\vec u_n$\\n        \\\\end{itemize}\\n        \\n        % \\\\vspace{6pt} \\n        \\n        % Note that $\\\\lambda_2$ is the second largest eigenvalue of $A$.'],\n",
       "  '7_4_1.tex': ['The singular values of any $m\\\\times n$ real matrix $A$ are the square roots of the eigenvalues of $A^TA$.',\n",
       "   'The eigenvalues of $ A ^{T} A $ are non-negative.',\n",
       "   'The singular values, $\\\\sigma_j$, of any $m\\\\times n$ real matrix $A$ are the square roots of the eigenvalues of $A^TA$. Singular values are arranged in decreasing order.\\n        \\n        $$\\\\sigma _1 = \\\\sqrt {\\\\lambda _1 } \\\\geq \\\\sigma _2 = \\\\sqrt {\\\\lambda _2}  \\\\geq \\\\ \\\\cdots \\\\ \\\\geq \\\\sigma _n=\\\\sqrt {\\\\lambda _n} $$'],\n",
       "  '7_3_1.tex': ['If $Q = \\\\vec x^{\\\\, T} A \\\\vec x$, $A$ is a real $n\\\\times n$ symmetric matrix, with eigenvalues \\n        $$\\\\lambda_1 \\\\ge \\\\lambda_2 \\\\ldots \\\\ge \\\\lambda_n$$\\n        and associated normalized eigenvectors \\n        $$\\\\vec u_1, \\\\vec u_2, \\\\ldots , \\\\vec u_n$$\\n        \\\\onslide<2->{Then, subject to the constraint $||\\\\vec x ||=1$, }\\n        \\\\begin{itemize}\\n            \\\\item<3-> the \\\\Emph{maximum} value of $Q(\\\\vec x) = \\\\lambda_1$, attained at $\\\\vec x = \\\\pm \\\\, \\\\vec u_1$.\\n            \\\\item<4-> the \\\\Emph{minimum} value of $Q(\\\\vec x) = \\\\lambda_n$, attained at $\\\\vec x = \\\\pm \\\\, \\\\vec u_n$.\\n        \\\\end{itemize}'],\n",
       "  '7_4_2.tex': ['For any $ A \\\\in \\\\mathbb R^{m\\\\times n}$,  the orthogonal complement of $\\\\Row A$ is $ \\\\Null A$, and the orthogonal complement of $ \\\\Col A$ is  $ \\\\Null A ^{T}$.',\n",
       "   'Suppose $\\\\vec v_i$ are the $n$ orthogonal eigenvectors of $A^TA$, ordered so that their corresponding eigenvalues satisfy $\\\\lambda_1 \\\\ge \\\\lambda_2 \\\\ge \\\\ldots \\\\ \\\\ge \\\\lambda_n$. \\\\onslide<2->{Suppose also that $A$ has $r$ non-zero singular values, $r \\\\le n$. }\\\\onslide<3->{Then the set of vectors $$\\\\{\\\\vec v_{r+1},  \\\\vec v_{r+2}, \\\\ \\\\ldots \\\\ , \\\\vec v_n\\\\}$$ is an orthogonal basis for $\\\\Nul A$, and the set $$\\\\{\\\\vec v_{1},  \\\\vec v_{2}, \\\\ \\\\ldots \\\\ , \\\\vec v_r\\\\}$$ is an orthogonal basis for $\\\\Row A$, and $\\\\text{rank} A = r$. }',\n",
       "   'Suppose $\\\\vec v_i$ are the $n$ orthonormal eigenvectors of $A^TA$, ordered so that their corresponding eigenvalues satisfy $\\\\lambda_1 \\\\ge \\\\lambda_2 \\\\ge \\\\ldots \\\\ \\\\ge \\\\lambda_n$. \\\\onslide<2->{Suppose also that $A$ has $r$ non-zero singular values. }\\\\onslide<3->{Then $$\\\\{A\\\\vec v_1, A\\\\vec v_2, \\\\ \\\\ldots \\\\ , A\\\\vec v_r\\\\}$$ are an orthogonal basis for $\\\\Col A$.}',\n",
       "   'The vectors $\\\\{\\\\vec u_i\\\\}$ for $i \\\\le m$ are the \\\\Emph{left singular vectors} of $A$. \\n        The vectors $\\\\{\\\\vec v_i\\\\}$ for $i \\\\le n$ are the \\\\Emph{right singular vectors} of $A$.'],\n",
       "  '7_2_3.tex': ['A quadratic form $Q$ is \\n        \\\\begin{itemize}\\n            \\\\item<2-> \\\\Emph{positive definite} if $Q > 0$ for all $\\\\vec x \\\\ne \\\\vec 0$.\\n            \\\\item<2-> \\\\Emph{negative definite} if $Q<0$ for all $\\\\vec x \\\\ne \\\\vec 0$.\\n            \\\\item<3-> \\\\Emph{positive semidefinite} if $Q\\\\ge0$ for all $\\\\vec x$.\\n            \\\\item<3-> \\\\Emph{negative semidefinite} if $Q\\\\le0$ for all $\\\\vec x$.\\n            \\\\item<4-> \\\\Emph{indefinite} if $Q$ takes on positive and negative values for $\\\\vec x \\\\ne \\\\vec 0$.\\n        \\\\end{itemize}',\n",
       "   '\\\\linespread{1.5}\\n    \\n        If $A$ is a symmetric matrix with eigenvalues $\\\\lambda_i$, then $Q = \\\\vec x^{\\\\,T} A \\\\vec x$ is \\n        \\n        \\\\begin{itemize}\\n            \\\\item \\\\onslide<2->{\\\\Emph{positive definite} when all eigenvalues are positive}\\n            \\\\item \\\\onslide<2->{\\\\Emph{negative definite} when all eigenvalues are negative}\\n            \\\\item \\\\onslide<3->{\\\\Emph{indefinite} when at least one eigenvalue is negative and at least one eigenvalue is positive}\\n        \\\\end{itemize}']}}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "63074ff0-8929-4b97-b214-172ecb0626d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/LinearLecNotes_Definitions.json\", \"w\") as f:\n",
    "    json.dump(all_matches, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "81ec431e-a052-439e-9bed-37026c7704b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The set of all possible values of $x_1, x_2, \\\\ldots x_n$ that satisfy all equations is the \\\\Emph{solution set} of the system. \\\\pause One point in the solution set is a \\\\Emph{solution}.'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
