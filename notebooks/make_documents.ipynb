{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a4603a-9537-4f33-a470-4e9d5ab83c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pathlib\n",
    "import textwrap\n",
    "import os\n",
    "import time\n",
    "from pylatexenc.latexencode import unicode_to_latex\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf4e82f-1d27-46b5-86b1-8f5f900f8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"./batch_responses/tf_197_content_id.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line)\n",
    "        custom_id = json_object['custom_id'].split('|')\n",
    "        q = json_object['response']['body']['choices'][0][\"message\"][\"content\"]\n",
    "        q = q.replace(\"`\", \"\").replace(\"json\", \"\").replace(\"\\n\", \"\").replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        q = q[q.find(\"{\"):]\n",
    "        q = q.replace(\",}\", \"}\")\n",
    "        try:\n",
    "            json_question = json.loads(q)\n",
    "        except:\n",
    "            print(q)\n",
    "            break\n",
    "        json_question['chapter'] = custom_id[0]\n",
    "        json_question['section'] = custom_id[1]\n",
    "        json_question['number'] = custom_id[2]\n",
    "        questions.append(json_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f393441-84d3-423a-9a34-3c285cef2138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'True or False: If $x$ and $y$ are continuous functions of $t$ on an interval $I$, then the set of points $(x,y)$ obtained as $t$ varies over $I$ is called a parametric curve and is denoted by $C$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A parametric curve, also known as a plane curve, is defined by the set of points $(x,y)$ where $x = x(t)$ and $y = y(t)$ are continuous functions of $t$ over an interval $I$. As $t$ varies within this interval, the points $(x, y)$ trace out the curve $C$. For example, if $x(t) = \\\\cos(t)$ and $y(t) = \\\\sin(t)$ for $t \\\\in [0, 2\\\\pi]$, the parametric equations describe a circle.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-1-parametric-equations',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False? For the plane curve defined by the parametric equations $x = x(t)$ and $y = y(t)$, if both $x'(t)$ and $y'(t)$ exist and $x'(t) \\\\neq 0$, then the derivative $\\\\\\\\frac{dy}{dx}$ is given by $\\\\\\\\frac{dy}{dt} \\\\\\\\over \\\\\\\\frac{dx}{dt} = \\\\\\\\frac{y'(t)}{x'(t)}$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The derivative $\\\\\\\\frac{dy}{dx}$ for a plane curve defined by the parametric equations $x = x(t)$ and $y = y(t)$ can be computed using the chain rule. Since $\\\\\\\\frac{dx}{dt} = x'(t)$ and $\\\\\\\\frac{dy}{dt} = y'(t)$, the derivative $\\\\\\\\frac{dy}{dx}$ is obtained as $\\\\\\\\frac{dy}{dt} \\\\\\\\over \\\\\\\\frac{dx}{dt} = \\\\\\\\frac{y'(t)}{x'(t)}$. This result shows that instead of differentiating $y$ directly with respect to $x$, we first differentiate $y$ and $x$ with respect to the parameter $t$ and then take their ratio. This method is particularly useful when dealing with curves defined parametrically.\",\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-2-calculus-of-parametric-curves',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: The area under a non-self-intersecting plane curve defined by the parametric equations $x = x(t)$ and $y = y(t)$, for $a \\\\leq t \\\\leq b$, can be found using $A = \\\\int_{a}^{b} y(t) x'(t) \\\\, dt$ if $x(t)$ is differentiable.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The area under a parametric curve can be determined using the given integral formula. Parametric curves are defined by equations $x = x(t)$ and $y = y(t)$, where $t$ runs from $a$ to $b$. For the area $A$ under the curve to be calculated, the function $x(t)$ must be differentiable, allowing us to use $x'(t)$ in the integral $\\\\int_{a}^{b} y(t) x'(t) \\\\, dt$. This formula accumulates small trapezoids formed by the width $dx = x'(t) \\\\, dt$ and height $y(t)$ over the interval from $t = a$ to $t = b$, summing to the total area.\",\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-2-calculus-of-parametric-curves',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The arc length of a parametric curve defined by $x = x(t)$ and $y = y(t)$ for $t_1 \\\\le t \\\\le t_2$, where $x(t)$ and $y(t)$ are differentiable functions of $t$, is given by $s = \\\\int_{t_1}^{t_2} \\\\sqrt{ \\\\left( \\\\frac{dx}{dt} \\\\right)^2 + \\\\left( \\\\frac{dy}{dt} \\\\right)^2 } \\\\, dt$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The arc length formula for a parametric curve $x = x(t)$ and $y = y(t)$ for $t_1 \\\\le t \\\\le t_2$, where both $x(t)$ and $y(t)$ are differentiable with respect to $t$, is $s = \\\\int_{t_1}^{t_2} \\\\sqrt{ \\\\left( \\\\frac{dx}{dt} \\\\right)^2 + \\\\left( \\\\frac{dy}{dt} \\\\right)^2 } \\\\, dt$. This formula accounts for the infinitesimal distances along the curve as $t$ varies, combining the changes in $x$ and $y$ coordinates, which are squared and then summed before taking the square root. This ensures the calculation of the actual distances moved along the curve. For example, if $x(t) = t$ and $y(t) = t^2$ for $t$ in $[0, 1]$, the arc length would involve integrating $ \\\\sqrt{1 + (2t)^2} \\\\, dt $ from 0 to 1.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-2-calculus-of-parametric-curves',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: Given a point \\\\( P \\\\) in the plane with Cartesian coordinates \\\\((x, y)\\\\) and polar coordinates \\\\((r, \\\\theta)\\\\), it is possible to determine \\\\( r \\\\) and \\\\( \\\\theta \\\\) using the equations \\\\( x = r \\\\cos \\\\theta \\\\) and \\\\( y = r \\\\sin \\\\theta \\\\).',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'While the equations \\\\( x = r \\\\cos \\\\theta \\\\) and \\\\( y = r \\\\sin \\\\theta \\\\) are used to convert from polar coordinates to Cartesian coordinates, they are not sufficient by themselves to determine \\\\( r \\\\) and \\\\( \\\\theta \\\\) from \\\\( x \\\\) and \\\\( y \\\\). For conversion from Cartesian to polar coordinates, we use the formulas \\\\( r = \\\\sqrt{x^2 + y^2} \\\\) and \\\\( \\\\tan \\\\theta = \\\\frac{y}{x} \\\\). These allow us to find \\\\( r \\\\) and \\\\( \\\\theta \\\\) given \\\\( x \\\\) and \\\\( y \\\\). For example, given the Cartesian coordinates (3, 4), we calculate \\\\( r \\\\) as \\\\( r = \\\\sqrt{3^2 + 4^2} = 5 \\\\) and \\\\( \\\\theta \\\\) as \\\\( \\\\theta = \\\\tan^{-1} (\\\\frac{4}{3}) \\\\).',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-3-polar-coordinates',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: If a polar curve given by the equation $r = f(\\\\\\\\theta)$ is symmetric about the vertical line $\\\\\\\\theta = \\\\\\\\frac{\\\\\\\\pi}{2}$, then for every point $(r, \\\\\\\\theta)$ on the graph, the point $(r, \\\\\\\\pi - \\\\\\\\theta)$ is also on the graph.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'According to the definition of symmetry in polar curves, a curve is symmetric about the vertical line $\\\\\\\\theta = \\\\\\\\frac{\\\\\\\\pi}{2}$ if for every point $(r, \\\\\\\\theta)$ on the graph, the point $(r, \\\\\\\\pi - \\\\\\\\theta)$ is also on the graph. This symmetry implies that replacing $\\\\\\\\theta$ with $\\\\\\\\pi - \\\\\\\\theta$ leaves the equation $r = f(\\\\\\\\theta)$ unchanged. For example, if $r = 2 + \\\\\\\\cos(\\\\\\\\theta)$, replacing $\\\\\\\\theta$ with $\\\\\\\\pi - \\\\\\\\theta$ gives us $r = 2 + \\\\\\\\cos(\\\\\\\\pi - \\\\\\\\theta)$, which simplifies to $r = 2 - \\\\\\\\cos(\\\\\\\\theta)$. If the resulting equation is the same, the curve demonstrates this symmetry.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-3-polar-coordinates',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The area of a region bounded by the graph of a polar curve $r = f(θ)$, with $f(θ)$ being continuous and nonnegative over the interval $α ≤ θ ≤ β$ and $0 < β - α ≤ 2π$, is given by $A = \\\\frac{1}{2} \\\\int_{α}^{β} [f(θ)]^2 \\\\, dθ = \\\\frac{1}{2} \\\\int_{α}^{β} r^2 \\\\, dθ$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given statement is true based on the standard formula for the area of a region bounded by a polar curve. For the polar curve $r = f(θ)$, which is continuous and nonnegative over the interval $α ≤ θ ≤ β$ and $0 < β - α ≤ 2π$, the area $A$ of the region can be calculated using the formula $A = \\\\frac{1}{2} \\\\int_{α}^{β} [f(θ)]^2 \\\\, dθ = \\\\frac{1}{2} \\\\int_{α}^{β} r^2 \\\\, dθ$. This formula derives from the concept of adding up infinitesimally small sectors of a circle to find the total area. An example to illustrate this is the area enclosed by a circle in polar coordinates with radius $r = a$, giving the area $A = \\\\frac{1}{2} \\\\int_{0}^{2π} a^2 \\\\, dθ = \\\\pi a^2$.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-4-area-and-arc-length-in-polar-coordinates',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: The arc length $L$ of a curve defined by a polar function $r=f(\\\\\\\\theta)$ from $\\\\\\\\theta=\\\\\\\\alpha$ to $\\\\\\\\theta=\\\\\\\\beta$ is given by $L=\\\\\\\\int_\\\\\\\\alpha^\\\\\\\\beta \\\\\\\\sqrt{[f(\\\\\\\\theta)]^2 + [f'(\\\\\\\\theta)]^2} d\\\\\\\\theta$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The formula provided for the arc length $L$ of a curve defined by a polar function is correct. The expression $L=\\\\\\\\int_\\\\\\\\alpha^\\\\\\\\beta \\\\\\\\sqrt{[f(\\\\\\\\theta)]^2 + [f'(\\\\\\\\theta)]^2} d\\\\\\\\theta$ accurately represents the arc length, where $r=f(\\\\\\\\theta)$ is the given polar function, and $f'(\\\\\\\\theta)$ is its derivative with respect to $\\\\\\\\theta$. This underlines the need to account for both the function $r$ and its rate of change $dr/d\\\\\\\\theta$ while integrating over the interval $[\\\\\\\\alpha, \\\\\\\\beta]$. For example, if $r=f(\\\\\\\\theta)=\\\\\\\\theta$ and $\\\\\\\\alpha=0$, $\\\\\\\\beta=\\\\\\\\pi$, the arc length would incorporate both $\\\\\\\\theta^2$ and $1$ within the integral.\",\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-4-area-and-arc-length-in-polar-coordinates',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: In the definition of a parabola, the distance from any point on the parabola to the focus is equal to the distance from that point to the directrix.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of a parabola states that it is the set of all points \\\\( P \\\\) such that the distance from \\\\( P \\\\) to a fixed point (the focus) is equal to the distance from \\\\( P \\\\) to a fixed line (the directrix). This means if you choose any point \\\\( P \\\\) on the parabola, the distance \\\\( d(P, \\\\text{focus}) \\\\) will be the same as \\\\( d(P, \\\\text{directrix}) \\\\). For example, if a parabola has its focus at \\\\((0, 2)\\\\) and the directrix at \\\\(y = -2\\\\), any point \\\\(P(x, y)\\\\) on the parabola will satisfy \\\\( \\\\sqrt{(x-0)^2 + (y-2)^2} = |y+2| \\\\).',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-5-conic-sections',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The equation $y = \\\\frac{1}{4p}(x - h)^2 + k$ represents a parabola that opens upward, with its vertex located at $(h,k)$ and its focus located at $(h,k+p)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given equation $y = \\\\frac{1}{4p}(x - h)^2 + k$ is indeed the standard form of a parabola with its vertex at $(h,k)$. For a parabola that opens upward, its focus is located at $(h,k+p)$. Here, $p$ is a constant that defines the distance from the vertex to the focus. This form confirms that the parabola opens upward as the quadratic term is in $x$ and the coefficient $\\\\frac{1}{4p}$ is positive. For example, if $h=0$, $k=0$, and $p=1$, then the equation simplifies to $y = \\\\frac{1}{4}(x)^2$, which is a parabola opening upward with its vertex at $(0,0)$ and focus at $(0,1)$.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-5-conic-sections',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: An ellipse is the set of all points such that the sum of their distances from two fixed points (the foci) is constant.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of an ellipse states that it is the set of all points where the sum of the distances from two fixed points (called foci) is constant. This means if you take any point on the ellipse and measure the distance to each of the foci, the total will always be the same regardless of which point you choose. For instance, if the two foci are \\\\(F_1\\\\) and \\\\(F_2\\\\), then for any point \\\\(P\\\\) on the ellipse, \\\\(d(P, F_1) + d(P, F_2)\\\\) is constant. This could be further illustrated using the major axis of the ellipse, where even the farthest points on the ellipse maintain this constant sum.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-5-conic-sections',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: For an ellipse with center $(h,k)$, if the major axis is horizontal with length $2a$ and the minor axis is vertical with length $2b$, the foci are located at $(h, k \\\\pm c)$, where $c^2 = a^2 - b^2$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'In the case of an ellipse with a horizontal major axis, the equation in standard form is $\\\\frac{(x-h)^2}{a^2} + \\\\frac{(y-k)^2}{b^2} = 1$. For this configuration, the foci are located at $(h \\\\pm c, k)$, not $(h, k \\\\pm c)$. Here, $c$ is given by $c^2 = a^2 - b^2$. If the major axis is horizontal, the foci will be horizontally aligned; if the major axis is vertical, the foci will be vertically aligned.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-5-conic-sections',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: In a hyperbola, the set of all points where the sum of their distances from two fixed points (the foci) is constant defines the hyperbola.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'A hyperbola is defined as the set of all points where the difference between their distances from two fixed points (the foci) is constant. This is distinct from an ellipse, where the sum of the distances from the foci to any point on the ellipse is constant. For example, if we have foci at points $F_1$ and $F_2$, then for any point $P$ on the hyperbola, $|d(P, F_1) - d(P, F_2)| = \\\\text{constant}$. In contrast, for an ellipse, $d(P, F_1) + d(P, F_2) = \\\\text{constant}$.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-5-conic-sections',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: For a hyperbola with center $(h,k)$, if the major axis is vertical, the equation of the hyperbola is $\\\\\\\\frac{(y-k)^2}{a^2}-\\\\\\\\frac{(x-h)^2}{b^2}=1$ and the foci are located at $(h, k \\\\\\\\pm c)$ where $c^2 = a^2 + b^2$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The equation of the hyperbola depends on the orientation of the major axis. When the major axis is vertical, the standard form of the equation is $\\\\\\\\frac{(y-k)^2}{a^2} - \\\\\\\\frac{(x-h)^2}{b^2} = 1$. Additionally, for a hyperbola, the relationship between the semi-major axis length $a$, the semi-minor axis length $b$, and the distance from the center to each focus $c$ is given by $c^2 = a^2 + b^2$. Therefore, the foci for a hyperbola with a vertical major axis are at $(h, k \\\\\\\\pm c)$. This aligns perfectly with the given definition.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-5-conic-sections',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: For any point on a parabola, the distance to its focus divided by the perpendicular distance to its directrix is always greater than 1.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The eccentricity $e$ of a conic section is defined as the distance from any point on the conic section to its focus divided by the perpendicular distance from that point to the nearest directrix. For a parabola, $e = 1$. This implies that for any point on a parabola, the distance to its focus divided by the perpendicular distance to its directrix is always exactly 1, not greater than 1.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-5-conic-sections',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: The polar equation of a conic section with focal parameter $p$ and eccentricity $e$ can be written as $r = \\\\\\\\frac{ep}{1 \\\\\\\\pm e\\\\\\\\cos\\\\\\\\theta}$ or $r = \\\\\\\\frac{ep}{1 \\\\\\\\pm e\\\\\\\\sin\\\\\\\\theta}$, where $r$ is the radius and $\\\\\\\\theta$ is the angle.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given statement accurately represents the polar equations for conic sections such as ellipses, hyperbolas, and parabolas. The parameter $p$ is the focal parameter, which is the perpendicular distance from the focus to the directrix. The eccentricity $e$ determines the shape of the conic section: $e < 1$ for an ellipse, $e = 1$ for a parabola, and $e > 1$ for a hyperbola. The presence of $\\\\\\\\cos\\\\\\\\theta$ or $\\\\\\\\sin\\\\\\\\theta$ in the denominator indicates how the radius $r$ changes with the angle $\\\\\\\\theta$ from the focal point to any point on the conic section. This is fundamental to understanding the geometric properties of conic sections in polar coordinates.',\n",
       "  'chapter': 'Parametric Equations and Polar Coordinates',\n",
       "  'section': '1-5-conic-sections',\n",
       "  'number': '8'},\n",
       " {'question': 'True or False: A vector only has magnitude but no direction.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'By definition, a vector is a quantity that has both magnitude and direction. For instance, velocity is a vector because it takes into account both the speed (magnitude) and the direction of motion. On the other hand, speed by itself is a scalar quantity as it only has magnitude but no direction.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-1-vectors-in-the-plane',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: Two vectors €(2, 3) and €(4, 6) are equivalent vectors.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'To determine whether two vectors are equivalent, we must check if they have the same magnitude and direction. The magnitude of a vector \\\\( \\\\mathbf{v} = (x, y) \\\\) is given by \\\\( \\\\sqrt{x^2 + y^2} \\\\).  For \\\\( \\\\mathbf{u} = (2, 3) \\\\):  \\\\[  \\\\text{Magnitude of } \\\\mathbf{u} = \\\\sqrt{2^2 + 3^2} = \\\\sqrt{4 + 9} = \\\\sqrt{13}  \\\\]  For \\\\( \\\\mathbf{v} = (4, 6) \\\\):  \\\\[  \\\\text{Magnitude of } \\\\mathbf{v} = \\\\sqrt{4^2 + 6^2} = \\\\sqrt{16 + 36} = \\\\sqrt{52}  \\\\]  Since \\\\( \\\\sqrt{13} \\\\) is not equal to \\\\( \\\\sqrt{52} \\\\), the vectors do not have the same magnitude. Hence, \\\\( (2, 3) \\\\) and \\\\( (4, 6) \\\\) are not equivalent vectors.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-1-vectors-in-the-plane',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: If a vector $v$ and a scalar $k$ are given, the product $kv$ will always have the same direction as $v$ regardless of the value of $k$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The direction of the product $kv$, where $k$ is a scalar and $v$ is a vector, depends on the sign of $k$. If $k > 0$, the direction of $kv$ is the same as the direction of $v$. If $k < 0$, the direction of $kv$ is opposite to the direction of $v$. For example, if $v = [1, 2]$ and $k = 2$, then $kv = [2, 4]$ which has the same direction as $v$. However, if $k = -2$, then $kv = [-2, -4]$ which is in the opposite direction of $v$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-1-vectors-in-the-plane',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: To construct the sum of two vectors $\\\\\\\\mathbf{v}$ and $\\\\\\\\mathbf{w}$ graphically, you should place the terminal point of $\\\\\\\\mathbf{w}$ at the initial point of $\\\\\\\\mathbf{v}$. Then, the vector sum $\\\\\\\\mathbf{v} + \\\\\\\\mathbf{w}$ is the vector with an initial point that coincides with the terminal point of $\\\\\\\\mathbf{v}$ and has a terminal point that coincides with the initial point of $\\\\\\\\mathbf{w}$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The correct method to construct the sum of two vectors $\\\\\\\\mathbf{v}$ and $\\\\\\\\mathbf{w}$ graphically involves placing the initial point of $\\\\\\\\mathbf{w}$ at the terminal point of $\\\\\\\\mathbf{v}$. The resulting vector sum $\\\\\\\\mathbf{v} + \\\\\\\\mathbf{w}$ then has its initial point at the initial point of $\\\\\\\\mathbf{v}$ and its terminal point at the terminal point of $\\\\\\\\mathbf{w}$. For example, consider $\\\\\\\\mathbf{v} = (1, 2)$ and $\\\\\\\\mathbf{w} = (3, 1)$. When vector $\\\\\\\\mathbf{w}$ is placed such that its initial point is at the terminal point of $\\\\\\\\mathbf{v}$, the sum $\\\\\\\\mathbf{v} + \\\\\\\\mathbf{w}$ is $(1+3, 2+1) = (4, 3)$. This correctly demonstrates the principle of vector addition.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-1-vectors-in-the-plane',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: A vector with an initial point at (0,0) and a terminal point at (3,4) can be represented in component form as $\\\\mathbf{v} = \\\\langle 3,4 \\\\rangle$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A vector $\\\\mathbf{v}$ with an initial point at $(0,0)$ and a terminal point at $(x,y)$ is represented in component form as $\\\\mathbf{v} = \\\\langle x, y \\\\rangle$. In this case, the initial point is $(0,0)$ and the terminal point is $(3,4)$, making the components $x = 3$ and $y = 4$. Therefore, the vector can be represented as $\\\\mathbf{v} = \\\\langle 3, 4 \\\\rangle$. If, for instance, the terminal point were $(5,7)$, the vector would be represented as $\\\\mathbf{v} = \\\\langle 5, 7 \\\\rangle$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-1-vectors-in-the-plane',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: Given vectors $v = \\\\langle x_1, y_1 \\\\rangle$ and $w = \\\\langle x_2, y_2 \\\\rangle$, the sum of $v$ and $2w$ is $v + 2w = \\\\langle x_1 + 2x_2, y_1 + 2y_2 \\\\rangle$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given statement correctly applies the concepts of vector addition and scalar multiplication. Starting with the vector $w = \\\\langle x_2, y_2 \\\\rangle$, multiplying it by the scalar $2$ yields:  $$2w = 2 \\\\langle x_2, y_2 \\\\rangle = \\\\langle 2x_2, 2y_2 \\\\rangle.$$  Then, adding $v = \\\\langle x_1, y_1 \\\\rangle$ to $2w$ results in:  $$v + 2w = \\\\langle x_1, y_1 \\\\rangle + \\\\langle 2x_2, 2y_2 \\\\rangle = \\\\langle x_1 + 2x_2, y_1 + 2y_2 \\\\rangle.$$  Thus, the sum $v + 2w$ indeed equals $\\\\langle x_1 + 2x_2, y_1 + 2y_2 \\\\rangle$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-1-vectors-in-the-plane',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False? The property $r(u + v) = ru + rv$ demonstrates the associative property of scalar multiplication for vectors.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The property $r(u + v) = ru + rv$ actually demonstrates the distributive property of scalar multiplication over vector addition. The associative property of scalar multiplication is given by $r(su) = (rs)u$. \\\\n\\\\nFor example, if $u = \\\\begin{pmatrix} 1 \\\\\\\\ 2 \\\\end{pmatrix}$ and $v = \\\\begin{pmatrix} 3 \\\\\\\\ 4 \\\\end{pmatrix}$, with scalars $r = 2$ and $s = 3$, \\\\n\\\\ndistributive property: \\\\n$r(u + v) = 2\\\\left( \\\\begin{pmatrix} 1 \\\\\\\\ 2 \\\\end{pmatrix} + \\\\begin{pmatrix} 3 \\\\\\\\ 4 \\\\end{pmatrix} \\\\right) = 2 \\\\begin{pmatrix} 4 \\\\\\\\ 6 \\\\end{pmatrix} = \\\\begin{pmatrix} 8 \\\\\\\\ 12 \\\\end{pmatrix}$\\\\nand \\\\n$ru + rv = 2\\\\begin{pmatrix} 1 \\\\\\\\ 2 \\\\end{pmatrix} + 2\\\\begin{pmatrix} 3 \\\\\\\\ 4 \\\\end{pmatrix} = \\\\begin{pmatrix} 2 \\\\\\\\ 4 \\\\end{pmatrix} + \\\\begin{pmatrix} 6 \\\\\\\\ 8 \\\\end{pmatrix} = \\\\begin{pmatrix} 8 \\\\\\\\ 12 \\\\end{pmatrix}$. \\\\nBoth give the same result illustrating distributive property.\\\\n\\\\nassociative property: \\\\n$r(su) = 2(3 \\\\begin{pmatrix} 1 \\\\\\\\ 2 \\\\end{pmatrix}) = 2 \\\\begin{pmatrix} 3 \\\\\\\\ 6 \\\\end{pmatrix} = \\\\begin{pmatrix} 6 \\\\\\\\ 12 \\\\end{pmatrix}$\\\\nand \\\\n$(rs)u = (2 \\\\cdot 3) \\\\begin{pmatrix} 1 \\\\\\\\ 2 \\\\end{pmatrix} = 6 \\\\begin{pmatrix} 1 \\\\\\\\ 2 \\\\end{pmatrix} = \\\\begin{pmatrix} 6 \\\\\\\\ 12 \\\\end{pmatrix}$. \\\\nBoth give the same result illustrating associative property.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-1-vectors-in-the-plane',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: In the three-dimensional rectangular coordinate system, the axes are not perpendicular to each other, and the system is often denoted by $\\\\\\\\mathbb{R}^2$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The three-dimensional rectangular coordinate system consists of three perpendicular axes: the $x$-axis, the $y$-axis, and the $z$-axis. The point of intersection of these axes is called the origin, which is denoted by (0,0,0). This system represents all real numbers in $\\\\\\\\mathbb{R}^3$, not $\\\\\\\\mathbb{R}^2$. The perpendicularity of the axes is a key feature of the system, allowing for the definition of coordinates in three dimensions.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-2-vectors-in-three-dimensions',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The distance $d$ between points $(x_1,y_1,z_1)$ and $(x_2,y_2,z_2)$ in a 3-dimensional space can be calculated using the formula $d=\\\\sqrt{(x_2−x_1)^2 +(y_2−y_1)^2 +(z_2−z_1)^2}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The formula $d=\\\\sqrt{(x_2−x_1)^2 +(y_2−y_1)^2 +(z_2−z_1)^2}$ is derived from the Pythagorean theorem in three-dimensional space. It calculates the straight-line (or Euclidean) distance between two points $(x_1, y_1, z_1)$ and $(x_2, y_2, z_2)$. For example, if we have points $(1, 2, 3)$ and $(4, 5, 6)$, the distance is $d=\\\\sqrt{(4−1)^2 +(5−2)^2 +(6−3)^2} = \\\\sqrt{3^2 + 3^2 + 3^2} = \\\\sqrt{27} = 3\\\\sqrt{3}$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-2-vectors-in-three-dimensions',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: In three-dimensional space, a sphere is equivalent to the set of all points that are the same distance from a fixed central point, known as the center, and this distance is called the radius.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A sphere is defined mathematically as the set of all points in three-dimensional space that are a fixed distance, denoted as the radius, from a central point called the center. This concept is analogous to a circle in two-dimensional space, where all points are equally distant from the center of the circle. For example, if the center of the sphere is at point $C$ and the radius is $r$, then any point $P$ on the sphere satisfies the equation $|P - C| = r$, where $|P - C|$ represents the distance between point $P$ and the center $C$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-2-vectors-in-three-dimensions',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The dot product of the vectors $\\\\\\\\mathbf{u} = \\\\\\\\langle u_1, u_2, u_3 \\\\\\\\rangle$ and $\\\\\\\\mathbf{v} = \\\\\\\\langle v_1, v_2, v_3 \\\\\\\\rangle$ can be calculated by the expression $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = u_1 v_1 + u_2 v_2 + u_3 v_3$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The dot product, also known as the scalar product, of two vectors $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$ in three-dimensional space is defined as the sum of the products of their corresponding components. Mathematically, for vectors $\\\\\\\\mathbf{u} = \\\\\\\\langle u_1, u_2, u_3 \\\\\\\\rangle$ and $\\\\\\\\mathbf{v} = \\\\\\\\langle v_1, v_2, v_3 \\\\\\\\rangle$, the dot product is given by $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = u_1 v_1 + u_2 v_2 + u_3 v_3$. For example, if $\\\\\\\\mathbf{u} = \\\\\\\\langle 1, 2, 3 \\\\\\\\rangle$ and $\\\\\\\\mathbf{v} = \\\\\\\\langle 4, 5, 6 \\\\\\\\rangle$, then $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = 1 \\\\\\\\cdot 4 + 2 \\\\\\\\cdot 5 + 3 \\\\\\\\cdot 6 = 4 + 10 + 18 = 32$. This calculation confirms the given expression is correct.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-3-the-dot-product',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: For any vectors $\\\\\\\\mathbf{u}$, $\\\\\\\\mathbf{v}$, and $\\\\\\\\mathbf{w}$, and any scalar $c$, the dot product properties include the following: $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = \\\\\\\\mathbf{v} \\\\\\\\cdot \\\\\\\\mathbf{u}$ (Commutative property), $\\\\\\\\mathbf{u} \\\\\\\\cdot (\\\\\\\\mathbf{v} + \\\\\\\\mathbf{w}) = \\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} + \\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{w}$ (Distributive property), $c(\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v}) = (c\\\\\\\\mathbf{u}) \\\\\\\\cdot \\\\\\\\mathbf{v} = \\\\\\\\mathbf{u} \\\\\\\\cdot (c\\\\\\\\mathbf{v})$ (Associative property), and $\\\\\\\\mathbf{v} \\\\\\\\cdot \\\\\\\\mathbf{v} = \\\\\\\\|\\\\\\\\mathbf{v}\\\\\\\\|^2$ (Property of magnitude).',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The properties of the dot product as stated are correct and form fundamental aspects of vector algebra: 1. Commutative property: $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = \\\\\\\\mathbf{v} \\\\\\\\cdot \\\\\\\\mathbf{u}$. This means the order of dotting two vectors does not matter. 2. Distributive property: $\\\\\\\\mathbf{u} \\\\\\\\cdot (\\\\\\\\mathbf{v} + \\\\\\\\mathbf{w}) = \\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} + \\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{w}$. This indicates that the dot product distributes over vector addition. 3. Associative property: $c(\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v}) = (c\\\\\\\\mathbf{u}) \\\\\\\\cdot \\\\\\\\mathbf{v} = \\\\\\\\mathbf{u} \\\\\\\\cdot (c\\\\\\\\mathbf{v})$. This implies the scalar can be factored through the dot product. 4. Property of magnitude: $\\\\\\\\mathbf{v} \\\\\\\\cdot \\\\\\\\mathbf{v} = \\\\\\\\|\\\\\\\\mathbf{v}\\\\\\\\|^2$. This shows that the dot product of a vector with itself is equal to the magnitude squared of the vector.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-3-the-dot-product',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The dot product of two vectors $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$ is always equal to the product of their magnitudes multiplied by the cosine of the angle between them, mathematically represented as $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = \\\\\\\\|\\\\\\\\mathbf{u}\\\\\\\\| \\\\\\\\|\\\\\\\\mathbf{v}\\\\\\\\| \\\\\\\\cos \\\\\\\\theta$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true. The dot product of two vectors, $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$, quantifies how much one vector extends in the direction of another. Mathematically, the dot product $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v}$ is calculated as the product of the magnitudes of the two vectors ($\\\\\\\\|\\\\\\\\mathbf{u}\\\\\\\\|$ and $\\\\\\\\|\\\\\\\\mathbf{v}\\\\\\\\|$) and the cosine of the angle $\\\\\\\\theta$ between them. For example, if $\\\\\\\\mathbf{u} = [1, 0]$ and $\\\\\\\\mathbf{v} = [0, 1]$, their magnitudes are both 1, but the angle $\\\\\\\\theta$ between them is 90 degrees, and $\\\\\\\\cos 90^{\\\\\\\\circ} = 0$. Hence, $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = 1 \\\\\\\\times 1 \\\\\\\\times 0 = 0$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-3-the-dot-product',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: If two nonzero vectors $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$ are orthogonal, then their dot product is zero, i.e., $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = 0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'Two nonzero vectors $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$ are defined to be orthogonal if and only if their dot product equals zero, which means $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = 0$. This signifies that the vectors are at a right angle (90 degrees) to each other in a given space. For example, if $\\\\\\\\mathbf{u} = \\\\\\\\begin{bmatrix}1 \\\\\\\\\\\\ 0\\\\\\\\\\\\end{bmatrix}$ and $\\\\\\\\mathbf{v} = \\\\\\\\begin{bmatrix}0 \\\\\\\\\\\\ 1\\\\\\\\\\\\end{bmatrix}$, then $\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v} = 1*0 + 0*1 = 0$, confirming they are orthogonal.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-3-the-dot-product',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The angles formed by a nonzero vector and the coordinate axes are known as the direction cosines for the vector.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The angles formed by a nonzero vector and the coordinate axes are known as the direction angles. The cosines of these angles are called the direction cosines. For example, if a vector $\\\\mathbf{v}$ forms angles $\\\\alpha$, $\\\\beta$, and $\\\\gamma$ with the x, y, and z axes respectively, then these angles are the direction angles. The cosines of these angles, $\\\\cos(\\\\alpha)$, $\\\\cos(\\\\beta)$, and $\\\\cos(\\\\gamma)$, are the direction cosines.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-3-the-dot-product',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: The vector projection of $\\\\\\\\mathbf{v}$ onto $\\\\\\\\mathbf{u}$ has a length given by $\\\\\\\\|\\\\\\\\text{proj}_{\\\\\\\\mathbf{u}} \\\\\\\\mathbf{v}\\\\\\\\| = \\\\\\\\frac{|\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v}|}{\\\\\\\\|\\\\\\\\mathbf{u}\\\\\\\\|}$ and it is always in the same direction as $\\\\\\\\mathbf{u}$, regardless of the angle $\\\\\\\\theta$ between $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The length of the vector projection of $\\\\\\\\mathbf{v}$ onto $\\\\\\\\mathbf{u}$ is indeed $\\\\\\\\|\\\\\\\\text{proj}_{\\\\\\\\mathbf{u}} \\\\\\\\mathbf{v}\\\\\\\\| = \\\\\\\\frac{|\\\\\\\\mathbf{u} \\\\\\\\cdot \\\\\\\\mathbf{v}|}{\\\\\\\\|\\\\\\\\mathbf{u}\\\\\\\\|}$. However, the direction of the projection depends on the angle $\\\\\\\\theta$ between $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$. If $\\\\\\\\theta$ is obtuse, the projection will be in the opposite direction of $\\\\\\\\mathbf{u}$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-3-the-dot-product',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: The work $W$ done by a constant force $\\\\mathbf{F}$, acting at an angle $\\\\theta$ to the direction of motion of an object from point $P$ to point $Q$, is given by $W = \\\\mathbf{F} \\\\cdot \\\\mathbf{PQ} = \\\\| \\\\mathbf{F} \\\\| \\\\| \\\\mathbf{PQ} \\\\| \\\\cos \\\\theta$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true according to the definition provided. The work $W$ done by a constant force $\\\\mathbf{F}$ is calculated using the dot product of the force vector $\\\\mathbf{F}$ and the displacement vector $\\\\mathbf{PQ}$. The formula $W = \\\\mathbf{F} \\\\cdot \\\\mathbf{PQ}$ translates to $W = \\\\| \\\\mathbf{F} \\\\| \\\\| \\\\mathbf{PQ} \\\\| \\\\cos \\\\theta$, where $\\\\| \\\\mathbf{F} \\\\|$ is the magnitude of the force, $\\\\| \\\\mathbf{PQ} \\\\|$ is the magnitude of the displacement, and $\\\\theta$ is the angle between the force vector and the displacement vector. For example, if an object is pushed with a force of 10 N over a distance of 5 meters at an angle of 30 degrees to the direction of motion, the work done would be $10 \\\\times 5 \\\\times \\\\cos(30^\\\\circ) = 50 \\\\times \\\\frac{\\\\sqrt{3}}{2} = 25\\\\sqrt{3}$ J.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-3-the-dot-product',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: Given the vectors $\\\\\\\\mathbf{u} = \\\\\\\\langle u_1, u_2, u_3 \\\\\\\\rangle$ and $\\\\\\\\mathbf{v} = \\\\\\\\langle v_1, v_2, v_3 \\\\\\\\rangle$, the cross product $\\\\\\\\mathbf{u} \\\\\\\\times \\\\\\\\mathbf{v}$ results in the vector $\\\\\\\\langle u_2 v_3 - u_3 v_2, - (u_1 v_3 - u_3 v_1), u_1 v_2 - u_2 v_1 \\\\\\\\rangle$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The cross product $\\\\\\\\mathbf{u} \\\\\\\\times \\\\\\\\mathbf{v}$ between two vectors $\\\\\\\\mathbf{u} = \\\\\\\\langle u_1, u_2, u_3 \\\\\\\\rangle$ and $\\\\\\\\mathbf{v} = \\\\\\\\langle v_1, v_2, v_3 \\\\\\\\rangle$ is given by:  \\\\[  \\\\\\\\mathbf{u} \\\\\\\\times \\\\\\\\mathbf{v} = (u_2 v_3 - u_3 v_2) \\\\\\\\mathbf{i} - (u_1 v_3 - u_3 v_1) \\\\\\\\mathbf{j} + (u_1 v_2 - u_2 v_1) \\\\\\\\mathbf{k}  \\\\]  This results in the vector $\\\\\\\\langle u_2 v_3 - u_3 v_2, - (u_1 v_3 - u_3 v_1), u_1 v_2 - u_2 v_1 \\\\\\\\rangle$. For example, for $\\\\\\\\mathbf{u} = \\\\\\\\langle 1, 2, 3 \\\\\\\\rangle$ and $\\\\\\\\mathbf{v} = \\\\\\\\langle 4, 5, 6 \\\\\\\\rangle$, the cross product is calculated as:  \\\\[  \\\\\\\\mathbf{u} \\\\\\\\times \\\\\\\\mathbf{v} = (2 \\\\\\\\cdot 6 - 3 \\\\\\\\cdot 5) \\\\\\\\mathbf{i} - (1 \\\\\\\\cdot 6 - 3 \\\\\\\\cdot 4) \\\\\\\\mathbf{j} + (1 \\\\\\\\cdot 5 - 2 \\\\\\\\cdot 4) \\\\\\\\mathbf{k} = \\\\\\\\langle -3, 6, -3 \\\\\\\\rangle.  \\\\]  This confirms the definition given is correct.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-4-the-cross-product',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: If $\\\\\\\\mathbf{u}$, $\\\\\\\\mathbf{v}$, and $\\\\\\\\mathbf{w}$ are vectors in space, and $c$ is a scalar, then the cross product properties include: $\\\\\\\\mathbf{u} \\\\\\\\times (\\\\\\\\mathbf{v} + \\\\\\\\mathbf{w}) = (\\\\\\\\mathbf{w} + \\\\\\\\mathbf{v}) \\\\\\\\times \\\\\\\\mathbf{u}$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The given statement is false because it does not respect the anticommutative property of the cross product. According to the anticommutative property, swapping the order of the vectors in a cross product results in a negated vector (i.e., $\\\\\\\\mathbf{u} \\\\\\\\times \\\\\\\\mathbf{v} = - (\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{u})$). Hence, $\\\\\\\\mathbf{u} \\\\\\\\times (\\\\\\\\mathbf{v} + \\\\\\\\mathbf{w})$ is not equal to $(\\\\\\\\mathbf{w} + \\\\\\\\mathbf{v}) \\\\\\\\times \\\\\\\\mathbf{u}$ but is equal to $- (\\\\\\\\mathbf{u} \\\\\\\\times (\\\\\\\\mathbf{w} + \\\\\\\\mathbf{v}))$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-4-the-cross-product',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The magnitude of the cross product of two vectors $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$ is given by $\\\\\\\\|\\\\\\\\mathbf{u} \\\\\\\\times \\\\\\\\mathbf{v}\\\\\\\\| = \\\\\\\\|\\\\\\\\mathbf{u}\\\\\\\\| \\\\\\\\cdot \\\\\\\\|\\\\\\\\mathbf{v}\\\\\\\\| \\\\\\\\cdot \\\\\\\\cos(\\\\\\\\theta)$, where $\\\\\\\\theta$ is the angle between them.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The correct formula for the magnitude of the cross product of two vectors $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$ is $\\\\\\\\|\\\\\\\\mathbf{u} \\\\\\\\times \\\\\\\\mathbf{v}\\\\\\\\| = \\\\\\\\|\\\\\\\\mathbf{u}\\\\\\\\| \\\\\\\\cdot \\\\\\\\|\\\\\\\\mathbf{v}\\\\\\\\| \\\\\\\\cdot \\\\\\\\sin(\\\\\\\\theta)$. This is because the cross product measures the area of the parallelogram formed by the two vectors, which depends on the sine of the angle between them. For example, if $\\\\\\\\mathbf{u}$ and $\\\\\\\\mathbf{v}$ are perpendicular, $\\\\\\\\theta = \\\\\\\\frac{\\\\\\\\pi}{2}$, and $\\\\\\\\sin(\\\\\\\\theta) = 1$, so $\\\\\\\\|\\\\\\\\mathbf{u} \\\\\\\\times \\\\\\\\mathbf{v}\\\\\\\\| = \\\\\\\\|\\\\\\\\mathbf{u}\\\\\\\\| \\\\\\\\cdot \\\\\\\\|\\\\\\\\mathbf{v}\\\\\\\\|$. However, if $\\\\\\\\cos(\\\\\\\\theta)$ were used, it would incorrectly represent the relationship, especially in cases where $\\\\\\\\theta = 0$ or $\\\\\\\\theta = \\\\\\\\pi$, where $\\\\\\\\cos(\\\\\\\\theta)$ would be 1 or -1, not representing the geometric concept of the cross product’s magnitude.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-4-the-cross-product',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The area of a parallelogram formed by vectors $u$ and $v$ is given by the magnitude of the cross product of $u$ and $v$, denoted as $\\\\\\\\|u \\\\\\\\times v\\\\\\\\|$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The area of a parallelogram formed by the vectors $u$ and $v$ is indeed given by the magnitude of their cross product, $\\\\\\\\|u \\\\\\\\times v\\\\\\\\|$. The cross product $u \\\\\\\\times v$ results in a vector orthogonal (perpendicular) to the plane containing $u$ and $v$, with a magnitude equal to the area of the parallelogram. For example, if $u = \\\\\\\\begin{pmatrix} 1 \\\\\\\\\\\\\\\\ 2 \\\\\\\\\\\\\\\\ 3 \\\\\\\\end{pmatrix}$ and $v = \\\\\\\\begin{pmatrix} 4 \\\\\\\\\\\\\\\\ 5 \\\\\\\\\\\\\\\\ 6 \\\\\\\\end{pmatrix}$, then $u \\\\\\\\times v = \\\\\\\\begin{pmatrix} -3 \\\\\\\\\\\\\\\\ 6 \\\\\\\\\\\\\\\\ -3 \\\\\\\\end{pmatrix}$ and $\\\\\\\\|u \\\\\\\\times v\\\\\\\\| = \\\\\\\\sqrt{(-3)^2 + 6^2 + (-3)^2} = 3 \\\\\\\\sqrt{2}$, which is the area of the parallelogram formed by $u$ and $v$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-4-the-cross-product',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The triple scalar product of vectors $\\\\\\\\mathbf{u}$, $\\\\\\\\mathbf{v}$, and $\\\\\\\\mathbf{w}$ is given by $\\\\\\\\mathbf{u} \\\\\\\\cdot (\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{w})$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The triple scalar product is a mathematical operation that involves three vectors and results in a scalar. It is defined as $\\\\\\\\mathbf{u} \\\\\\\\cdot (\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{w})$, where $\\\\\\\\mathbf{u}$, $\\\\\\\\mathbf{v}$, and $\\\\\\\\mathbf{w}$ are vectors. To understand this concept, recall that the cross product $\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{w}$ yields a vector that is orthogonal to both $\\\\\\\\mathbf{v}$ and $\\\\\\\\mathbf{w}$. The dot product $\\\\\\\\mathbf{u} \\\\\\\\cdot (\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{w})$ then projects vector $\\\\\\\\mathbf{u}$ onto this orthogonal vector, resulting in a scalar. For example, if $\\\\\\\\mathbf{u} = \\\\\\\\begin{pmatrix} 1 \\\\\\\\\\\\\\\\ 0 \\\\\\\\\\\\\\\\ 0 \\\\\\\\end{pmatrix}$, $\\\\\\\\mathbf{v} = \\\\\\\\begin{pmatrix} 0 \\\\\\\\\\\\\\\\ 1 \\\\\\\\\\\\\\\\ 0 \\\\\\\\end{pmatrix}$, and $\\\\\\\\mathbf{w} = \\\\\\\\begin{pmatrix} 0 \\\\\\\\\\\\\\\\ 0 \\\\\\\\\\\\\\\\ 1 \\\\\\\\end{pmatrix}$, the cross product $\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{w}$ gives $\\\\\\\\begin{pmatrix} 1 \\\\\\\\\\\\\\\\ 0 \\\\\\\\\\\\\\\\ 0 \\\\\\\\end{pmatrix}$, and the dot product of $\\\\\\\\mathbf{u}$ with this result is $1$. Thus, $\\\\\\\\mathbf{u} \\\\\\\\cdot (\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{w}) = 1$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-4-the-cross-product',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: The triple scalar product of vectors $\\\\\\\\mathbf{u} = u_1\\\\\\\\mathbf{i} + u_2\\\\\\\\mathbf{j} + u_3\\\\\\\\mathbf{k}$, $\\\\\\\\mathbf{v} = v_1\\\\\\\\mathbf{i} + v_2\\\\\\\\mathbf{j} + v_3\\\\\\\\mathbf{k}$, and $\\\\\\\\mathbf{w} = w_1\\\\\\\\mathbf{i} + w_2\\\\\\\\mathbf{j} + w_3\\\\\\\\mathbf{k}$ is given by the determinant of the matrix formed by their components, specifically $\\\\\\\\mathbf{u} \\\\\\\\cdot (\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{w}) = \\\\\\\\begin{vmatrix} u_1 & u_2 & u_3 \\\\\\\\\\\\\\\\ v_1 & v_2 & v_3 \\\\\\\\\\\\\\\\ w_1 & w_2 & w_3 \\\\\\\\end{vmatrix}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The triple scalar product $\\\\\\\\mathbf{u} \\\\\\\\cdot (\\\\\\\\mathbf{v} \\\\\\\\times \\\\\\\\mathbf{w})$ represents the volume of the parallelepiped formed by the vectors $\\\\\\\\mathbf{u}$, $\\\\\\\\mathbf{v}$, and $\\\\\\\\mathbf{w}$. It is calculated as the determinant of a $3 \\\\\\\\times 3$ matrix whose rows (or columns) are the components of the vectors $\\\\\\\\mathbf{u}$, $\\\\\\\\mathbf{v}$, and $\\\\\\\\mathbf{w}$. For example, if $\\\\\\\\mathbf{u} = \\\\\\\\mathbf{i} + \\\\\\\\mathbf{j} + \\\\\\\\mathbf{k}$, $\\\\\\\\mathbf{v} = 2\\\\\\\\mathbf{i} + 3\\\\\\\\mathbf{j} + \\\\\\\\mathbf{k}$, and $\\\\\\\\mathbf{w} = \\\\\\\\mathbf{i} + 2\\\\\\\\mathbf{j} + 3\\\\\\\\mathbf{k}$, then the triple scalar product is calculated as the determinant $\\\\\\\\begin{vmatrix} 1 & 1 & 1 \\\\\\\\\\\\\\\\ 2 & 3 & 1 \\\\\\\\\\\\\\\\ 1 & 2 & 3 \\\\\\\\end{vmatrix}$, which confirms the definition.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-4-the-cross-product',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: The volume of a parallelepiped defined by vectors $\\\\\\\\vec{u}$, $\\\\\\\\vec{v}$, and $\\\\\\\\vec{w}$ is given by the absolute value of the dot product of $\\\\\\\\vec{u}$ with the cross product of $\\\\\\\\vec{v}$ and $\\\\\\\\vec{w}$, i.e., $V = |\\\\\\\\vec{u} \\\\\\\\cdot (\\\\\\\\vec{v} \\\\\\\\times \\\\\\\\vec{w})|$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The volume of a parallelepiped formed by the vectors $\\\\\\\\vec{u}$, $\\\\\\\\vec{v}$, and $\\\\\\\\vec{w}$ is indeed given by the absolute value of the triple scalar product. The triple scalar product for vectors $\\\\\\\\vec{u}$, $\\\\\\\\vec{v}$, and $\\\\\\\\vec{w}$ is denoted as $\\\\\\\\vec{u} \\\\\\\\cdot (\\\\\\\\vec{v} \\\\\\\\times \\\\\\\\vec{w})$. This product measures the scalar volume enclosed by the parallelepiped. Hence, $V = |\\\\\\\\vec{u} \\\\\\\\cdot (\\\\\\\\vec{v} \\\\\\\\times \\\\\\\\vec{w})|$. For example, if $\\\\\\\\vec{u} = \\\\\\\\begin{pmatrix}1 \\\\\\\\\\\\\\\\ 0 \\\\\\\\\\\\\\\\ 0\\\\\\\\end{pmatrix}$, $\\\\\\\\vec{v} = \\\\\\\\begin{pmatrix}0 \\\\\\\\\\\\\\\\ 1 \\\\\\\\\\\\\\\\ 0\\\\\\\\end{pmatrix}$, and $\\\\\\\\vec{w} = \\\\\\\\begin{pmatrix}0 \\\\\\\\\\\\\\\\ 0 \\\\\\\\\\\\\\\\ 1\\\\\\\\end{pmatrix}$, the volume $V$ would be $|\\\\\\\\begin{pmatrix}1 \\\\\\\\\\\\\\\\ 0 \\\\\\\\\\\\\\\\ 0\\\\\\\\end{pmatrix} \\\\\\\\cdot (\\\\\\\\begin{pmatrix}0 \\\\\\\\\\\\\\\\ 1 \\\\\\\\\\\\\\\\ 0\\\\\\\\end{pmatrix} \\\\\\\\times \\\\\\\\begin{pmatrix}0 \\\\\\\\\\\\\\\\ 0 \\\\\\\\\\\\\\\\ 1\\\\\\\\end{pmatrix})| = |1| = 1$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-4-the-cross-product',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: Torque, denoted by $\\\\\\\\tau$, is a measure of the tendency of a force $\\\\\\\\mathbf{F}$ to produce rotation about an axis of rotation and can be calculated as the dot product of the position vector $\\\\\\\\mathbf{r}$ and the force vector $\\\\\\\\mathbf{F}$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'Torque, $\\\\\\\\tau$, is indeed a measure of the tendency of a force $\\\\\\\\mathbf{F}$ to produce rotation about an axis of rotation. However, torque is calculated as the cross product of the position vector $\\\\\\\\mathbf{r}$ and the force vector $\\\\\\\\mathbf{F}$, not the dot product. The cross product $\\\\\\\\mathbf{r} \\\\\\\\times \\\\\\\\mathbf{F}$ results in a vector that is perpendicular to both $\\\\\\\\mathbf{r}$ and $\\\\\\\\mathbf{F}$, indicating the direction of rotation. For instance, if $\\\\\\\\mathbf{r}$ lies in the $xy$-plane and $\\\\\\\\mathbf{F}$ also lies in the $xy$-plane, their cross product $\\\\\\\\mathbf{r} \\\\\\\\times \\\\\\\\mathbf{F}$ would point along the $z$-axis, indicating the axis of rotation.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-4-the-cross-product',\n",
       "  'number': '8'},\n",
       " {'question': 'True or False: A line parallel to the vector $\\\\\\\\mathbf{v}=\\\\\\\\langle a,b,c \\\\\\\\rangle$ and passing through the point $P(x_0, y_0, z_0)$ can only be described using parametric and symmetric equations if $a$, $b$, and $c$ are all nonzero.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given definitions describe the parametric and symmetric equations of a line. The parametric equations are given by $x = x_0 + ta$, $y = y_0 + tb$, and $z = z_0 + tc$. These equations are always valid for any values of $a$, $b$, and $c$. However, the symmetric equation $\\\\\\\\frac{x-x_0}{a} = \\\\\\\\frac{y-y_0}{b} = \\\\\\\\frac{z-z_0}{c}$ is only valid when $a$, $b$, and $c$ are all nonzero, because if any of these constants are zero, it would lead to an undefined expression due to division by zero. Thus, a line can be described using both parametric and symmetric equations if and only if $a$, $b$, and $c$ are all nonzero.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-5-equations-of-lines-and-planes-in-space',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The distance from a point $M$ to a line $L$, which passes through a point $P$ and has a direction vector $\\\\\\\\mathbf{v}$, can be calculated using the formula $d = \\\\\\\\frac{\\\\\\\\| \\\\\\\\overrightarrow{PM} \\\\\\\\times \\\\\\\\mathbf{v} \\\\\\\\|}{\\\\\\\\| \\\\\\\\mathbf{v} \\\\\\\\|}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The formula for the distance from a point $M$ to a line $L$ passing through point $P$ with direction vector $\\\\\\\\mathbf{v}$ is indeed $d = \\\\\\\\frac{\\\\\\\\| \\\\\\\\overrightarrow{PM} \\\\\\\\times \\\\\\\\mathbf{v} \\\\\\\\|}{\\\\\\\\| \\\\\\\\mathbf{v} \\\\\\\\|}$. This formula is derived from projecting the vector $\\\\\\\\overrightarrow{PM}$ onto the direction vector $\\\\\\\\mathbf{v}$ and taking the magnitude of the perpendicular component. For example, if $L$ passes through $P(1, 2)$ with direction vector $\\\\\\\\mathbf{v} = (3, 4)$, and $M$ is at $(4, 6)$, then the distance is found by first determining $\\\\\\\\overrightarrow{PM} = (3, 4)$ and using the cross product and magnitudes in the formula.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-5-equations-of-lines-and-planes-in-space',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The scalar equation of a plane passing through the point $P=(1, 2, 3)$ with a normal vector $\\\\mathbf{n}=\\\\langle 2, -1, 3 \\\\rangle$ can be written as $2x - y + 3z + 1 = 0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'To derive the scalar equation of a plane from a point $P=(x_0, y_0, z_0)$ and a normal vector $\\\\mathbf{n}=\\\\langle a, b, c \\\\rangle$, we use the formula $a(x-x_0) + b(y-y_0) + c(z-z_0) = 0$. Here, $a=2$, $b=-1$, $c=3$, and $P=(1, 2, 3)$ so:    $$2(x-1) - 1(y-2) + 3(z-3) = 0$$.  Simplifying:  $$2x - 2 - y + 2 + 3z - 9 = 0$$  $$2x - y + 3z - 9 = 0$$,    Adding an offset to both sides to match the given general form:    $$2x - y + 3z - 9 + 1 = 0$$  $$2x - y + 3z - 8 = 0$$.    Comparing with $2x - y + 3z + 1 = 0$, it shows a discrepancy in understanding that for the correct sign of $d$, the scalar equation must show the appropriate separation constants contributed by $P=(1, 2, 3)$. Here confusion lies in missed component simplification. A true or false evaluates contextual derivation but here shown satisfy condition when properly adjusted constancy leading to true when simplified further for adjusting volts/structure conversion',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-5-equations-of-lines-and-planes-in-space',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The distance $d$ from a point $P$ to a plane that passes through point $Q$ with normal vector $\\\\\\\\mathbf{n}$ is given by $d = \\\\\\\\left| \\\\\\\\frac{ \\\\\\\\mathbf{QP} \\\\\\\\cdot \\\\\\\\mathbf{n} }{ \\\\\\\\| \\\\\\\\mathbf{n} \\\\\\\\| } \\\\\\\\right|$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The distance $d$ from a point $P$ to a plane that passes through point $Q$ with normal vector $\\\\\\\\mathbf{n}$ can be calculated using the formula $d = \\\\\\\\left| \\\\\\\\frac{ \\\\\\\\mathbf{QP} \\\\\\\\cdot \\\\\\\\mathbf{n} }{ \\\\\\\\| \\\\\\\\mathbf{n} \\\\\\\\| } \\\\\\\\right|$. Here, $\\\\\\\\mathbf{QP}$ represents the vector from $Q$ to $P$, $\\\\\\\\mathbf{n}$ is the normal vector to the plane, and $\\\\\\\\mathbf{QP} \\\\\\\\cdot \\\\\\\\mathbf{n}$ is the dot product of $\\\\\\\\mathbf{QP}$ and $\\\\\\\\mathbf{n}$. The magnitude $\\\\\\\\| \\\\\\\\mathbf{n} \\\\\\\\|$ is the norm of the normal vector. This formula encapsulates the projection of $\\\\\\\\mathbf{QP}$ onto the normal vector $\\\\\\\\mathbf{n}$, divided by the magnitude of $\\\\\\\\mathbf{n}$, providing the perpendicular distance from the point to the plane.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-5-equations-of-lines-and-planes-in-space',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The distance $d$ from a point $P(x_0, y_0, z_0)$ to a plane $ax + by + cz + k = 0$ is given by $d = \\\\\\\\frac{|ax_0 + by_0 + cz_0 + k|}{\\\\\\\\sqrt{a^2 + b^2 + c^2}}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The formula $d = \\\\\\\\frac{|ax_0 + by_0 + cz_0 + k|}{\\\\\\\\sqrt{a^2 + b^2 + c^2}}$ correctly represents the distance from a point $P(x_0, y_0, z_0)$ to a plane defined by the equation $ax + by + cz + k = 0$. This formula is derived from projecting the point onto the normal vector of the plane and measuring the perpendicular distance. For example, for a point $P(1, 2, 3)$ and a plane $2x + 3y + 4z + 5 = 0$, the distance is $\\\\\\\\frac{|2 \\\\cdot 1 + 3 \\\\cdot 2 + 4 \\\\cdot 3 + 5|}{\\\\\\\\sqrt{2^2 + 3^2 + 4^2}}$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-5-equations-of-lines-and-planes-in-space',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: A cylindrical surface is formed by a set of lines that are perpendicular to a given line and pass through a given curve. These lines are called rulings.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'A cylindrical surface, or cylinder, is actually formed by a set of lines that are *parallel* to a given line, not perpendicular, and pass through a given curve. These parallel lines are called rulings. For example, consider a curve in the $xy$-plane and a line parallel to the $z$-axis; the cylindrical surface is created by translating this curve along the $z$-axis parallel to that line.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-6-quadric-surfaces',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The traces of a surface are formed when the surface intersects a plane that is parallel to one of the coordinate planes.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The concept of traces in surface geometry involves creating cross-sections of a surface by intersecting it with planes parallel to the coordinate planes (e.g., $xy$-plane, $yz$-plane, $zx$-plane). For example, a trace of a surface on the $xy$-plane is obtained by setting $z = k$ (a constant) and observing the resulting curve in the $xy$-plane. Similarly, for the $yz$-plane, we set $x = k$, and for the $zx$-plane, we set $y = k$. These cross-sections (traces) help analyze the properties and shapes of the surfaces by looking at simpler 2-dimensional slices.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-6-quadric-surfaces',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: A quadric surface must always include all of the cross-product terms (e.g., $Dxy$, $Exz$, $Fyz$) in its equation to be considered a quadric surface.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'A quadric surface is defined by the general form $Ax^2 + By^2 + Cz^2 + Dxy + Exz + Fyz + Gx + Hy + Jz + K = 0$. However, not all terms are required for the equation to represent a quadric surface. For example, a sphere is a specific type of quadric surface given by $x^2 + y^2 + z^2 = r^2$, wherein the cross-product terms ($Dxy$, $Exz$, and $Fyz$) and linear terms ($Gx$, $Hy$, and $Jz$) are absent. Therefore, the presence of cross-product terms is not mandatory for the equation to be considered a quadric surface.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-6-quadric-surfaces',\n",
       "  'number': '3'},\n",
       " {'question': \"True or False: In the cylindrical coordinate system, a point in space is represented by the ordered triple $(r, \\\\theta, z)$, where $(r, \\\\theta)$ are the Cartesian coordinates of the point's projection in the $xy$-plane and $z$ is the usual $z$-coordinate in the Cartesian coordinate system.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': 'In the cylindrical coordinate system, a point in space is indeed represented by the ordered triple $(r, \\\\theta, z)$. However, $(r, \\\\theta)$ are the polar coordinates of the point’s projection in the $xy$-plane, not the Cartesian coordinates. The polar coordinates $(r, \\\\theta)$ specify the radial distance $r$ from the origin and the angle $\\\\theta$ from the positive $x$-axis. The $z$ coordinate remains the same as in the Cartesian coordinate system. For example, a point in cylindrical coordinates might be expressed as $(3, \\\\frac{\\\\pi}{4}, 5)$, indicating a radial distance of 3 units, an angle of $\\\\frac{\\\\pi}{4}$ radians, and a height of 5 units.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-7-cylindrical-and-spherical-coordinates',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: In cylindrical coordinates $(r, \\\\\\\\theta, z)$, the coordinate $z$ remains unchanged during the conversion to Cartesian coordinates $(x, y, z)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The coordinate system conversion relationship between cylindrical and Cartesian coordinates maintains the $z$ coordinate unchanged. In both coordinate systems, $z$ represents the same vertical distance from the $xy$-plane. For example, a point located at $(r, \\\\\\\\theta, z)$ in cylindrical coordinates will have its $z$ value remain the same when represented in Cartesian coordinates $(x, y, z)$. Only the $x$ and $y$ coordinates are computed differently: $x = r \\\\\\\\cos \\\\\\\\theta$ and $y = r \\\\\\\\sin \\\\\\\\theta$.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-7-cylindrical-and-spherical-coordinates',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: In the spherical coordinate system, the coordinate $\\\\\\\\phi$ (the Greek letter phi) represents the distance between the point $P$ and the origin, where $0 \\\\\\\\leq \\\\\\\\phi \\\\\\\\leq \\\\\\\\pi$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'In the spherical coordinate system, the coordinate $\\\\\\\\phi$ represents the angle formed by the positive $z$-axis and the line segment $OP$, where $O$ is the origin and $0 \\\\\\\\leq \\\\\\\\phi \\\\\\\\leq \\\\\\\\pi$. The distance between point $P$ and the origin is denoted by $\\\\\\\\rho$ (the Greek letter rho), not $\\\\\\\\phi$. For example, for a point $P$ lying on the positive $z$-axis, $\\\\\\\\phi$ would be $0$ degrees, irrespective of the distance $\\\\\\\\rho$. Thus, the given statement is false.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-7-cylindrical-and-spherical-coordinates',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The relationship between spherical coordinates $(\\\\rho, \\\\theta, \\\\phi)$ and rectangular coordinates $(x, y, z)$ includes the equations $x = \\\\rho \\\\sin \\\\phi \\\\cos \\\\theta$, $y = \\\\rho \\\\sin \\\\phi \\\\sin \\\\theta$, and $z = \\\\rho \\\\cos \\\\phi$. Subsequently, the relationship between cylindrical coordinates $(r, \\\\theta, z)$ and spherical coordinates $(\\\\rho, \\\\theta, \\\\phi)$ includes the equations $r = \\\\rho \\\\sin \\\\phi$, $\\\\theta = \\\\theta$, and $z = \\\\rho \\\\cos \\\\phi$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The conversion between different coordinate systems involves specific equations that map the coordinates from one system to another. For spherical coordinates $(\\\\rho, \\\\theta, \\\\phi)$ to rectangular coordinates $(x, y, z)$, the correct relationships are indeed $x = \\\\rho \\\\sin \\\\phi \\\\cos \\\\theta$, $y = \\\\rho \\\\sin \\\\phi \\\\sin \\\\theta$, and $z = \\\\rho \\\\cos \\\\phi$. Similarly, for cylindrical coordinates $(r, \\\\theta, z)$ to spherical coordinates $(\\\\rho, \\\\theta, \\\\phi)$, the relationship is $r = \\\\rho \\\\sin \\\\phi$, $\\\\theta = \\\\theta$, and $z = \\\\rho \\\\cos \\\\phi$. These equations allow for the translation of points between the coordinate systems and ensure that the positional information remains consistent across different representations. For example, a point with spherical coordinates $(2, \\\\pi/4, \\\\pi/3)$ translates to rectangular coordinates using the provided equations, preserving its spatial position.',\n",
       "  'chapter': 'Vectors in Space',\n",
       "  'section': '2-7-cylindrical-and-spherical-coordinates',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: A vector-valued function can be represented in two forms: \\\\( r(t) = f(t)\\\\mathbf{i} + g(t)\\\\mathbf{j} \\\\) or \\\\( r(t) = f(t)\\\\mathbf{i} + g(t)\\\\mathbf{j} + h(t)\\\\mathbf{k} \\\\), which describe 2-dimensional and 3-dimensional vector-valued functions respectively.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A vector-valued function is defined as a function of the form \\\\( r(t) = f(t)\\\\mathbf{i} + g(t)\\\\mathbf{j} \\\\) or \\\\( r(t) = f(t)\\\\mathbf{i} + g(t)\\\\mathbf{j} + h(t)\\\\mathbf{k} \\\\). The first form, \\\\( r(t) = f(t)\\\\mathbf{i} + g(t)\\\\mathbf{j} \\\\), represents a two-dimensional vector-valued function as it involves only the \\\\( \\\\mathbf{i} \\\\) and \\\\( \\\\mathbf{j} \\\\) components. The second form, \\\\( r(t) = f(t)\\\\mathbf{i} + g(t)\\\\mathbf{j} + h(t)\\\\mathbf{k} \\\\), describes a three-dimensional vector-valued function since it includes the additional \\\\( \\\\mathbf{k} \\\\) component. For example, \\\\( r(t) = \\\\langle t, t^2 \\\\rangle \\\\) is a 2-dimensional vector-valued function, while \\\\( r(t) = \\\\langle t, t^2, t^3 \\\\rangle \\\\) is a 3-dimensional vector-valued function.',\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-1-vector-valued-functions-and-space-curves',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: For a vector-valued function $\\\\\\\\mathbf{r}(t)$ to approach a limit $\\\\\\\\mathbf{L}$ as $t$ approaches $a$, it is sufficient that $\\\\\\\\lim_{{t \\\\\\\\to a}} \\\\\\\\| \\\\\\\\mathbf{r}(t) - \\\\\\\\mathbf{L} \\\\\\\\| = 0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'According to the definition, a vector-valued function $\\\\\\\\mathbf{r}(t)$ approaches the limit $\\\\\\\\mathbf{L}$ as $t$ approaches $a$, written as $\\\\\\\\lim_{{t \\\\\\\\to a}} \\\\\\\\mathbf{r}(t) = \\\\\\\\mathbf{L}$, if and only if $\\\\\\\\lim_{{t \\\\\\\\to a}} \\\\\\\\| \\\\\\\\mathbf{r}(t) - \\\\\\\\mathbf{L} \\\\\\\\| = 0$. This means that the distance between $\\\\\\\\mathbf{r}(t)$ and $\\\\\\\\mathbf{L}$ goes to zero as $t$ approaches $a$, ensuring the function $\\\\\\\\mathbf{r}(t)$ gets arbitrarily close to $\\\\\\\\mathbf{L}$. For example, if $\\\\\\\\mathbf{r}(t)$ represents a position vector moving towards a point $\\\\\\\\mathbf{L}$, as $t$ gets closer to $a$, the distance between the position defined by $\\\\\\\\mathbf{r}(t)$ and $\\\\\\\\mathbf{L}$ becomes negligible.',\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-1-vector-valued-functions-and-space-curves',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The limit of a vector-valued function $\\\\\\\\mathbf{r}(t) = f(t)\\\\\\\\mathbf{i} + g(t)\\\\\\\\mathbf{j} + h(t)\\\\\\\\mathbf{k}$ as $t$ approaches $a$ can be found by taking the limits of each of its component functions $f(t)$, $g(t)$, and $h(t)$ individually, provided these limits exist.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The statement is true. The limit of a vector-valued function $\\\\\\\\mathbf{r}(t) = f(t)\\\\\\\\mathbf{i} + g(t)\\\\\\\\mathbf{j} + h(t)\\\\\\\\mathbf{k}$ as $t$ approaches $a$ is given by $\\\\\\\\lim_{{t \\\\\\\\to a}} \\\\\\\\mathbf{r}(t) = [\\\\\\\\lim_{{t \\\\\\\\to a}} f(t)] \\\\\\\\mathbf{i} + [\\\\\\\\lim_{{t \\\\\\\\to a}} g(t)] \\\\\\\\mathbf{j} + [\\\\\\\\lim_{{t \\\\\\\\to a}} h(t)] \\\\\\\\mathbf{k}$, provided that the individual limits $\\\\\\\\lim_{{t \\\\\\\\to a}} f(t)$, $\\\\\\\\lim_{{t \\\\\\\\to a}} g(t)$, and $\\\\\\\\lim_{{t \\\\\\\\to a}} h(t)$ exist. For example, if $\\\\\\\\mathbf{r}(t) = t \\\\\\\\mathbf{i} + t^2 \\\\\\\\mathbf{j} + t^3 \\\\\\\\mathbf{k}$ and we are interested in the limit as $t$ approaches 1, we find that $\\\\\\\\lim_{{t \\\\\\\\to 1}} t = 1$, $\\\\\\\\lim_{{t \\\\\\\\to 1}} t^2 = 1$, and $\\\\\\\\lim_{{t \\\\\\\\to 1}} t^3 = 1$. Thus, $\\\\\\\\lim_{{t \\\\\\\\to 1}} \\\\\\\\mathbf{r}(t) = 1 \\\\\\\\mathbf{i} + 1 \\\\\\\\mathbf{j} + 1 \\\\\\\\mathbf{k} = \\\\\\\\mathbf{i} + \\\\\\\\mathbf{j} + \\\\\\\\mathbf{k}$.',\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-1-vector-valued-functions-and-space-curves',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: A vector-valued function $\\\\\\\\mathbf{r}(t)=f(t)\\\\\\\\mathbf{i}+g(t)\\\\\\\\mathbf{j}+h(t)\\\\\\\\mathbf{k}$ is continuous at point $t=a$ if $\\\\\\\\mathbf{r}(a)$ exists and $\\\\\\\\lim\\\\limits_{t \\\\\\\\to a} \\\\\\\\mathbf{r}(t) = \\\\\\\\mathbf{r}(a)$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'For the vector-valued function $\\\\\\\\mathbf{r}(t) = f(t)\\\\\\\\mathbf{i} + g(t)\\\\\\\\mathbf{j} + h(t)\\\\\\\\mathbf{k}$ to be continuous at $t = a$, the following three conditions must hold: 1) $\\\\\\\\mathbf{r}(a)$ exists, 2) $\\\\\\\\lim\\\\\\\\limits_{t \\\\\\\\to a} \\\\\\\\mathbf{r}(t)$ exists, 3) $\\\\\\\\lim\\\\\\\\limits_{t \\\\\\\\to a} \\\\\\\\mathbf{r}(t) = \\\\\\\\mathbf{r}(a)$. The given statement omits the second condition that $\\\\\\\\lim\\\\\\\\limits_{t \\\\\\\\to a} \\\\\\\\mathbf{r}(t)$ must exist.',\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-1-vector-valued-functions-and-space-curves',\n",
       "  'number': '4'},\n",
       " {'question': \"True or False: For a vector-valued function $ \\\\mathbf{r}(t) $ to be differentiable over the closed interval $ [a,b] $, the derivatives $ \\\\mathbf{r}'(a) $ and $ \\\\mathbf{r}'(b) $ must be evaluated using one-sided limits.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"For the function $ \\\\mathbf{r}(t) $ to be differentiable over a closed interval $ [a,b] $, the derivatives at the endpoints $ a $ and $ b $ need to be evaluated using one-sided limits. Specifically, $ \\\\mathbf{r}'(a) = \\\\lim_{\\\\Delta t \\\\to 0^{+}} \\\\frac{\\\\mathbf{r}(a + \\\\Delta t) - \\\\mathbf{r}(a)}{\\\\Delta t} $ requires the right-hand limit, while $ \\\\mathbf{r}'(b) = \\\\lim_{\\\\Delta t \\\\to 0^{-}} \\\\frac{\\\\mathbf{r}(b + \\\\Delta t) - \\\\mathbf{r}(b)}{\\\\Delta t} $ requires the left-hand limit. This ensures that the function is differentiable at the boundaries of the interval.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-2-calculus-of-vector-valued-functions',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: Given a vector-valued function $\\\\\\\\mathbf{r}(t) = f(t)\\\\\\\\mathbf{i} + g(t)\\\\\\\\mathbf{j} + h(t)\\\\\\\\mathbf{k}$, its derivative is given by $\\\\\\\\mathbf{r}'(t) = f'(t)\\\\\\\\mathbf{i} + g'(t)\\\\\\\\mathbf{j}$.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"The correct derivative of a vector-valued function $\\\\\\\\mathbf{r}(t) = f(t)\\\\\\\\mathbf{i} + g(t)\\\\\\\\mathbf{j} + h(t)\\\\\\\\mathbf{k}$ is $\\\\\\\\mathbf{r}'(t) = f'(t)\\\\\\\\mathbf{i} + g'(t)\\\\\\\\mathbf{j} + h'(t)\\\\\\\\mathbf{k}$. The mistake in the question is the omission of the $h'(t)\\\\\\\\mathbf{k}$ term. Each component function must be differentiated separately.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-2-calculus-of-vector-valued-functions',\n",
       "  'number': '2'},\n",
       " {'question': \"True or False: For differentiable vector-valued functions $\\\\\\\\mathbf{r}(t)$ and $\\\\\\\\mathbf{u}(t)$, and a scalar $c$, if $\\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}(t) = c$, then $\\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}'(t) = 0$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"If $\\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}(t)$ is constant and equal to $c$, this implies that the magnitude (or norm) of $\\\\\\\\mathbf{r}(t)$ is constant. The derivative of a constant is zero, so we have:$$\\\\\\\\frac{d}{dt} [\\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}(t)] = 0.$$Using the product rule for differentiation of the dot product, we get:$$\\\\\\\\frac{d}{dt} [\\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}(t)] = \\\\\\\\mathbf{r}'(t) \\\\\\\\cdot \\\\\\\\mathbf{r}(t) + \\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}'(t).$$Since $\\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}(t)$ is a scalar, this simplifies to:$$2 (\\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}'(t)) = 0.$$Thus, $$\\\\\\\\mathbf{r}(t) \\\\\\\\cdot \\\\\\\\mathbf{r}'(t) = 0,$$proving that the vector $\\\\\\\\mathbf{r}(t)$ is orthogonal to its derivative $\\\\\\\\mathbf{r}'(t)$.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-2-calculus-of-vector-valued-functions',\n",
       "  'number': '3'},\n",
       " {'question': \"True or False: The principal unit tangent vector $T(t)$ at $t=t_0$ is given by $T(t) = \\\\\\\\frac{r'(t)}{||r'(t)||}$, provided that $||r'(t)|| \\\\\\\\neq 0$. In particular, $T(t)$ is a normalized vector that is always tangent to the curve $C$ at $t=t_0$ if $r'(t_0) \\\\\\\\neq 0$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The given definition states that the principal unit tangent vector at time $t$ is defined as $T(t) = \\\\\\\\frac{r'(t)}{||r'(t)||}$, where $||r'(t)|| \\\\\\\\neq 0$. This vector is tangent to the curve at the point $r(t_0)$. The principal unit tangent vector is always tangent to the curve because it is derived from the first derivative $r'(t)$, which represents the direction of the curve's velocity at $t$. Normalizing $r'(t)$ ensures that $T(t)$ has unit length. For example, if $r(t) = (t, t^2)$, then $r'(t) = (1, 2t)$. At $t=1$, $T(1) = \\\\\\\\frac{(1, 2)}{\\\\\\\\sqrt{1^2 + 2^2}} = \\\\\\\\frac{(1, 2)}{\\\\\\\\sqrt{5}}$, which is a unit vector tangent to the curve at $t=1$.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-2-calculus-of-vector-valued-functions',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The definite integral of a vector-valued function $\\\\\\\\vec{r}(t) = f(t)\\\\\\\\hat{i} + g(t)\\\\\\\\hat{j} + h(t)\\\\\\\\hat{k}$ over the interval $[a,b]$ can be expressed as $\\\\\\\\int_{a}^{b} [f(t)\\\\\\\\hat{i} + g(t)\\\\\\\\hat{j} + h(t)\\\\\\\\hat{k}] dt = [\\\\\\\\int_{a}^{b} f(t) dt] \\\\\\\\hat{i} + [\\\\\\\\int_{a}^{b} g(t) dt] \\\\\\\\hat{j} + [\\\\\\\\int_{a}^{b} h(t) dt] \\\\\\\\hat{k}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The question tests understanding of the properties of the integral of vector-valued functions. According to the definition, the definite integral of a vector-valued function $\\\\\\\\vec{r}(t) = f(t)\\\\\\\\hat{i} + g(t)\\\\\\\\hat{j} + h(t)\\\\\\\\hat{k}$ over an interval $[a,b]$ can be computed by integrating each component function individually over that interval. Hence, $\\\\\\\\int_{a}^{b} [f(t)\\\\\\\\hat{i} + g(t)\\\\\\\\hat{j} + h(t)\\\\\\\\hat{k}] dt = [\\\\\\\\int_{a}^{b} f(t) dt] \\\\\\\\hat{i} + [\\\\\\\\int_{a}^{b} g(t) dt] \\\\\\\\hat{j} + [\\\\\\\\int_{a}^{b} h(t) dt] \\\\\\\\hat{k}$. This uses the linearity property of integrals. For instance, if $f(t)=t$, $g(t)=t^2$, and $h(t)=t^3$, then integrating each component independently over $[0,1]$ would yield the respective integrals for $t$, $t^2$, and $t^3$ separately.',\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-2-calculus-of-vector-valued-functions',\n",
       "  'number': '5'},\n",
       " {'question': \"True or False: For a smooth space curve \\\\( C \\\\) defined by the function \\\\( \\\\mathbf{r}(t) = f(t)\\\\mathbf{i} + g(t)\\\\mathbf{j} + h(t)\\\\mathbf{k} \\\\), where \\\\( t \\\\) lies within the interval \\\\([a, b]\\\\), the arc length \\\\( s \\\\) of \\\\( C \\\\) over the interval is given by \\\\( s = \\\\int_{a}^{b} \\\\sqrt{ [f'(t)]^2 + [g'(t)]^2 + [h'(t)]^2 } \\\\, dt = \\\\int_{a}^{b} \\\\| \\\\mathbf{r}'(t) \\\\| \\\\, dt \\\\).\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"This is true because the arc length of a smooth space curve \\\\( C \\\\) defined by the vector function \\\\( \\\\mathbf{r}(t) = f(t)\\\\mathbf{i} + g(t)\\\\mathbf{j} + h(t)\\\\mathbf{k} \\\\) over the interval \\\\([a, b]\\\\) is calculated by integrating the norm of the derivative of \\\\( \\\\mathbf{r}(t) \\\\). The formula \\\\( s = \\\\int_{a}^{b} \\\\sqrt{ [f'(t)]^2 + [g'(t)]^2 + [h'(t)]^2 } \\\\, dt = \\\\int_{a}^{b} \\\\| \\\\mathbf{r}'(t) \\\\| \\\\, dt \\\\) expresses this concept. For example, if \\\\( \\\\mathbf{r}(t) \\\\) represented the path of a particle in 3D space, this formula gives the total distance traveled by the particle along the path from \\\\( t = a \\\\) to \\\\( t = b \\\\).\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-3-arc-length-and-curvature',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: If $\\\\\\\\|r'(t)\\\\\\\\| = 1$ for all $t \\\\\\\\geq a$, then the arc-length function $s(t)$ equals $t-a$ for $t \\\\\\\\geq a$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The arc-length function is defined as $s(t) = \\\\\\\\int_a^t \\\\\\\\|r'(u)\\\\\\\\| du$. If $\\\\\\\\|r'(t)\\\\\\\\| = 1$ for all $t \\\\\\\\geq a$, then $\\\\\\\\|r'(u)\\\\\\\\| = 1$ over the entire interval of integration. Thus, $s(t) = \\\\\\\\int_a^t 1 \\\\\\\\, du = t - a$. This shows that $s(t)$ equals the parameter $t$ minus the initial point $a$, confirming the statement as true.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-3-arc-length-and-curvature',\n",
       "  'number': '2'},\n",
       " {'question': \"True or False: The curvature $\\\\kappa$ at a point on a smooth curve $C$ given by $\\\\mathbf{r}(s)$, where $s$ is the arc-length parameter, is defined as $\\\\kappa = \\\\| \\\\frac{d\\\\mathbf{T}}{ds} \\\\|$ or equivalently $\\\\kappa = \\\\| \\\\mathbf{T}'(s) \\\\|$, where $\\\\mathbf{T}$ is the unit tangent vector to the curve.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The curvature $\\\\kappa$ measures how quickly the unit tangent vector $\\\\mathbf{T}$ changes as one moves along the curve. The curvature is given by $\\\\kappa = \\\\| \\\\frac{d\\\\mathbf{T}}{ds} \\\\|$, which signifies the magnitude of the derivative of the unit tangent vector $\\\\mathbf{T}$ with respect to the arc-length parameter $s$. Since $\\\\mathbf{T}'(s) = \\\\frac{d\\\\mathbf{T}}{ds}$, the expression $\\\\kappa = \\\\| \\\\mathbf{T}'(s) \\\\|$ is equivalent. For example, a straight line has zero curvature because its tangent vector does not change, while a circle of radius $r$ has constant curvature $\\\\kappa = \\\\frac{1}{r}$ because the tangent vector changes at a constant rate.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-3-arc-length-and-curvature',\n",
       "  'number': '3'},\n",
       " {'question': \"True or False? For a smooth, three-dimensional curve $C$ given by the vector function $r(t)$, the curvature $\\\\kappa$ can be calculated using the formula $\\\\\\\\kappa = \\\\\\\\frac{ \\\\\\\\|r'(t) \\\\\\\\times r''(t)\\\\\\\\| }{ \\\\\\\\|r'(t)\\\\\\\\|^3 }$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The curvature $\\\\kappa$ of a smooth, three-dimensional curve $C$, given by the vector function $r(t)$, measures how sharply the curve bends at a point. One of the formulas to calculate this curvature in three dimensions is $\\\\\\\\kappa = \\\\\\\\frac{ \\\\\\\\|r'(t) \\\\\\\\times r''(t)\\\\\\\\| }{ \\\\\\\\|r'(t)\\\\\\\\|^3 }$. Here, $r'(t)$ is the first derivative of $r(t)$ with respect to $t$, representing the tangent vector to the curve, and $r''(t)$ is the second derivative of $r(t)$ with respect to $t$, representing the rate of change of the tangent vector. The numerator, $\\\\\\\\|r'(t) \\\\\\\\times r''(t)\\\\\\\\|$, is the magnitude of the cross product of these two vectors, giving a measure of how much the curve twists out of the tangent plane, while the denominator, $\\\\\\\\|r'(t)\\\\\\\\|^3$, normalizes this by the cube of the tangent vector's magnitude. This formula is derived from the more general formula for curvature using three-dimensional vector functions.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-3-arc-length-and-curvature',\n",
       "  'number': '4'},\n",
       " {'question': \"True or False: If $T'(t) = 0$, then we can still define the principal unit normal vector $N(t)$ for a three-dimensional smooth curve $C$ represented by $\\\\\\\\mathbf{r}$ over an open interval $I$.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"The principal unit normal vector $N(t)$ is defined as $N(t) = \\\\\\\\frac{T'(t)}{\\\\\\\\|T'(t)\\\\\\\\|}$. For this expression to be valid, $T'(t) \\\\\\\\neq 0$ must hold because division by zero is undefined. If $T'(t) = 0$, then $\\\\\\\\|T'(t)\\\\\\\\| = 0$, making it impossible to compute $N(t)$. Therefore, $T'(t) \\\\\\\\neq 0$ is a necessary condition for defining the principal unit normal vector $N(t)$. For example, if $T'(t) = 0$ at some point, $N(t)$ would be undefined at that point.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-3-arc-length-and-curvature',\n",
       "  'number': '5'},\n",
       " {'question': \"True or False: For a twice-differentiable vector-valued function $r(t)$ representing the position of an object, the speed of the object is given by $ \\\\| r''(t) \\\\| $.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"Speed is defined as the magnitude of the velocity vector, which is given by $ \\\\| v(t) \\\\| $ or $ \\\\| r'(t) \\\\| $. The expression $ \\\\| r''(t) \\\\| $ represents the magnitude of the acceleration vector, not the speed. For example, if $r(t)$ represents the position function, $v(t) = r'(t)$ is the velocity and $a(t) = r''(t)$ is the acceleration. Therefore, the speed is $ \\\\| v(t) \\\\| = \\\\| r'(t) \\\\| $.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-4-motion-in-space',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: For an object moving along a curve traced out by a twice-differentiable function $r(t)$, the acceleration vector $\\\\mathbf{a}(t)$ always lies in the plane formed by the unit tangent vector $\\\\mathbf{T}(t)$ and the principal unit normal vector $\\\\mathbf{N}(t)$. The expression for the acceleration vector is given by $\\\\mathbf{a}(t) = v'(t)\\\\mathbf{T}(t) + [v(t)]^2 \\\\kappa \\\\mathbf{N}(t)$, where $v(t)$ is the speed of the object and $\\\\kappa$ is the curvature of the curve $C$ traced out by $r(t)$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The given expression for the acceleration vector $\\\\mathbf{a}(t)$ indicates that it is a linear combination of the unit tangent vector $\\\\mathbf{T}(t)$ and the principal unit normal vector $\\\\mathbf{N}(t)$. Specifically, $\\\\mathbf{a}(t) = v'(t)\\\\mathbf{T}(t) + [v(t)]^2 \\\\kappa \\\\mathbf{N}(t)$ shows that $\\\\mathbf{a}(t)$ is constructed from components along $\\\\mathbf{T}(t)$ and $\\\\mathbf{N}(t)$. Since any linear combination of $\\\\mathbf{T}(t)$ and $\\\\mathbf{N}(t)$ lies in the plane formed by these vectors, the acceleration vector $\\\\mathbf{a}(t)$ must also lie within this plane. This holds true as long as the function $r(t)$ is twice-differentiable, ensuring that $\\\\mathbf{T}(t)$ and $\\\\mathbf{N}(t)$ are well-defined.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-4-motion-in-space',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The formula $a(t) = a_T T(t) + a_N N(t)$ represents the decomposition of the acceleration vector into its tangential and normal components, where $a_T = \\\\\\\\frac{v \\\\\\\\cdot a}{||v||}$ and $a_N = \\\\\\\\frac{||v \\\\\\\\times a||}{||v||}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The given formula $a(t) = a_T T(t) + a_N N(t)$ indeed represents the acceleration vector's decomposition into its tangential and normal components. Here, $a_T$ is the tangential component, which measures the rate of change of speed in the direction of the velocity vector $T(t)$. It is defined as $a_T = \\\\\\\\frac{v \\\\\\\\cdot a}{||v||}$, where $v$ is the velocity vector and $a$ is the acceleration vector. The normal component $a_N$ measures the rate of change of direction of the velocity vector and is given by $a_N = \\\\\\\\frac{||v \\\\\\\\times a||}{||v||}$. These components are orthogonal, meaning they describe different aspects of the acceleration: $a_T$ along the direction of motion and $a_N$ perpendicular to it. An example could be a car moving in a circular path where the tangential component would involve changes in speed along the path, while the normal component would reflect changes due to the curved nature of the path.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-4-motion-in-space',\n",
       "  'number': '3'},\n",
       " {'question': \"True or False: According to Kepler's Laws of Planetary Motion, the ratio of the periods of any two planets is equal to the ratio of the cubes of the lengths of their semimajor orbital axes.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"Kepler's Third Law, or the law of harmonies, states that the ratio of the squares of the periods (\\\\(T\\\\)) of any two planets is equal to the ratio of the cubes of the lengths of their semimajor orbital axes (\\\\(a\\\\)). Mathematically, this is represented as \\\\(\\\\left(\\\\frac{T_1}{T_2}\\\\right)^2 = \\\\left(\\\\frac{a_1}{a_2}\\\\right)^3\\\\). Therefore, the statement should reference the squares of the periods, not the periods themselves. For example, if Planet A's period is 8 years and its semimajor axis is 4 AU, and Planet B's period is 2 years and its semimajor axis is 1 AU, the ratios of the squares of the periods (64:4) and the cubes of the semimajor axes (64:1) confirm Kepler's Third Law.\",\n",
       "  'chapter': 'Vector-Valued Functions',\n",
       "  'section': '3-4-motion-in-space',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The domain of a function $z=f(x,y)$ is the set of all real numbers $z$ that are mapped to by at least one ordered pair $(x,y)$ in a subset $D$ of the real plane $\\\\mathbb{R}^2$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The domain of a function $z=f(x,y)$ is actually the set of all ordered pairs $(x,y)$ in a subset $D$ of the real plane $\\\\mathbb{R}^2$. The range of the function, on the other hand, is the set of all real numbers $z$ that are mapped by at least one ordered pair $(x,y) \\\\in D$ such that $f(x,y) = z$. For example, if $f(x,y) = x^2 + y^2$ and $D$ is the set of all $(x,y)$ in $\\\\mathbb{R}^2$, then the domain is all $(x,y) \\\\in \\\\mathbb{R}^2$, and the range is all $z \\\\geq 0$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-1-functions-of-several-variables',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: A level curve of a function $f(x,y)$ for a value $c$ is defined to be the set of points $(x, y)$ that satisfy the equation $f(x, y) = c$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A level curve of a function $f(x,y)$ for a given value $c$ is indeed the set of all points $(x, y)$ that make the equation $f(x, y) = c$ true. This means that at each point $(x, y)$ on the level curve, the function $f$ takes the constant value $c$. For example, if $f(x, y) = x^2 + y^2$ and $c = 1$, the level curve consists of the points that satisfy $x^2 + y^2 = 1$, which is a circle of radius 1 centered at the origin.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-1-functions-of-several-variables',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: A vertical trace of the function $z = f(x,y)$ can be obtained by setting either $x = a$ or $y = b$ where $a$ and $b$ are constants, and then examining the resulting equation in one variable.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition specifies that a vertical trace of the function $z = f(x,y)$ is the set of points that solves the equation $f(a,y) = z$ for a given constant $x = a$ or $f(x,b) = z$ for a given constant $y = b$. This means that by setting either $x = a$ or $y = b$, we reduce the function to a single-variable function in terms of $y$ or $x$ respectively. For example, if $f(x,y) = x^2 + y^2$, setting $x = 1$ gives us the trace $z = 1^2 + y^2 = 1 + y^2$, which is an equation in $y$. Similarly, setting $y = 2$ gives us the trace $z = x^2 + 2^2 = x^2 + 4$, which is an equation in $x$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-1-functions-of-several-variables',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: If $f(x,y,z)$ is a function of three variables and $c$ is a constant within the range of $f$, then the set of points $(x,y,z)$ satisfying the equation $f(x,y,z) = c$ represents a level surface of the function.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'According to the definition, a level surface of a function $f(x,y,z)$ is formed by the set of all points $(x,y,z)$ such that $f(x,y,z) = c$, where $c$ is a given constant within the range of $f$. This concept generalizes the idea of level curves in two dimensions to three dimensions. For instance, if $f(x,y,z) = x^2 + y^2 + z^2$ and $c=1$, then the level surface is the set of points $(x,y,z)$ on the sphere with radius $1$, i.e., $x^2 + y^2 + z^2 = 1$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-1-functions-of-several-variables',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: A $\\\\\\\\delta$-disk centered at the point $(a,b) \\\\\\\\in \\\\\\\\mathbb{R}^2$ is the set of all points $(x,y) \\\\\\\\in \\\\\\\\mathbb{R}^2$ for which the distance between $(x,y)$ and $(a,b)$ is less than or equal to $\\\\\\\\delta$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': \"A $\\\\\\\\delta$-disk centered at the point $(a,b) \\\\\\\\in \\\\\\\\mathbb{R}^2$ is defined as the set of all points $(x,y) \\\\\\\\in \\\\\\\\mathbb{R}^2$ such that the distance between $(x,y)$ and $(a,b)$ is strictly less than $\\\\\\\\delta$. Formally, this is represented as:$$\\\\\\\\{(x,y) \\\\\\\\in \\\\\\\\mathbb{R}^2 | (x-a)^2 + (y-b)^2 < \\\\\\\\delta^2 \\\\\\\\}$$The statement in the question incorrectly includes the boundary of the disk by stating the distance can be 'less than or equal to $\\\\\\\\delta$'. An open disk does not include its boundary, so this inclusion is incorrect. For example, for $\\\\\\\\delta = 1$ and $(a,b) = (0,0)$, the point $(1,0)$ would not be included in the disk because $\\\\\\\\sqrt{(1-0)^2 + (0-0)^2} = 1$, which is not strictly less than $\\\\\\\\delta$.\",\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The limit of a function \\\\( f(x, y) \\\\) as \\\\( (x, y) \\\\) approaches \\\\( (a, b) \\\\) is \\\\( L \\\\) if for any \\\\( \\\\varepsilon > 0 \\\\), there exists a number \\\\( \\\\delta > 0 \\\\) such that \\\\( |f(x, y) - L| < \\\\varepsilon \\\\) whenever \\\\( 0 < \\\\sqrt{(x-a)^2 + (y-b)^2} < \\\\delta \\\\).',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The correct condition for the limit \\\\( \\\\lim_{(x,y) \\\\to (a,b)} f(x,y) = L \\\\) is that for any \\\\( \\\\varepsilon > 0 \\\\), there exists a \\\\( \\\\delta > 0 \\\\) such that \\\\( |f(x, y) - L| < \\\\varepsilon \\\\) whenever \\\\( 0 < (x-a)^2 + (y-b)^2 < \\\\delta^2 \\\\). The given statement incorrectly uses \\\\( 0 < \\\\sqrt{(x-a)^2 + (y-b)^2} < \\\\delta \\\\), whereas the correct formulation should avoid introducing the square root in the inequality and involve \\\\( \\\\delta^2 \\\\).',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: If $\\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} f(x,y) = L$ and $\\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} g(x,y) = M$, then $\\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} [f(x,y) + g(x,y)] = \\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} f(x,y) + \\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} g(x,y)]$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is an application of the Sum Law for limits of functions of two variables. According to the Sum Law, if $\\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} f(x,y) = L$ and $\\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} g(x,y) = M$, then $\\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} [f(x,y) + g(x,y)] = L + M$. The formula can be rephrased as $\\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} [f(x,y) + g(x,y)] = \\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} f(x,y) + \\\\\\\\lim_{(x,y)\\\\\\\\to(a,b)} g(x,y)$, which simplifies to the initial sum, thus proving it true.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: If $P_0$ is a boundary point of a subset $S \\\\subset \\\\mathbb{R}^2$, then every $\\\\\\\\delta$ disk centered around $P_0$ contains points inside $S$ as well as points outside of $S$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A boundary point $P_0$ of a subset $S \\\\subset \\\\mathbb{R}^2$ is defined such that every $\\\\\\\\delta$ disk centered around $P_0$ contains points both inside and outside of $S$. For example, consider the boundary point of a circle; any disk centered at this point will touch both the interior and exterior of the circle, satisfying the given condition.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: If a subset $S$ of $\\\\mathbb{R}^2$ contains all its boundary points, then $S$ is an open set.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'A subset $S$ of $\\\\mathbb{R}^2$ is called a closed set if it contains all its boundary points. However, an open set requires every point in $S$ to be an interior point, meaning that for every point $x$ in $S$, there exists an $\\\\epsilon$-ball centered at $x$ that is entirely contained within $S$. A set can be closed but not open if it includes its boundary points yet does not fulfill the requirement for each point to be an interior point. For example, the set $[0,1]$ in $\\\\mathbb{R}$ is closed because it contains its boundary points 0 and 1 but is not open because every point does not have an $\\\\epsilon$-ball contained entirely within $[0,1]$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: A set $S \\\\subset \\\\mathbb{R}^2$ is a region if and only if it is open, connected, and nonempty.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'By definition, a set $S \\\\subset \\\\mathbb{R}^2$ is considered a region if it satisfies the following conditions: it must be open, connected, and nonempty. An open set means every point in the set has a neighborhood entirely contained within the set. A connected set means it cannot be represented as the union of two or more disjoint, nonempty open subsets. Finally, being nonempty simply means the set contains at least one element. For example, the interior of a circle in $\\\\mathbb{R}^2$ is a region because it is open, connected, and nonempty.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: If $ \\\\lim_{(x,y) \\\\to (a,b)} f(x,y) = L $, then for every $ \\\\epsilon > 0 $, there exists a $ \\\\delta > 0 $ such that $ |f(x,y) - L| < \\\\epsilon $ whenever $ 0 < (x - a)^2 + (y - b)^2 < \\\\delta $.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of the limit for a function of two variables $ f(x, y) $ as $ (x, y) $ approaches $ (a, b) $ to be $ L $ requires that for every $ \\\\epsilon > 0 $, there must exist a $ \\\\delta > 0 $ such that the distance between $ f(x, y) $ and $ L $ is less than $ \\\\epsilon $ whenever the distance between $ (x, y) $ and $ (a, b) $ (measured by $ (x - a)^2 + (y - b)^2 $) is positive and less than $ \\\\delta $. This concept ensures that $ f(x, y) $ gets arbitrarily close to $ L $ as $ (x, y) $ nears $ (a, b) $, within a specific neighborhood defined by $ \\\\delta $. This definition is analogous to the $\\\\epsilon-\\\\delta$ definition of a limit in single-variable calculus but extended to two variables. For example, if $ f(x, y) = x^2 + y^2 $ and $ (a, b) = (0, 0) $, then $ \\\\lim_{(x,y) \\\\to (0,0)} f(x,y) = 0 $ because for any chosen $ \\\\epsilon $, you can find an appropriate $ \\\\delta $ such that $ |x^2 + y^2 - 0| < \\\\epsilon $ whenever $ 0 < x^2 + y^2 < \\\\delta $. Therefore, the statement is true.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: For a function $f(x,y)$ to be continuous at a point $(a,b)$ in its domain, it is sufficient that $f(a,b)$ exists.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'For a function $f(x,y)$ to be continuous at a point $(a,b)$, it must satisfy three conditions:    1. $f(a,b)$ must exist.    2. $\\\\lim_{(x,y) \\\\to (a,b)} f(x,y)$ must exist.    3. $\\\\lim_{(x,y) \\\\to (a,b)} f(x,y) = f(a,b)$.  Simply having $f(a,b)$ exist is not enough; the limit of the function as $(x,y)$ approaches $(a,b)$ must also exist and be equal to $f(a,b)$. For example, if $f(x,y) = \\\\frac{\\\\sin(x^2 + y^2)}{x^2 + y^2}$ at $(0,0)$, while $f(0,0)$ might be defined, analyzing the limit as $(x,y) \\\\to (0,0)$ reveals if it truly matches $f(0,0)$ for continuity.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '8'},\n",
       " {'question': 'True or False: If $f(x,y)$ is continuous at $(x_0,y_0)$ and $g(x,y)$ is continuous at $(x_0,y_0)$, then $f(x,y) + g(x,y)$ is continuous at $(x_0,y_0)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The continuity of a function $h(x,y)$ at a point $(x_0, y_0)$ means $\\\\lim_{(x,y) \\\\to (x_0,y_0)} h(x,y) = h(x_0, y_0)$. If $f(x,y)$ and $g(x,y)$ are both continuous at $(x_0,y_0)$, then $\\\\lim_{(x,y) \\\\to (x_0,y_0)} f(x,y) = f(x_0, y_0)$ and $\\\\lim_{(x,y) \\\\to (x_0,y_0)} g(x,y) = g(x_0, y_0)$. Consequently, the limit of their sum as $(x,y)$ approaches $(x_0, y_0)$ is $\\\\lim_{(x,y) \\\\to (x_0,y_0)} (f(x,y) + g(x,y)) = \\\\lim_{(x,y) \\\\to (x_0,y_0)} f(x,y) + \\\\lim_{(x,y) \\\\to (x_0,y_0)} g(x,y) = f(x_0, y_0) + g(x_0, y_0) = (f+g)(x_0, y_0)$, thus proving $f(x,y) + g(x,y)$ is continuous at $(x_0, y_0)$. For example, if $f(x,y) = x + y$ and $g(x,y) = xy$, both are continuous functions, hence their sum $f(x,y) + g(x,y) = x + y + xy$ is also continuous at any given point $(x_0, y_0)$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '9'},\n",
       " {'question': 'True or False: If $g(x)$ is continuous at $x_0$ and $h(y)$ is continuous at $y_0$, then the function $f(x, y) = g(x) \\\\cdot h(y)$ is continuous at $(x_0, y_0)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'By definition, the product of continuous functions is also continuous. Since $g(x)$ is continuous at $x_0$ and $h(y)$ is continuous at $y_0$, their product $f(x, y) = g(x) \\\\cdot h(y)$ must be continuous at $(x_0, y_0)$. For example, if $g(x) = x$ and $h(y) = y$, both functions are continuous everywhere. Therefore, $f(x, y) = xy$ is also continuous everywhere, including at any specific point such as $(x_0, y_0)$. This illustrates how the continuity of the product follows from the continuity of each factor.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '10'},\n",
       " {'question': 'True or False: If $g: D \\\\subseteq \\\\mathbb{R}^2 \\\\to \\\\mathbb{R}$ is continuous at a point $(x_0, y_0) \\\\in D$ and $f: \\\\mathbb{R} \\\\to \\\\mathbb{R}$ is continuous at $z_0 = g(x_0, y_0)$, then the composition $f \\\\circ g$ is continuous at $(x_0, y_0)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The composition of continuous functions is continuous. Here, $g$ is continuous at $(x_0, y_0)$, meaning that small changes in $(x_0, y_0)$ result in small changes in $z_0 = g(x_0, y_0)$. Since $f$ is continuous at $z_0$, small changes in $z_0$ result in small changes in $f(z_0)$, or $f(g(x_0, y_0))$. Therefore, by the composition of these properties, $f \\\\circ g$ is continuous at $(x_0, y_0)$. For example, if $g(x, y) = x + y$ and $f(z) = z^2$, the function $f(g(x,y)) = (x + y)^2$ is continuous at any point $(x_0, y_0)$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '11'},\n",
       " {'question': 'True or False: For a point $(x_0, y_0, z_0)$ in $\\\\\\\\mathbb{R}^3$, a $\\\\\\\\delta$ ball consists of all points $(x, y, z)$ such that $\\\\\\\\sqrt{(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2} < \\\\\\\\delta$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A $\\\\\\\\delta$ ball in $\\\\\\\\mathbb{R}^3$ around the point $(x_0, y_0, z_0)$ includes all points $(x, y, z)$ such that the Euclidean distance to $(x_0, y_0, z_0)$ is less than $\\\\\\\\delta$. Mathematically, this is represented as $\\\\\\\\{(x, y, z) \\\\\\\\in \\\\\\\\mathbb{R}^3 \\\\\\\\mid (x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 < \\\\\\\\delta^2\\\\\\\\}$. The provided definition under the square root and with $<$ $\\\\\\\\delta$ conveys the same concept since taking a square root of both sides of the inequality $((x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 < \\\\\\\\delta^2)$ yields the equivalent form $\\\\\\\\sqrt{(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2} < \\\\\\\\delta$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-2-limits-and-continuity',\n",
       "  'number': '12'},\n",
       " {'question': 'True or False: The partial derivative of a function $f(x, y)$ with respect to $x$, denoted as $\\\\frac{\\\\partial f}{\\\\partial x}$, is defined as $\\\\lim_{k \\\\to 0}\\\\frac{f(x + k, y) - f(x, y)}{k}$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The partial derivative of $f(x, y)$ with respect to $x$ is correctly denoted as $\\\\frac{\\\\partial f}{\\\\partial x}$ but is defined as $\\\\lim_{h \\\\to 0}\\\\frac{f(x + h, y) - f(x, y)}{h}$. The given limit notation uses $k$ and suggests a change in $x$, which is conceptually incorrect for the definition of $\\\\frac{\\\\partial f}{\\\\partial x}$. The correct definition involves change in $x$ when $h$ approaches zero, while changes in $y$ involve $k$ approaching zero.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-3-partial-derivatives',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The partial derivative of a function $f(x,y,z)$ with respect to $x$ is given by $\\\\\\\\frac{\\\\\\\\partial f}{\\\\\\\\partial x} = \\\\\\\\lim_{h \\\\\\\\to 0} \\\\\\\\frac{f(x+h, y, z) - f(x, y, z)}{h}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The partial derivative of a function $f(x, y, z)$ with respect to $x$, denoted as $\\\\\\\\frac{\\\\\\\\partial f}{\\\\\\\\partial x}$, measures how $f$ changes as $x$ changes while keeping $y$ and $z$ constant. By definition, it is calculated as $\\\\\\\\lim_{h \\\\\\\\to 0} \\\\\\\\frac{f(x+h, y, z) - f(x, y, z)}{h}$. Similarly, partial derivatives with respect to $y$ and $z$ are given by $\\\\\\\\frac{\\\\\\\\partial f}{\\\\\\\\partial y} = \\\\\\\\lim_{k \\\\\\\\to 0} \\\\\\\\frac{f(x, y+k, z) - f(x, y, z)}{k}$ and $\\\\\\\\frac{\\\\\\\\partial f}{\\\\\\\\partial z} = \\\\\\\\lim_{m \\\\\\\\to 0} \\\\\\\\frac{f(x, y, z+m) - f(x, y, z)}{m}$, respectively. These definitions illustrate how partial derivatives isolate the effect of changing one variable at a time.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-3-partial-derivatives',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: If a function $f(x,y)$ is defined on an open disk $D$ containing the point $(a,b)$, and the mixed partial derivatives $f_{xy}$ and $f_{yx}$ are continuous on $D$, then $f_{xy} = f_{yx}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'According to Clairaut’s Theorem, if a function $f(x,y)$ is defined on an open disk $D$ that contains the point $(a,b)$ and if the mixed partial derivatives $f_{xy}$ and $f_{yx}$ are continuous on $D$, then these mixed partial derivatives are equal, i.e., $f_{xy} = f_{yx}$. This theorem tells us that the order of differentiation does not matter in this case. For example, if we have a function $f(x,y) = x^2 y + y^3$, the mixed partial derivatives $f_{xy} = 2x + 3y^2$ and $f_{yx} = 2x + 3y^2$ are continuous and equal.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-3-partial-derivatives',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: If the tangent lines to all curves passing through a point $P_0$ on a surface $S$ lie in the same plane, then this plane is known as the tangent plane to the surface $S$ at point $P_0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A tangent plane to a surface $S$ at a point $P_0 = (x_0, y_0, z_0)$ is defined as the plane in which the tangent lines to all possible curves passing through $P_0$ lie. This plane represents a local linear approximation to the surface at that point. For instance, on a smooth surface like a sphere, the tangent plane at a particular point would contain all the tangent lines to curves on the surface passing through that point.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-4-tangent-planes-and-linear-approximations',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The equation of the tangent plane to a surface defined by a differentiable function $z = f(x, y)$ at a point $P_0 = (x_0, y_0)$ is given by $z = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given equation $z = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0)$ accurately represents the tangent plane to the surface $z = f(x, y)$ at the point $P_0 = (x_0, y_0)$. This formula is derived from the first-order Taylor expansion of the function $f$ around the point $P_0$. The partial derivatives $f_x(x_0, y_0)$ and $f_y(x_0, y_0)$ represent the slopes of the surface in the $x$ and $y$ directions at $P_0$, respectively. The constant term $f(x_0, y_0)$ is the height of the surface at $P_0$. Together, these components form the linear approximation to the surface at the point of tangency. For example, if $f(x, y) = x^2 + y^2$, and considering the point $(1, 1)$, the partial derivatives are $f_x = 2x$ and $f_y = 2y$. At $(1, 1)$, these derivatives evaluate to 2, thus the tangent plane equation would be $z = 2 + 2(x - 1) + 2(y - 1) = 2x + 2y - 2$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-4-tangent-planes-and-linear-approximations',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: If the function \\\\( z = f(x, y) \\\\) has continuous partial derivatives at the point \\\\( (x_0, y_0) \\\\), then the linear approximation of \\\\( f \\\\) at \\\\( (x_0, y_0) \\\\) is given by \\\\( L(x, y) = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0) \\\\).',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The linear approximation (or tangent plane approximation) is used to approximate the value of a function \\\\( f(x, y) \\\\) near a point \\\\( (x_0, y_0) \\\\) using a linear function. The formula \\\\( L(x, y) = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0) \\\\) expresses this approximation as a plane tangent to the surface defined by \\\\( z = f(x, y) \\\\) at \\\\( (x_0, y_0) \\\\). Here, \\\\( f_x(x_0, y_0) \\\\) and \\\\( f_y(x_0, y_0) \\\\) represent the partial derivatives of \\\\( f \\\\) with respect to \\\\( x \\\\) and \\\\( y \\\\) evaluated at \\\\( (x_0, y_0) \\\\). For example, if \\\\( f(x, y) = x^2 + y^2 \\\\), at the point \\\\( (1, 1) \\\\), the linear approximation would be \\\\( L(x, y) = 2 + 2(x - 1) + 2(y - 1) \\\\).',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-4-tangent-planes-and-linear-approximations',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: A function $f(x,y)$ is differentiable at a point $P(x_0, y_0)$ if, for all points $(x,y)$ in a $\\\\delta$-disk around $P$, we can write $f(x,y) = f(x_0,y_0) + f_x(x_0,y_0)(x-x_0) + f_y(x_0,y_0)(y-y_0) + E(x,y)$, where the error term $E$ satisfies $\\\\lim_{(x,y)\\\\to(x_0,y_0)} \\\\frac{E(x,y)}{(x-x_0)^2 + (y-y_0)^2}=0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of differentiability at a point $P(x_0, y_0)$ for a function $f(x,y)$ involves expressing the function in terms of a linear approximation plus an error term $E(x,y)$. The error term must become insignificant relative to the square of the distance from $(x,y)$ to $(x_0, y_0)$ as $(x,y)$ approaches $(x_0, y_0)$. This means $\\\\lim_{(x,y)\\\\to(x_0,y_0)} \\\\frac{E(x,y)}{(x-x_0)^2 + (y-y_0)^2}=0$. For example, if $f(x,y) = x^2 + y^2$, then $f$ is differentiable at $(0,0)$ with $f_x = 0$ and $f_y = 0$, and the error term $E(x,y) = x^2 + y^2$ satisfies the required limit condition.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-4-tangent-planes-and-linear-approximations',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: If a function $z = f(x, y)$ of two variables is differentiable at a point $(x_0, y_0)$, then it must also be continuous at $(x_0, y_0)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'For any function $f(x, y)$ to be differentiable at a point $(x_0, y_0)$, it must be expressible as a linear approximation involving partial derivatives at that point. This implies that the function can be approximated by a plane in the vicinity of $(x_0, y_0)$, making the function behave smoothly and without abrupt changes around this point. As a result, such a function must also be continuous at $(x_0, y_0)$ because differentiability (which involves the existence of partial derivatives and their linearity) necessitates that $f(x, y)$ does not have sudden jumps or breaks at that point. For example, if $f(x,y) = x^2 + y^2$, it is differentiable everywhere, hence it is also continuous everywhere, particularly at any arbitrary point $(x_0, y_0)$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-4-tangent-planes-and-linear-approximations',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: If $z = f(x, y)$ has partial derivatives $f_x$ and $f_y$ that are continuous at $(x_0, y_0)$, then $f(x, y)$ is differentiable at $(x_0, y_0)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The continuity of the first partial derivatives $f_x$ and $f_y$ at a point $(x_0, y_0)$ implies that $f(x, y)$ is differentiable at that point. Differentiability means that $f(x, y)$ can be approximated by a linear function near $(x_0, y_0)$. For instance, if $f(x, y)$, $f_x(x, y)$, and $f_y(x, y)$ exist and $f_x$ and $f_y$ are continuous in a neighborhood of $(x_0, y_0)$, then the function behaves smoothly and is differentiable at $(x_0, y_0)$. An example is the function $f(x, y) = x^2 + y^2$, which is differentiable at every point because its partial derivatives $f_x = 2x$ and $f_y = 2y$ are continuous everywhere.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-4-tangent-planes-and-linear-approximations',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: If \\\\( z = f(x,y) \\\\) is differentiable at \\\\( (x_0, y_0) \\\\), then the total differential \\\\( dz \\\\) at \\\\( (x_0, y_0) \\\\) can be expressed as \\\\( dz = f_x(x_0, y_0) dx + f_y(x_0, y_0) dy \\\\), where \\\\( dx = \\\\Delta x \\\\) and \\\\( dy = \\\\Delta y \\\\).',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The total differential \\\\( dz \\\\) of a function \\\\( z = f(x, y) \\\\) at a point \\\\( (x_0, y_0) \\\\) is given as \\\\( dz = f_x(x_0, y_0) dx + f_y(x_0, y_0) dy \\\\). For this relationship to hold, the function must be differentiable at \\\\( (x_0, y_0) \\\\). Here, \\\\( f_x(x_0, y_0) \\\\) and \\\\( f_y(x_0, y_0) \\\\) are the partial derivatives of \\\\( f \\\\) with respect to \\\\( x \\\\) and \\\\( y \\\\) at \\\\( (x_0, y_0) \\\\), respectively, and \\\\( dx \\\\) and \\\\( dy \\\\) represent small changes in \\\\( x \\\\) and \\\\( y \\\\), specifically \\\\( dx = \\\\Delta x \\\\) and \\\\( dy = \\\\Delta y \\\\). This linear approximation allows us to estimate the change in the function \\\\( f \\\\) due to changes in \\\\( x \\\\) and \\\\( y \\\\).',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-4-tangent-planes-and-linear-approximations',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: A function $f(x, y, z)$ is differentiable at a point $P(x_0, y_0, z_0)$ if it can be expressed as $f(x, y, z) = f(x_0, y_0, z_0) + f_x(x_0, y_0, z_0)(x - x_0) + f_y(x_0, y_0, z_0)(y - y_0) + f_z(x_0, y_0, z_0)(z - z_0) + E(x, y, z)$, where the error term $E(x, y, z)$ satisfies $\\\\lim_{{(x, y, z) \\\\to (x_0, y_0, z_0)}} \\\\frac{E(x, y, z)}{(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2} = 0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of differentiability for a function $f(x, y, z)$ at a point $P(x_0, y_0, z_0)$ states that we can express the function in terms of its value at $P$ and its partial derivatives at $P$ along with an error term $E(x, y, z)$. The error term must tend to zero faster than the distance squared from $(x, y, z)$ to $(x_0, y_0, z_0)$ as $(x, y, z)$ approaches $(x_0, y_0, z_0)$. This ensures that the linear approximation becomes increasingly accurate near the point $P$. For example, if $f(x, y, z) = x^2 + y^2 + z^2$, then at the point $(0, 0, 0)$ it can be expressed as $f(x, y, z) = 0 + 0 + 0 + 0 + E(x, y, z)$, where $E(x, y, z) = x^2 + y^2 + z^2$ satisfies the required limit condition.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-4-tangent-planes-and-linear-approximations',\n",
       "  'number': '8'},\n",
       " {'question': 'True or False: The chain rule for one independent variable states that if $x = g(t)$ and $y = h(t)$ are differentiable functions of $t$, and $z = f(x,y)$ is a differentiable function of $x$ and $y$, then $z = f(x(t), y(t))$ is also a differentiable function of $t$ with $\\\\\\\\frac{dz}{dt} = \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial x} \\\\\\\\cdot \\\\\\\\frac{dx}{dt} + \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial y} \\\\\\\\cdot \\\\\\\\frac{dy}{dt}$, where the ordinary derivatives are evaluated at $t$ and the partial derivatives are evaluated at $(x,y)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The chain rule for one independent variable helps us find the derivative of a composite function. If $x = g(t)$ and $y = h(t)$ are differentiable functions of $t$, and $z = f(x,y)$ is a differentiable function of $x$ and $y$, the rule tells us that $z = f(x(t), y(t))$ is a differentiable function of $t$. The total derivative of $z$ with respect to $t$ is given by $\\\\\\\\frac{dz}{dt} = \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial x} \\\\\\\\cdot \\\\\\\\frac{dx}{dt} + \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial y} \\\\\\\\cdot \\\\\\\\frac{dy}{dt}$. For example, if $x = t^2$, $y = 3t$, and $z = x + y$, then $z = t^2 + 3t$. Differentiating gives $\\\\\\\\frac{dz}{dt} = 2t + 3$, demonstrating the use of the chain rule.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-5-the-chain-rule',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: If $x = g(u,v)$ and $y = h(u,v)$ are differentiable functions of $u$ and $v$, and $z = f(x,y)$ is a differentiable function of $x$ and $y$, then $z = f(g(u,v), h(u,v))$ is a differentiable function of $u$ and $v$, and the partial derivatives are given by $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial u} = \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial x} \\\\\\\\frac{\\\\\\\\partial x}{\\\\\\\\partial u} + \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial y} \\\\\\\\frac{\\\\\\\\partial y}{\\\\\\\\partial u}$ and $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial v} = \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial x} \\\\\\\\frac{\\\\\\\\partial x}{\\\\\\\\partial v} + \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial y} \\\\\\\\frac{\\\\\\\\partial y}{\\\\\\\\partial v}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true. The chain rule for functions of two independent variables states that if $x = g(u,v)$ and $y = h(u,v)$ are differentiable with respect to $u$ and $v$, and $z = f(x, y)$ is differentiable with respect to $x$ and $y$, then $z = f(g(u,v), h(u,v))$ is differentiable with respect to $u$ and $v$. The partial derivative of $z$ with respect to $u$ is found by taking the partial derivatives of $z$ with respect to $x$ and $y$, and multiplying these by the respective partial derivatives of $x$ and $y$ with respect to $u$, and then summing the results. Similarly, the partial derivative of $z$ with respect to $v$ involves the same process but with respect to $v$. This ensures a proper application of the chain rule in multivariable calculus.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-5-the-chain-rule',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The Generalized Chain Rule states that if $w = f(x_1, x_2, \\\\ldots, x_m)$ is a differentiable function of $m$ independent variables, and each $x_i = x_i(t_1, t_2, \\\\ldots, t_n)$ is a differentiable function of $n$ independent variables, then $\\\\frac{\\\\partial w}{\\\\partial t_j} = \\\\sum_{i=1}^{m} \\\\frac{\\\\partial w}{\\\\partial x_i} \\\\frac{\\\\partial x_i}{\\\\partial t_j}$ for any $j \\\\in \\\\{1, 2, \\\\ldots, n\\\\}$. ',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The Generalized Chain Rule (also known as the Multivariable Chain Rule) is used to express the derivative of a composite function in terms of its partial derivatives. In this case, $w = f(x_1, x_2, \\\\ldots, x_m)$ depends on the variables $x_1, x_2, \\\\ldots, x_m$, which in turn depend on the variables $t_1, t_2, \\\\ldots, t_n$. The rule states that the partial derivative of $w$ with respect to $t_j$ is the sum of the product of the partial derivative of $w$ with respect to each $x_i$ and the partial derivative of that $x_i$ with respect to $t_j$. This formula allows us to calculate the rate of change of $w$ with respect to $t_j$ by accounting for all pathways through the intermediate variables $x_i$. For example, if $w = x_1^2 + x_2$ where $x_1 = t_1 + t_2$ and $x_2 = t_1 t_2$, then $\\\\frac{\\\\partial w}{\\\\partial t_1}$ can be found by applying the chain rule as described.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-5-the-chain-rule',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: If a function $f(x,y) = 0$ implicitly defines $y$ as a differentiable function of $x$, then the derivative of $y$ with respect to $x$ is given by $\\\\\\\\frac{dy}{dx} = -\\\\\\\\frac{\\\\\\\\partial f /\\\\\\\\partial x}{\\\\\\\\partial f /\\\\\\\\partial y}$, provided $f_y(x,y) \\\\\\\\neq 0$. Similarly, if a function $f(x,y,z) = 0$ implicitly defines $z$ as a differentiable function of $x$ and $y$, then the partial derivative $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial x}$ is given by $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial x} = -\\\\\\\\frac{\\\\\\\\partial f /\\\\\\\\partial x}{\\\\\\\\partial f /\\\\\\\\partial z}$ and the partial derivative $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial y}$ is given by $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial y} = -\\\\\\\\frac{\\\\\\\\partial f /\\\\\\\\partial y}{\\\\\\\\partial f /\\\\\\\\partial z}$, provided $f_z(x,y,z) \\\\\\\\neq 0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'Implicit differentiation is used to find derivatives of variables that are defined implicitly rather than explicitly. Given a function $f(x,y) = 0$ that defines $y$ as an implicit function of $x$, differentiating both sides with respect to $x$ and solving for $\\\\\\\\frac{dy}{dx}$ yields $\\\\\\\\frac{dy}{dx} = -\\\\\\\\frac{\\\\\\\\partial f /\\\\\\\\partial x}{\\\\\\\\partial f /\\\\\\\\partial y}$, provided $f_y(x,y) \\\\\\\\neq 0$. Similarly, for a function $f(x,y,z) = 0$ that implicitly defines $z$ as a function of $x$ and $y$, differentiating and solving for the partial derivatives $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial x}$ and $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial y}$ results in $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial x} = -\\\\\\\\frac{\\\\\\\\partial f /\\\\\\\\partial x}{\\\\\\\\partial f /\\\\\\\\partial z}$ and $\\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial y} = -\\\\\\\\frac{\\\\\\\\partial f /\\\\\\\\partial y}{\\\\\\\\partial f /\\\\\\\\partial z}$, provided $f_z(x,y,z) \\\\\\\\neq 0$. These relationships follow directly from applying the chain rule for partial derivatives.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-5-the-chain-rule',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The directional derivative $D_u f(a, b)$ of a function $z = f(x, y)$ in the direction of $\\\\mathbf{u} = \\\\cos \\\\theta \\\\mathbf{i} + \\\\sin \\\\theta \\\\mathbf{j}$ can be found by evaluating the limit $ \\\\lim_{h \\\\to 0} \\\\frac{f(a + h \\\\cos \\\\theta, b + h \\\\sin \\\\theta) - f(a, b)}{h}$, provided the limit exists.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The directional derivative $D_u f(a, b)$ of a function $z = f(x, y)$ in the direction of a unit vector $\\\\mathbf{u} = \\\\cos \\\\theta \\\\mathbf{i} + \\\\sin \\\\theta \\\\mathbf{j}$ is given by the limit expression $D_u f(a, b) = \\\\lim_{h \\\\to 0} \\\\frac{f(a + h \\\\cos \\\\theta, b + h \\\\sin \\\\theta) - f(a, b)}{h}$, provided this limit exists. This expression calculates how the function $f$ changes as we move from the point $(a, b)$ in the direction defined by the vector $\\\\mathbf{u}$. For example, if $f(x,y) = x^2 + y^2$ and $(a, b) = (1, 1)$, and $\\\\mathbf{u}$ is in the direction $\\\\theta = \\\\frac{\\\\pi}{4}$, then $\\\\mathbf{u} = \\\\frac{\\\\sqrt{2}}{2} \\\\mathbf{i} + \\\\frac{\\\\sqrt{2}}{2} \\\\mathbf{j}$, and the directional derivative at $(1, 1)$ would involve testing how $f$ changes along this specific path, computing the limit if it exists.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-6-directional-derivatives-and-the-gradient',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The directional derivative $D_u f(x, y)$ of a function $f(x, y)$ in the direction $u = \\\\cos(\\\\theta) \\\\mathbf{i} + \\\\sin(\\\\theta) \\\\mathbf{j}$ is given by $D_u f(x, y) = f_x(x, y) \\\\cos(\\\\theta) + f_y(x, y) \\\\sin(\\\\theta)$, where $f_x$ and $f_y$ are the partial derivatives of $f$ with respect to $x$ and $y$, respectively.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given statement is true. The directional derivative of a function $f(x, y)$ in the direction of a unit vector $u$ with components $\\\\cos(\\\\theta)$ and $\\\\sin(\\\\theta)$ is calculated using the partial derivatives $f_x$ and $f_y$. Specifically, $D_u f(x, y)$ combines these partial derivatives weighted by the direction components to give $D_u f(x, y) = f_x(x, y) \\\\cos(\\\\theta) + f_y(x, y) \\\\sin(\\\\theta)$. For example, if $f(x, y) = x^2 + y^2$, then $f_x = 2x$ and $f_y = 2y$. In the direction $\\\\theta = \\\\pi/4$, $u = \\\\frac{\\\\sqrt{2}}{2} \\\\mathbf{i} + \\\\frac{\\\\sqrt{2}}{2} \\\\mathbf{j}$, and $D_u f(x, y)$ would be $2x \\\\cdot \\\\frac{\\\\sqrt{2}}{2} + 2y \\\\cdot \\\\frac{\\\\sqrt{2}}{2} = \\\\sqrt{2}(x + y)$. This embodies the principle of the directional derivative, combining both the slope in the $x$ and $y$ directions weighted by the direction components.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-6-directional-derivatives-and-the-gradient',\n",
       "  'number': '2'},\n",
       " {'question': \"True or False: The gradient of a function $f(x,y)$, denoted by $\\\\\\\\nabla f(x,y)$ or 'grad f', is a vector that consists of the partial derivatives $\\\\\\\\frac{\\\\\\\\partial f}{\\\\\\\\partial x}$ and $\\\\\\\\frac{\\\\\\\\partial f}{\\\\\\\\partial y}$ multiplied by the unit vectors $\\\\\\\\mathbf{i}$ and $\\\\\\\\mathbf{j}$ respectively.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The gradient of the function $f(x,y)$ is indeed a vector that encompasses the partial derivatives of $f$ with respect to $x$ and $y$. Mathematically, this is expressed as $\\\\\\\\nabla f(x,y) = \\\\\\\\frac{\\\\\\\\partial f}{\\\\\\\\partial x}(x,y) \\\\\\\\mathbf{i} + \\\\\\\\frac{\\\\\\\\partial f}{\\\\\\\\partial y}(x,y) \\\\\\\\mathbf{j}$. This means the gradient vector points in the direction of the steepest ascent of the function $f(x,y)$. For example, if $f(x,y) = x^2 + y^2$, then $\\\\\\\\nabla f(x,y) = 2x \\\\\\\\mathbf{i} + 2y \\\\\\\\mathbf{j}$, which illustrates how the gradient provides both the direction and rate of the steepest increase in $f$ from a given point $(x,y)$. Thus, the statement is true.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-6-directional-derivatives-and-the-gradient',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: For a differentiable function $z = f(x, y)$ at a point $(x_0, y_0)$, if $\\\\\\\\nabla f(x_0, y_0) = 0$, then the directional derivative $D_u f(x_0, y_0)$ is zero for any unit vector $u$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The gradient $\\\\\\\\nabla f(x_0, y_0)$ represents the direction and rate of the steepest ascent of the function at the point $(x_0, y_0)$. If $\\\\\\\\nabla f(x_0, y_0) = 0$, it indicates that the function has no change in any direction at that point (it could be a local minimum, maximum, or saddle point). Mathematically, the directional derivative in any direction $u$ is given by $D_u f(x_0, y_0) = \\\\\\\\nabla f(x_0, y_0) \\\\\\\\cdot u$. Since the gradient is zero, the dot product with any unit vector $u$ will also be zero, resulting in $D_u f(x_0, y_0) = 0$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-6-directional-derivatives-and-the-gradient',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: If the function $z = f(x, y)$ has continuous first-order partial derivatives in an open disk centered at a point $(x_0, y_0)$, and $\\\\\\\\nabla f(x_0, y_0) \\\\\\\\neq 0$, then $\\\\\\\\nabla f(x_0, y_0)$ is tangent to the level curve of $f$ at $(x_0, y_0)$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The statement is false because the gradient $\\\\\\\\nabla f(x_0, y_0)$ is actually normal (perpendicular) to the level curve of the function $f$ at the point $(x_0, y_0)$, not tangent to it. The gradient vector points in the direction of the steepest ascent of the function, which is perpendicular to the contour line representing the level curve at that point. For example, if $f(x, y) = x^2 + y^2$, then the level curves are circles, and at any point $(x_0, y_0)$, the gradient $\\\\\\\\nabla f(x_0, y_0) = (2x_0, 2y_0)$ is perpendicular to the circle passing through $(x_0, y_0)$. In general, for any function with continuous first-order partial derivatives, the gradient at a point is always orthogonal to the level curve at that point.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-6-directional-derivatives-and-the-gradient',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: If $w = f(x, y, z)$ is a function of three variables, and the partial derivatives $f_x$, $f_y$, and $f_z$ exist, then the gradient of $f$, denoted as $\\\\\\\\nabla f(x, y, z)$, can be written as $\\\\\\\\nabla f(x, y, z) = f_x(x, y, z) \\\\mathbf{i} + f_y(x, y, z) \\\\mathbf{j} + f_z(x, y, z) \\\\mathbf{k}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The gradient of a function $f(x, y, z)$ is a vector that consists of its partial derivatives with respect to each of the variables $x$, $y$, and $z$. Specifically, $\\\\\\\\nabla f(x, y, z)$ is defined as $f_x(x, y, z) \\\\mathbf{i} + f_y(x, y, z) \\\\mathbf{j} + f_z(x, y, z) \\\\mathbf{k}$, where $f_x$, $f_y$, and $f_z$ denote the partial derivatives of $f$ with respect to $x$, $y$, and $z$ respectively. For example, if $f(x, y, z) = x^2 + y^2 + z^2$, then $f_x = 2x$, $f_y = 2y$, and $f_z = 2z$, so $\\\\\\\\nabla f(x, y, z) = 2x \\\\mathbf{i} + 2y \\\\mathbf{j} + 2z \\\\mathbf{k}$.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-6-directional-derivatives-and-the-gradient',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: The directional derivative of a function $ f(x, y, z) $ in the direction of a unit vector $ \\\\mathbf{u} = \\\\cos\\\\alpha \\\\mathbf{i} + \\\\cos\\\\beta \\\\mathbf{j} + \\\\cos\\\\gamma \\\\mathbf{k} $ at the point $ (x_0, y_0, z_0) \\\\in D $ can be expressed as $ \\\\lim_{t \\\\to 0} \\\\frac{f(x_0 + t\\\\cos\\\\alpha, y_0 + t\\\\cos\\\\beta, z_0 + t\\\\cos\\\\gamma) - f(x_0, y_0, z_0)}{t} $, provided the limit exists.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The directional derivative measures the rate at which a function changes at a point in a specified direction. Given a function $ f(x, y, z) $ with a domain $ D $ and a point $ (x_0, y_0, z_0) $ in $ D $, the directional derivative in the direction of a unit vector $ \\\\mathbf{u} = \\\\cos\\\\alpha \\\\mathbf{i} + \\\\cos\\\\beta \\\\mathbf{j} + \\\\cos\\\\gamma \\\\mathbf{k} $ is defined by $ \\\\lim_{t \\\\to 0} \\\\frac{f(x_0 + t\\\\cos\\\\alpha, y_0 + t\\\\cos\\\\beta, z_0 + t\\\\cos\\\\gamma) - f(x_0, y_0, z_0)}{t} $ if this limit exists. For example, if $ f(x, y, z) = x^2 + y^2 + z^2 $, the directional derivative in the direction of $ \\\\mathbf{u} = \\\\frac{1}{\\\\sqrt{3}}\\\\mathbf{i} + \\\\frac{1}{\\\\sqrt{3}}\\\\mathbf{j} + \\\\frac{1}{\\\\sqrt{3}}\\\\mathbf{k} $ at $ (1, 1, 1) $ can be calculated using this limit expression.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-6-directional-derivatives-and-the-gradient',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: The directional derivative of a function $f(x,y,z)$ in the direction of a unit vector $\\\\mathbf{u} = \\\\cos(\\\\alpha)\\\\mathbf{i} + \\\\cos(\\\\beta)\\\\mathbf{j} + \\\\cos(\\\\gamma)\\\\mathbf{k}$ is given by $D_{\\\\mathbf{u}} f(x,y,z) = \\\\nabla f(x,y,z) \\\\cdot \\\\mathbf{u} = f_x(x,y,z)\\\\cos(\\\\alpha) + f_y(x,y,z)\\\\cos(\\\\beta) + f_z(x,y,z)\\\\cos(\\\\gamma)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given statement accurately describes the directional derivative. The directional derivative of a function $f(x,y,z)$ in the direction of a unit vector $\\\\mathbf{u}$ measures the rate of change of $f$ in that direction. Mathematically, it is expressed as the dot product of the gradient $\\\\nabla f(x,y,z)$ and the unit vector $\\\\mathbf{u}$, which simplifies to $f_x(x,y,z)\\\\cos(\\\\alpha) + f_y(x,y,z)\\\\cos(\\\\beta) + f_z(x,y,z)\\\\cos(\\\\gamma)$. For example, if $\\\\mathbf{u}$ points in the direction of the x-axis ($\\\\alpha=0, \\\\beta=\\\\pi/2, \\\\gamma=\\\\pi/2$), the directional derivative simplifies to $f_x(x,y,z)$. This means the directional derivative captures directional rates of change integrating contributions of partial derivatives modulated by the direction cosines.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-6-directional-derivatives-and-the-gradient',\n",
       "  'number': '8'},\n",
       " {'question': 'True or False: If $z = f(x, y)$ is a function of two variables defined on an open set containing the point $(x_0, y_0)$, then $(x_0, y_0)$ is a critical point of $f$ only if both partial derivatives $f_x(x_0, y_0)$ and $f_y(x_0, y_0)$ equal zero, and neither of them can be undefined at that point.',\n",
       "  'answer': 'False',\n",
       "  'explanation': \"A point $(x_0, y_0)$ is a critical point of a function $f(x, y)$ if either both partial derivatives $f_x(x_0, y_0) = 0$ and $f_y(x_0, y_0) = 0$, or if at least one of the partial derivatives does not exist at $(x_0, y_0)$. Thus, the condition about the partial derivatives being undefined is not part of the 'only if' condition as stated in the question.\",\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-7-maxima-minima-problems',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The function $z = f(x, y)$ has a local maximum at $(x_0, y_0)$ if $f(x_0, y_0) \\\\geq f(x, y)$ for all $(x, y)$ within some disk centered at $(x_0, y_0)$. If this condition holds for every point $(x, y)$ in the domain of $f$, then $f$ has a global maximum at $(x_0, y_0)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'According to the given definition, a function $z = f(x, y)$ has a local maximum at $(x_0, y_0)$ if $f(x_0, y_0) \\\\geq f(x, y)$ for all points $(x, y)$ within some disk centered at $(x_0, y_0)$. This means that within a small neighborhood around $(x_0, y_0)$, the function attains its highest value at $(x_0, y_0)$. If this inequality holds for every point $(x, y)$ in the domain of $f$ (not just within a local neighborhood), then $f$ has a global maximum at $(x_0, y_0)$. Thus, the statement in the question is true.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-7-maxima-minima-problems',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: According to Fermat’s Theorem for Functions of Two Variables, if a function $z=f(x,y)$ has a local extremum at $(x_0,y_0)$, then both partial derivatives $f_x$ and $f_y$ must be zero at $(x_0,y_0)$. ',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"Fermat's Theorem for Functions of Two Variables states that if a function $z=f(x,y)$ is defined and continuous on an open set containing the point $(x_0,y_0)$, and $f_x$ and $f_y$ exist at $(x_0,y_0)$, then if $f$ has a local extremum at $(x_0,y_0)$, $(x_0,y_0)$ is a critical point of $f$. This implies that both partial derivatives $f_x$ and $f_y$ must be zero at $(x_0,y_0)$ because critical points are where the gradient of the function is zero.\",\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-7-maxima-minima-problems',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: For a function $z = f(x,y)$, the point $(x_0, y_0, f(x_0, y_0))$ is a saddle point if $f_x(x_0, y_0) = 0$ and $f_y(x_0, y_0) = 0$, but $f$ does not have a local extremum at $(x_0, y_0)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A saddle point for the function $z = f(x,y)$ at a point $(x_0, y_0, f(x_0, y_0))$ is defined by the conditions that the first partial derivatives $f_x(x_0, y_0)$ and $f_y(x_0, y_0)$ are both zero, and that the point $(x_0, y_0)$ is not a local extremum. This means that at $(x_0, y_0)$, the function $f(x,y)$ does not achieve a local maximum or minimum, but rather, it exhibits a change in curvature such that the point acts as a transition between regions of different behaviors. For example, $z = x^2 - y^2$ has a saddle point at $(0,0,0)$ because $f_x(0,0) = 2*0 = 0$, $f_y(0,0) = -2*0 = 0$, and $(0,0)$ is neither a local maximum nor a minimum. The function increases along the $x$-axis and decreases along the $y$-axis through this point.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-7-maxima-minima-problems',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: Given a function $z=f(x,y)$ with continuous first- and second-order partial derivatives on some disk containing the point $(x_0, y_0)$, if $f_x(x_0, y_0)=0$, $f_y(x_0, y_0)=0$, and $D=f_{xx}(x_0, y_0)f_{yy}(x_0, y_0)-(f_{xy}(x_0, y_0))^2 > 0$, then the function $f$ must have a local maximum at $(x_0, y_0)$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'For a function $z=f(x,y)$, the second derivative test states that if $D > 0$, then whether $f$ has a local maximum, local minimum, or neither depends on the sign of $f_{xx}(x_0, y_0)$. Specifically, if $D > 0$ and $f_{xx}(x_0, y_0) > 0$, then $f$ has a local minimum at $(x_0, y_0)$. Conversely, if $D > 0$ and $f_{xx}(x_0, y_0) < 0$, then $f$ has a local maximum at $(x_0, y_0)$. Thus, $D > 0$ alone does not guarantee a local maximum; it also depends on the sign of $f_{xx}(x_0, y_0)$. For example, if $f_{xx}(0,0) > 0$, the function would have a local minimum rather than a maximum.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-7-maxima-minima-problems',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: According to the Extreme Value Theorem, a continuous function $f(x)$ defined on a closed interval $[a, b]$ attains its absolute maximum and minimum values at some points within the interval.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The Extreme Value Theorem states that if a function $f(x)$ is continuous on a closed interval $[a, b]$, then $f(x)$ attains its absolute maximum and minimum values at some points within that interval. This concept can be expanded to functions of two variables, such as $f(x, y)$, on a closed and bounded set $D$. For example, if $f(x)$ is continuous on $[1, 3]$, it will have both a maximum and a minimum value somewhere in this interval.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-7-maxima-minima-problems',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: If a differentiable function $z=f(x,y)$ is defined on a closed, bounded set $D$, it is possible for the absolute maximum and absolute minimum values to occur at points that are neither critical points of $f$ within $D$ nor on the boundary of $D$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'Consider a differentiable function $z=f(x,y)$ defined on a closed, bounded set $D$. According to the Extreme Value Theorem, $f$ will attain both an absolute maximum value and an absolute minimum value on $D$. These values must occur either at the critical points of $f$ within $D$ or on the boundary of $D$. No other points outside these two categories can be the locations of the absolute extremum points. For example, if we take $f(x, y) = x^2 + y^2$ on the unit disk $D: x^2 + y^2 \\\\leq 1$, the minimum value occurs at the origin (a critical point), and the maximum value occurs on the boundary of the disk (the circle $x^2 + y^2 = 1$).',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-7-maxima-minima-problems',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: If $f$ is a function of two variables and has a local extremum at the point $(x_0, y_0)$, which lies on the curve defined by $g(x, y) = 0$, with $ \\\\nabla g(x_0, y_0) \\\\ne 0 $, then there exists a number $ \\\\lambda $ such that $ \\\\nabla f(x_0, y_0) = \\\\lambda \\\\nabla g(x_0, y_0) $.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true due to the method of Lagrange multipliers. If a function $f(x, y)$ has a local extremum on a curve given by $g(x, y) = 0$ at the point $(x_0, y_0)$ and the gradient of $g$, $ \\\\nabla g(x_0, y_0) $, is not zero, then there must exist a scalar $\\\\lambda$ (Lagrange multiplier) such that $ \\\\nabla f(x_0, y_0) = \\\\lambda \\\\nabla g(x_0, y_0) $. This method is used to find the local maxima and minima of a function subject to equality constraints. For example, to find the extrema of $f(x, y) = x^2 + y^2$ subject to $g(x, y) = x + y - 1 = 0$, one would solve the system $ \\\\nabla f = \\\\lambda \\\\nabla g $, leading to the solution for $\\\\lambda$ and the points $(x, y)$. This demonstrates the principle in action.',\n",
       "  'chapter': 'Differentiation of Functions of Several Variables',\n",
       "  'section': '4-8-lagrange-multipliers',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The double integral of a function $f(x,y)$ over a rectangular region $R$ in the $xy$-plane, $\\\\iint_R f(x,y) \\\\, dA$ can be expressed as the limit of a sum of the function values at specified points times the area of the sub-rectangles, specifically, $\\\\iint_R f(x,y) \\\\, dA = \\\\lim_{m,n \\\\to \\\\infty} \\\\sum_{i=1}^m \\\\sum_{j=1}^n f(x_i^*, y_j^*) \\\\Delta A$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The double integral $\\\\iint_R f(x,y) \\\\, dA$ is indeed defined as the limit of a double sum as the number of sub-rectangles approaches infinity. This method sums the values of $f$ at chosen sample points $(x_i^*, y_j^*)$ within each sub-rectangle and multiplies by the area $\\\\Delta A$ of the sub-rectangle, thereby approximating the total 'volume' under the surface $z = f(x,y)$ over the region $R$. For example, if $R$ is divided into $m \\\\times n$ sub-rectangles, $\\\\Delta A$ would be the area of each sub-rectangle, and $x_i^*$, $y_j^*$ would be specific points in each sub-rectangle where the function is evaluated.\",\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-1-double-integrals-over-rectangular-regions',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: If $f(x,y)$ is greater than or equal to $g(x,y)$ for all $(x,y)$ in the region $R$, then the double integral of $f(x,y)$ over $R$ is greater than or equal to the double integral of $g(x,y)$ over $R$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true as it represents the comparison property of double integrals. According to this property, if $f(x,y) \\\\geq g(x,y)$ for all $(x,y) \\\\in R$, then integrating both sides over the region $R$ will preserve the inequality: $\\\\iint_R f(x,y) \\\\, dA \\\\geq \\\\iint_R g(x,y) \\\\, dA$. This makes sense since the greater function accumulates more or equal value over the same region. For example, if $f(x,y)$ is always 5 and $g(x,y)$ is always 3 over $R$, the double integral of $f(x,y)$ will be greater than that of $g(x,y)$ because 5 is greater than 3.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-1-double-integrals-over-rectangular-regions',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The iterated integral $\\\\\\\\int_a^b \\\\\\\\int_c^d f(x,y) \\\\\\\\; dy \\\\\\\\; dx$ over the rectangular region $R = [a,b] \\\\\\\\times [c,d]$ can be rewritten as $\\\\\\\\int_c^d \\\\\\\\int_a^b f(x,y) \\\\\\\\; dx \\\\\\\\; dy$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"An iterated integral allows us to compute the integral of a function $f(x,y)$ over a rectangular region $R=[a,b] \\\\\\\\times [c,d]$ by integrating in one variable at a time. The order of integration does not matter for iterated integrals of continuous functions over rectangular regions, meaning that $\\\\\\\\int_a^b \\\\\\\\int_c^d f(x,y) \\\\\\\\; dy \\\\\\\\; dx$ is equal to $\\\\\\\\int_c^d \\\\\\\\int_a^b f(x,y) \\\\\\\\; dx \\\\\\\\; dy$. This concept is important in multivariable calculus and is known as Fubini's Theorem. For example, if $f(x,y) = x + y$, computing either $\\\\\\\\int_0^1 \\\\\\\\int_0^1 (x + y) \\\\\\\\; dy \\\\\\\\; dx$ or $\\\\\\\\int_0^1 \\\\\\\\int_0^1 (x + y) \\\\\\\\; dx \\\\\\\\; dy$ will yield the same result.\",\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-1-double-integrals-over-rectangular-regions',\n",
       "  'number': '3'},\n",
       " {'question': \"True or False: According to Fubini's Theorem, if \\\\( f(x,y) \\\\) is a function continuous over a rectangular region \\\\( R = \\\\{ (x,y) \\\\in \\\\mathbb{R}^2 \\\\mid a \\\\leq x \\\\leq b, c \\\\leq y \\\\leq d \\\\} \\\\), then the double integral of \\\\( f \\\\) over \\\\( R \\\\) can always be expressed as the iterated integrals \\\\( \\\\int_{a}^{b} \\\\int_{c}^{d} f(x,y) \\\\, dy \\\\, dx \\\\) and \\\\( \\\\int_{c}^{d} \\\\int_{a}^{b} f(x,y) \\\\, dx \\\\, dy \\\\).\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"According to Fubini's Theorem, if \\\\( f(x,y) \\\\) is continuous over a rectangular region \\\\( R \\\\), then the double integral of \\\\( f \\\\) over \\\\( R \\\\) can indeed be expressed as iterated integrals in different orders. That is, \\\\(\\\\iint_{R} f(x,y) \\\\, dA = \\\\int_{a}^{b} \\\\int_{c}^{d} f(x,y) \\\\, dy \\\\, dx = \\\\int_{c}^{d} \\\\int_{a}^{b} f(x,y) \\\\, dx \\\\, dy \\\\). The theorem also holds more generally if \\\\( f \\\\) is bounded and discontinuous on a finite number of continuous curves. For example, if \\\\( f(x,y) = x+y \\\\) over \\\\( R = [0,1] \\\\times [0,1] \\\\), we can compute the integral by either iterated integral order.\",\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-1-double-integrals-over-rectangular-regions',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The area of a region $R$ can be calculated using the double integral $A(R) = \\\\iint_R 1 \\\\, dA$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The statement is true. The area $A(R)$ of a region $R$ in the plane can indeed be calculated using the double integral $A(R) = \\\\iint_R 1 \\\\, dA$. This is because the double integral $\\\\iint_R 1 \\\\, dA$ sums the value '1' over every infinitesimal area element $dA$ within the region $R$, effectively counting up the total number of those area elements, which gives the total area of the region. For example, for a rectangular region with sides of length $a$ and $b$, this would result in the integral $\\\\iint_R 1 \\\\, dA = ab$, which corresponds to the area of the rectangle.\",\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-1-double-integrals-over-rectangular-regions',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: The average value of a function $f(x,y)$ over a region $R$ is given by $f_{ave} = \\\\frac{1}{\\\\text{Area}(R)} \\\\int_{R} f(x,y) \\\\, dA$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The formula $f_{ave} = \\\\frac{1}{\\\\text{Area}(R)} \\\\int_{R} f(x,y) \\\\, dA$ expresses the average value of a function $f(x,y)$ over the region $R$. To find this average value, you integrate the function over the region and divide by the area of that region. For example, if $R$ is the rectangle $[0,1] \\\\times [0,1]$ and $f(x,y) = x+y$, then $\\\\text{Area}(R) = 1$. The integral $\\\\int_{0}^{1} \\\\int_{0}^{1} (x+y) \\\\, dy \\\\, dx$ results in $\\\\frac{1}{2}$ and dividing by the area gives $f_{ave} = \\\\frac{1}{2}$. This showcases the concept correctly.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-1-double-integrals-over-rectangular-regions',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: A region $D$ in the $(x, y)$-plane bounded by $x = 1$, $x = 3$, $y = x^2$, and $y = 4$ is of Type II.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'A region $D$ in the $(x, y)$-plane is of Type I if it lies between two vertical lines (here $x = 1$ and $x = 3$) and the graphs of two continuous functions $g_1(x)$ and $g_2(x)$ (here $y = x^2$ and $y = 4$). Since the region given fits this description, it is a Type I region, not Type II, which would require the region to be bounded by two horizontal lines and the graphs of two continuous functions $h_1(y)$ and $h_2(y)$. Hence, the statement is false.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: If $g(x,y)$ is the extension of the integrable function $f(x,y)$ defined on region $D$ inside the rectangle $R$, then the double integral of $f(x,y)$ over $D$ is equal to the double integral of $g(x,y)$ over $R$, i.e., $\\\\iint_D f(x,y) \\\\, dA = \\\\iint_R g(x,y) \\\\, dA$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The statement is true based on the definition provided. In the context of double integrals over nonrectangular regions, $g(x,y)$ is an extension of the integrable function $f(x,y)$, so $g(x,y)$ is also integrable. The double integral of $f(x,y)$ over region $D$ is defined to be equal to the double integral of $g(x,y)$ over the rectangle $R$. This allows us to evaluate integrals over complex, nonrectangular regions by extending the function to a simpler rectangular region and integrating over it.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '2'},\n",
       " {'question': \"True or False: According to Fubini's Theorem, if a function $f(x,y)$ is continuous on a region $D$ of Type I, then the iterated integral $ \\\\int_a^b \\\\left[ \\\\int_{g_1(x)}^{g_2(x)} f(x,y) \\\\, dy \\\\right] \\\\, dx $ is equal to $ \\\\int_c^d \\\\left[ \\\\int_{h_1(y)}^{h_2(y)} f(x,y) \\\\, dx \\\\right] \\\\, dy $.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"Fubini's Theorem states that for a function $f(x,y)$ continuous on a region $D$ of Type I, the double integral can be computed as $ \\\\iint_D f(x,y) \\\\, dA = \\\\int_a^b \\\\left[ \\\\int_{g_1(x)}^{g_2(x)} f(x,y) \\\\, dy \\\\right] \\\\, dx $. For a region $D$ of Type II, the double integral can be computed as $ \\\\iint_D f(x,y) \\\\, dA = \\\\int_c^d \\\\left[ \\\\int_{h_1(y)}^{h_2(y)} f(x,y) \\\\, dx \\\\right] \\\\, dy $. The given iterated integrals in the question are only valid for their respective types (Type I or Type II), and are not interchangeable.\",\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: If a region $D$ can be expressed as the union of two smaller regions $D_1$ and $D_2$, where $D_1$ and $D_2$ only overlap at their boundaries, then the double integral of a function $f(x,y)$ over $D$ is equal to the sum of the double integrals of $f(x,y)$ over $D_1$ and $D_2$, mathematically stated as: $$\\\\iint_D f(x,y) \\\\, dA = \\\\iint_{D_1} f(x,y) \\\\, dA + \\\\iint_{D_2} f(x,y) \\\\, dA.$$',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This is a fundamental property of double integrals over regions. When a region $D$ can be decomposed into two non-overlapping regions $D_1$ and $D_2$ that only intersect at their boundaries, the integral over $D$ can be split into the sum of the integrals over $D_1$ and $D_2$. For example, if $D$ is a rectangle that is partitioned into two smaller rectangles $D_1$ and $D_2$ along a vertical or horizontal line, the total area under the curve represented by $f(x,y)$ across $D$ is indeed the sum of the areas under the curve across $D_1$ and $D_2$.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The area of a plane-bounded region $D$ can be found using the double integral $\\\\\\\\iint_D 1 \\\\, dA$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The double integral $\\\\\\\\iint_D 1 \\\\, dA$ is used to compute the area of a plane-bounded region $D$. This is because integrating 1 over the region $D$ sums up infinitesimally small area elements $dA$ that cover the entire region, thus yielding the area of $D$. For example, if $D$ is a rectangle with length $a$ and width $b$, then $\\\\\\\\iint_D 1 \\\\, dA = ab$, which matches the formula for the area of a rectangle.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: If $f(x,y)$ is integrable over a plane-bounded region $D$ with positive area $A(D)$, then the average value of the function is given by $f_{ave} = \\\\frac{1}{A(D)} \\\\iint_D f(x,y) \\\\, dA$. Note that the area is $A(D) = \\\\iint_D 1 \\\\, dA$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The average value of a function $f(x,y)$ over a region $D$ with area $A(D)$ is calculated as $\\\\frac{1}{A(D)} \\\\iint_D f(x,y) \\\\, dA$. This can be understood by analogy to the one-dimensional case where the average value of a function over an interval is the integral of the function divided by the length of the interval. Here, $A(D) = \\\\iint_D 1 \\\\, dA$ represents the area of the region $D$, effectively acting as the denominator in the average value formula. For instance, if $D$ is the region bounded by $0 \\\\leq x \\\\leq 1$ and $0 \\\\leq y \\\\leq 1$, and $f(x,y) = x + y$, then $A(D) = 1$ and the average value $f_{ave}$ will be $\\\\frac{1}{1} \\\\iint_D (x+y) \\\\, dA = 1$.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '6'},\n",
       " {'question': \"True or False: According to Fubini's Theorem for Improper Integrals, if $D$ is defined as the region $(x,y) : a ≤ x ≤ b, g(x) ≤ y ≤ h(x)$ or equivalently as $(x,y) : c ≤ y ≤ d, j(y) ≤ x ≤ k(y)$, and if $f$ is a nonnegative function on $D$ with finitely many discontinuities within $D$, then the double integral of $f$ over $D$ can be expressed as both $\\\\int_{a}^{b}\\\\int_{g(x)}^{h(x)}f(x,y)\\\\,dy\\\\,dx$ and $\\\\int_{c}^{d}\\\\int_{j(y)}^{k(y)}f(x,y)\\\\,dx\\\\,dy$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': 'Fubini’s Theorem for Improper Integrals states that for a bounded rectangle or simple region $D$ in the plane, given as either $(x,y) : a ≤ x ≤ b, g(x) ≤ y ≤ h(x)$ or $(x,y) : c ≤ y ≤ d, j(y) ≤ x ≤ k(y)$, and for a nonnegative function $f$ on $D$ with finitely many discontinuities in the interior of $D$, the double integral of $f$ over $D$ can be calculated using either of the iterated integrals: $\\\\int_{a}^{b}\\\\int_{g(x)}^{h(x)}f(x,y)\\\\,dy\\\\,dx$ or $\\\\int_{c}^{d}\\\\int_{j(y)}^{k(y)}f(x,y)\\\\,dx\\\\,dy$. This means that the value of the double integral is independent of the order of integration.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: If an unbounded rectangle $R$ is given by $R = \\\\{ (x, y) : a \\\\leq x < \\\\infty, c \\\\leq y < \\\\infty \\\\}$, and the limit exists, then the double integral over $R$ of $f(x, y)$ can be expressed as both $\\\\\\\\iint_R f(x, y) \\\\, dA = \\\\lim_{(b, d) \\\\to (\\\\infty, \\\\infty)} \\\\int_a^b \\\\left( \\\\int_c^d f(x, y) \\\\, dy \\\\right) dx$ and $\\\\\\\\iint_R f(x, y) \\\\, dA = \\\\lim_{(b, d) \\\\to (\\\\infty, \\\\infty)} \\\\int_c^d \\\\left( \\\\int_a^b f(x, y) \\\\, dx \\\\right) dy$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The statement is true because an improper integral over an unbounded region $R = \\\\{(x, y) : a \\\\leq x < \\\\infty, c \\\\leq y < \\\\infty\\\\}$ can be defined as the limit of proper integrals over bounded regions. Here, when the limit exists, it means the integral is computable as one of two iterated integrals, either by integrating first with respect to $y$ and then $x$, or vice versa. The equality:$$ \\\\iint_R f(x, y) \\\\, dA = \\\\lim_{(b,d) \\\\to (\\\\infty, \\\\infty)} \\\\int_a^b \\\\left( \\\\int_c^d f(x, y) \\\\, dy \\\\right) dx = \\\\lim_{(b,d) \\\\to (\\\\infty, \\\\infty)} \\\\int_c^d \\\\left( \\\\int_a^b f(x, y) \\\\, dx \\\\right) dy $$ensures the integration proper in either order gives the same result. For example, if $f(x,y)=e^{-x-y}$, the double integral over $R$ converges by this definition.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '8'},\n",
       " {'question': 'True or False: For a pair of continuous random variables $X$ and $Y$ with a joint density function $f(x,y)$, the probability that $(X,Y)$ lies in a certain region $D$ is given by the double integral $\\\\iint_D f(x,y) \\\\, dA$, and the joint density function $f(x,y)$ must satisfy $f(x,y) \\\\geq 0$ and $\\\\iint_{\\\\mathbb{R}^2} f(x,y) \\\\, dA = 1$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The joint density function $f(x,y)$ for continuous random variables $X$ and $Y$ must be non-negative and integrate to 1 over the entire plane $\\\\mathbb{R}^2$. The probability that $(X,Y)$ lies within a specific region $D$ is found by integrating $f(x,y)$ over that region with a double integral. For example, if $f(x,y) = e^{-(x^2 + y^2)}$, then $f(x,y) \\\\geq 0$ is satisfied, and we must ensure $\\\\iint_{\\\\mathbb{R}^2} e^{-(x^2 + y^2)} \\\\, dA = 1$ for it to be a valid joint density function. Thus, the given statement accurately describes these key properties of the joint density function.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '9'},\n",
       " {'question': 'True or False: If $X$ and $Y$ are independent random variables, then their joint density function $f(x,y)$ can be expressed as the product of their individual density functions $f_X(x)$ and $f_Y(y)$, such that $f(x,y) = f_X(x)f_Y(y)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true. By definition, two random variables $X$ and $Y$ are independent if the joint density function $f(x,y)$ can be factored into the product of their individual density functions $f_X(x)$ and $f_Y(y)$. That is, $f(x,y) = f_X(x)f_Y(y)$. For example, if $X$ and $Y$ are independent normal random variables with respective density functions $f_X(x)$ and $f_Y(y)$, their joint density function would be $f(x,y) = f_X(x) \\\\cdot f_Y(y)$. This means that knowing the outcome of one variable does not provide any information about the other, and their probabilities are mutually exclusive.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '10'},\n",
       " {'question': 'True or False: In probability theory, the expected value $E(X)$ of a random variable $X$ in a continuous sample space $S$ can be computed using the integral $E(X) = \\\\iint_S x \\\\, f(x, y) \\\\, dA$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The expected value $E(X)$ represents the mean or average outcome of the random variable $X$. For continuous random variables over a sample space $S$, this is calculated using the integral $E(X) = \\\\iint_S x \\\\, f(x, y) \\\\, dA$, where $f(x, y)$ is the joint probability density function of the variables $X$ and $Y$. Similarly, $E(Y)$ can be computed as $E(Y) = \\\\iint_S y \\\\, f(x, y) \\\\, dA$. These integrals effectively sum up all possible values of $x$ and $y$ weighted by their probabilities, giving the mean value of the distributions. For example, if $S$ represents a two-dimensional area where $X$ and $Y$ can take values, $f(x, y)$ gives the probability density at each point $(x, y)$, and the integrals give the overall expected values.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-2-double-integrals-over-general-regions',\n",
       "  'number': '11'},\n",
       " {'question': 'True or False: When converting a double integral $\\\\iint_{R} f(r, \\\\theta) \\\\, dA$ over a polar rectangular region $R$ in the $r\\\\theta$-plane to an iterated sum, it is necessary to include the term $r_{ij}^* \\\\Delta r \\\\Delta \\\\theta$ to account for the area element in polar coordinates.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'In polar coordinates, the area element $dA$ is represented as $r \\\\, dr \\\\, d\\\\theta$. Therefore, when approximating the double integral $\\\\iint_{R} f(r, \\\\theta) \\\\, dA$ using a sum, it is necessary to include the additional $\\\\Delta r \\\\Delta \\\\theta$ term multiplied by $r_{ij}^*$, which accounts for the variation in the area of each small rectangular element in polar coordinates. This is because the area element in polar coordinates varies with the radius, as opposed to Cartesian coordinates where the area element is simply $\\\\Delta x \\\\Delta y$.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-3-double-integrals-in-polar-coordinates',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: For a continuous function $f(r, \\\\\\\\theta)$ defined over a general polar region $D$, the double integral of $f(r, \\\\\\\\theta)$ can be expressed as \\\\\\\\( \\\\\\\\iint_{D} f(r, \\\\\\\\theta) \\\\, r \\\\, dr \\\\, d\\\\\\\\theta = \\\\\\\\int_{\\\\\\\\theta = \\\\\\\\alpha}^{\\\\\\\\theta = \\\\\\\\beta} \\\\\\\\int_{r = h_1(\\\\\\\\theta)}^{r = h_2(\\\\\\\\theta)} f(r, \\\\\\\\theta) \\\\, r \\\\, dr \\\\, d\\\\\\\\theta \\\\\\\\).',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true. In polar coordinates, a double integral over a region $D$ is given by $\\\\\\\\iint_{D} f(r, \\\\\\\\theta) \\\\, r \\\\, dr \\\\, d\\\\\\\\theta$. When converting from Cartesian to polar coordinates, an additional factor of $r$ is introduced due to the Jacobian determinant. For a general polar region bounded by $\\\\\\\\theta$ from $\\\\\\\\alpha$ to $\\\\\\\\beta$ and $r$ from $h_1(\\\\\\\\theta)$ to $h_2(\\\\\\\\theta)$, the limits of integration adapt accordingly, resulting in the integral expression: \\\\\\\\( \\\\\\\\int_{\\\\\\\\theta = \\\\\\\\alpha}^{\\\\\\\\theta = \\\\\\\\beta} \\\\\\\\int_{r = h_1(\\\\\\\\theta)}^{r = h_2(\\\\\\\\theta)} f(r, \\\\\\\\theta) \\\\, r \\\\, dr \\\\, d\\\\\\\\theta \\\\\\\\). For example, if you were integrating over a circular region, the limits would be determined by $r$ ranging from $0$ to the radius of the circle and $\\\\\\\\theta$ ranging from $0$ to $2\\\\\\\\pi$.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-3-double-integrals-in-polar-coordinates',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The triple integral of a function $f(x,y,z)$ over a rectangular box $B$ can be approximated by summing the values of $f$ at selected points within subrectangles of $B$, multiplied by the volume of those subrectangles, and taking the limit as the number of subrectangles tends to infinity.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The triple integral of a function $f(x,y,z)$ over a rectangular box $B$ is defined as the limit of a Riemann sum:\\\\\\\\[\\\\lim_{l,m,n \\\\to \\\\infty} \\\\sum_{i=1}^{l} \\\\sum_{j=1}^{m} \\\\sum_{k=1}^{n} f(x_{ijk}^*, y_{ijk}^*, z_{ijk}^*) \\\\Delta x \\\\Delta y \\\\Delta z = \\\\iiint_B f(x,y,z) \\\\, dV\\\\\\\\]if this limit exists. Here, $f(x_{ijk}^*, y_{ijk}^*, z_{ijk}^*)$ are the function values evaluated at chosen sample points within the subrectangles, and $\\\\Delta x \\\\Delta y \\\\Delta z$ is the volume of each subrectangle. This concept can be illustrated by breaking down the integral into smaller and smaller subrectangles and summing up the contributions over these subrectangles, resulting in an approximation that becomes exact in the limit.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-4-triple-integrals',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: According to Fubini's Theorem for Triple Integrals, if $f(x,y,z)$ is continuous on a rectangular box $B = [a,b] \\\\times [c,d] \\\\times [e,f]$, then the integral $\\\\\\\\iiint_B f(x,y,z) \\\\\\\\, dV$ can be expressed only as $\\\\\\\\int_e^f \\\\\\\\int_c^d \\\\\\\\int_a^b f(x,y,z) \\\\\\\\, dx \\\\\\\\, dy \\\\\\\\, dz$.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"Fubini's Theorem for Triple Integrals states that if $f(x,y,z)$ is continuous on a rectangular box $B = [a,b] \\\\\\\\times [c,d] \\\\\\\\times [e,f]$, then the integral $\\\\\\\\iiint_B f(x,y,z) \\\\\\\\, dV$ can be expressed not only as $\\\\\\\\int_e^f \\\\\\\\int_c^d \\\\\\\\int_a^b f(x,y,z) \\\\\\\\, dx \\\\\\\\, dy \\\\\\\\, dz$, but also as any of the six possible orderings of iterated integrals. For example, it can also be written as $\\\\\\\\int_a^b \\\\\\\\int_c^d \\\\\\\\int_e^f f(x,y,z) \\\\\\\\, dz \\\\\\\\, dy \\\\\\\\, dx$. The key concept is that the order of integration can be rearranged, provided the function is continuous over the specified domain.\",\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-4-triple-integrals',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False? The triple integral of a continuous function $ f(x,y,z) $ over a general three-dimensional region $ E = \\\\{(x,y,z) \\\\;|\\\\; (x,y) \\\\in D, \\\\; u_1(x,y) \\\\leq z \\\\leq u_2(x,y)\\\\} $ in $ \\\\mathbb{R}^3 $, where $ D $ is the projection of $ E $ onto the $ xy $-plane, is given by: $$ \\\\iiint_E f(x,y,z) \\\\, dV = \\\\iint_D \\\\left[ \\\\int_{u_1(x,y)}^{u_2(x,y)} f(x,y,z) \\\\, dz \\\\right] dA. $$',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true. The triple integral of a continuous function $ f(x,y,z) $ over the three-dimensional region $ E $ can be computed by first integrating $ f(x,y,z) $ with respect to $ z $ from $ u_1(x,y) $ to $ u_2(x,y) $, and then integrating the resulting expression over the region $ D $ in the $ xy $-plane. This method leverages the concept of iterated integrals, where the volume integral is broken down into a sequence of simpler integrals. For example, consider a region $ E $ where $ D $ is the unit disk in the $ xy $-plane and $ u_1(x,y) = 0 $, $ u_2(x,y) = 1 - x^2 - y^2 $. The volume integral would be: $$ \\\\iiint_E f(x,y,z) \\\\, dV = \\\\iint_D \\\\left[ \\\\int_0^{1-x^2-y^2} f(x,y,z) \\\\, dz \\\\right] dA. $$',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-4-triple-integrals',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The average value of a function $f(x,y,z)$ over a solid bounded region $E$ with positive volume $V(E)$ can be calculated using the formula $f_{ave} = \\\\frac{1}{V(E)} \\\\iiint_E f(x,y,z) \\\\, dV$, where $V(E) = \\\\iiint_E 1 \\\\, dV$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The statement is true. The average value of an integrable function $f(x,y,z)$ over a solid bounded region $E$ is given by the formula $f_{ave} = \\\\frac{1}{V(E)} \\\\iiint_E f(x,y,z) \\\\, dV$. Here, $V(E)$ represents the volume of the region $E$, which can be computed as $V(E) = \\\\iiint_E 1 \\\\, dV$. For example, if $E$ is the unit cube $[0,1]^3$ and $f(x,y,z) = x+y+z$, we can compute $V(E)$ as $\\\\iiint_E 1 \\\\, dV = \\\\iiint_{[0,1]^3} 1 \\\\, dx \\\\, dy \\\\, dz = 1$. The average value $f_{ave}$ would then be $\\\\frac{1}{1} \\\\iiint_{[0,1]^3} (x+y+z) \\\\, dx \\\\, dy \\\\, dz = \\\\frac{3}{2}/1 = \\\\frac{3}{2}$.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-4-triple-integrals',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: In cylindrical coordinates, the triple integral of a continuous function \\\\( f(r, \\\\theta, z) \\\\) over a cylindrical box \\\\( B = \\\\\\\\{(r, \\\\theta, z) | a \\\\leq r \\\\leq b, \\\\alpha \\\\leq \\\\theta \\\\leq \\\\beta, c \\\\leq z \\\\leq d \\\\\\\\} \\\\) can be expressed as the limit of a triple Riemann sum of the form \\\\( \\\\lim_{l,m,n \\\\to \\\\infty} \\\\sum_{i=1}^{l} \\\\sum_{j=1}^{m} \\\\sum_{k=1}^{n} f(r_{ijk}^*, \\\\theta_{ijk}^*, z_{ijk}^*) r_{ijk}^* \\\\Delta r \\\\Delta \\\\theta \\\\Delta z \\\\), as long as this limit exists.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The concept tested here is the definition of the triple integral in cylindrical coordinates. For a continuous function \\\\( f(r, \\\\theta, z) \\\\) over the given cylindrical box \\\\( B \\\\), the triple integral can indeed be defined as the limit of a triple Riemann sum, provided that the corresponding limit exists. In cylindrical coordinates, the volume element includes the factor \\\\( r \\\\) to account for the radial distance. The given Riemann sum \\\\( \\\\sum_{i=1}^{l} \\\\sum_{j=1}^{m} \\\\sum_{k=1}^{n} f(r_{ijk}^*, \\\\theta_{ijk}^*, z_{ijk}^*) r_{ijk}^* \\\\Delta r \\\\Delta \\\\theta \\\\Delta z \\\\) accurately represents this volume element. Thus, if this limit exists as \\\\( l \\\\), \\\\( m \\\\), and \\\\( n \\\\) approach infinity, the integral is properly defined.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-5-triple-integrals-in-cylindrical-and-spherical-coordinates',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: Fubini's Theorem in cylindrical coordinates allows us to evaluate a triple integral over a circular cylinder $B$, where the function $g(x,y,z)$ is converted into cylindrical coordinates $f(r, \\\\\\\\theta, z)$, by integrating $\\\\int_{a}^{b} \\\\int_{\\\\\\\\alpha}^{\\\\\\\\beta} \\\\int_{c}^{d} f(r, \\\\\\\\theta, z) \\\\, r \\\\, dz \\\\, d\\\\\\\\theta \\\\, dr$.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"According to Fubini's Theorem in cylindrical coordinates, the correct order of integration for the volume integral is $\\\\int_{c}^{d} \\\\int_{\\\\\\\\alpha}^{\\\\\\\\beta} \\\\int_{a}^{b} f(r, \\\\\\\\theta, z) \\\\, r \\\\, dr \\\\, d\\\\\\\\theta \\\\, dz$. The order of integration must follow the bounds of $z$ from $c$ to $d$, $\\\\\\\\theta$ from $\\\\\\\\alpha$ to $\\\\\\\\beta$, and $r$ from $a$ to $b$. This represents the proper slicing of the volume in cylindrical coordinates. For example, consider $g(x, y, z) = x^2 + y^2 + z^2$, which in cylindrical coordinates becomes $f(r, \\\\\\\\theta, z) = r^2 \\\\cos^2(\\\\\\\\theta) + r^2 \\\\sin^2(\\\\\\\\theta) + z^2 = r^2 + z^2$. The triple integral would be set up with the correct order of integration to cover all the specified bounds.\",\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-5-triple-integrals-in-cylindrical-and-spherical-coordinates',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The triple integral in spherical coordinates is represented as the limit of a triple Riemann sum, $\\\\\\\\lim_{l,m,n\\\\\\\\to\\\\\\\\infty}\\\\\\\\sum_{i=1}^{l}\\\\\\\\sum_{j=1}^{m}\\\\\\\\sum_{k=1}^{n}f(\\\\\\\\rho_{ijk}^*,\\\\\\\\theta_{ijk}^*,\\\\\\\\phi_{ijk}^*)(\\\\\\\\rho_{ijk}^*)^2 \\\\\\\\sin \\\\\\\\phi_{ijk}^* \\\\\\\\Delta \\\\\\\\rho \\\\\\\\Delta \\\\\\\\theta \\\\\\\\Delta \\\\\\\\phi$, provided the limit exists.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The triple integral in spherical coordinates is a way to calculate the volume under a surface in a three-dimensional spherical coordinate space. It is expressed as a limit of a triple Riemann sum: $\\\\\\\\lim_{l,m,n\\\\\\\\to\\\\\\\\infty}\\\\\\\\sum_{i=1}^{l}\\\\\\\\sum_{j=1}^{m}\\\\\\\\sum_{k=1}^{n}f(\\\\\\\\rho_{ijk}^*,\\\\\\\\theta_{ijk}^*,\\\\\\\\phi_{ijk}^*)(\\\\\\\\rho_{ijk}^*)^2 \\\\\\\\sin \\\\\\\\phi_{ijk}^* \\\\\\\\Delta \\\\\\\\rho \\\\\\\\Delta \\\\\\\\theta \\\\\\\\Delta \\\\\\\\phi$. Here, $\\\\\\\\rho$, $\\\\\\\\theta$, and $\\\\\\\\phi$ are the spherical coordinates, and $(\\\\\\\\rho_{ijk}^*, \\\\\\\\theta_{ijk}^*, \\\\\\\\phi_{ijk}^*)$ are sample points within each sub-interval of the partition. The terms $\\\\\\\\Delta \\\\\\\\rho$, $\\\\\\\\Delta \\\\\\\\theta$, and $\\\\\\\\Delta \\\\\\\\phi$ denote the widths of the partitions in their respective coordinates. The factor $(\\\\\\\\rho_{ijk}^*)^2 \\\\\\\\sin \\\\\\\\phi_{ijk}^*$ accounts for the Jacobian determinant when converting from Cartesian to spherical coordinates. Thus, the given expression correctly represents a triple integral in spherical coordinates as a Riemann sum.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-5-triple-integrals-in-cylindrical-and-spherical-coordinates',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: According to Fubini’s Theorem for Spherical Coordinates, if $f(\\\\\\\\rho, \\\\\\\\theta, \\\\\\\\phi)$ is continuous on a spherical solid box $B = [a,b] \\\\\\\\times [\\\\\\\\alpha, \\\\\\\\beta] \\\\\\\\times [\\\\\\\\gamma, \\\\\\\\psi]$, then the triple integral $\\\\\\\\iiint_B f(\\\\\\\\rho, \\\\\\\\theta, \\\\\\\\phi) \\\\\\\\rho^2 \\\\\\\\sin(\\\\\\\\phi) \\\\\\\\, d\\\\\\\\rho \\\\\\\\, d\\\\\\\\phi \\\\\\\\, d\\\\\\\\theta$ can only be computed by integrating with respect to $\\\\\\\\rho$, $\\\\\\\\phi$, and $\\\\\\\\theta$ in that specific order.',\n",
       "  'answer': 'False',\n",
       "  'explanation': \"Fubini's Theorem for Spherical Coordinates allows for the triple integral $\\\\\\\\iiint_B f(\\\\\\\\rho, \\\\\\\\theta, \\\\\\\\phi) \\\\\\\\rho^2 \\\\\\\\sin(\\\\\\\\phi) \\\\\\\\, d\\\\\\\\rho \\\\\\\\, d\\\\\\\\phi \\\\\\\\, d\\\\\\\\theta$ to be computed by integrating with respect to the three variables in any order, provided the function $f(\\\\\\\\rho, \\\\\\\\theta, \\\\\\\\phi)$ is continuous. This means that we can permute the order of integration without changing the result. For instance, we could integrate with respect to $\\\\\\\\theta$ first, then $\\\\\\\\phi$, and finally $\\\\\\\\rho$, or in any other order, and the value of the integral would remain the same.\",\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-5-triple-integrals-in-cylindrical-and-spherical-coordinates',\n",
       "  'number': '4'},\n",
       " {'question': \"True or False: The moments of inertia of a solid object about the coordinate planes are calculated by integrating the squared distances of points from the respective planes, weighted by the object's density at those points.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This statement is true based on the definition. The moments of inertia about the yz-plane, xz-plane, and xy-plane are given by $I_x = \\\\iiint_Q (y^2 + z^2) \\\\rho(x,y,z) \\\\, dV$, $I_y = \\\\iiint_Q (x^2 + z^2) \\\\rho(x,y,z) \\\\, dV$, and $I_z = \\\\iiint_Q (x^2 + y^2) \\\\rho(x,y,z) \\\\, dV$, respectively. These formulas integrate the squared distances of the points from the respective planes, weighted by the density $\\\\rho(x,y,z)$ at those points. For example, $I_x$ involves the distances squared from both the y and z axes, reflecting the moment of inertia with respect to rotation around the x-axis. This concept applies similarly to $I_y$ and $I_z$ for the y and z axes.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-6-calculating-centers-of-mass-and-moments-of-inertia',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: A transformation $T: G \\\\\\\\to R$, defined as $T(u,v) = (x,y)$, is one-to-one if every distinct pair of points $(u_1, v_1)$ and $(u_2, v_2)$ in the domain $G$ maps to distinct points $(x_1, y_1)$ and $(x_2, y_2)$ in the range $R$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A transformation $T: G \\\\\\\\to R$ is considered one-to-one if and only if no two different points in the domain $G$ map to the same point in the range $R$. This means if $T(u_1, v_1) = (x_1, y_1)$ and $T(u_2, v_2) = (x_2, y_2)$, then $(u_1, v_1) \\\\\\\\ne (u_2, v_2)$ implies $(x_1, y_1) \\\\\\\\ne $(x_2, y_2)$. For example, if $T(1, 2) = (3, 4)$ and $T(5, 6) = (3, 4)$, then $T$ is not one-to-one because two different points in the domain map to the same point in the range.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-7-change-of-variables-in-multiple-integrals',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: For the transformation \\\\( T(u,v) = (g(u,v), h(u,v)) \\\\), the Jacobian determinant \\\\( J(u,v) \\\\) is given by \\\\( J(u,v) = \\\\left| \\\\frac{\\\\partial(g,h)}{\\\\partial(u,v)} \\\\right| = \\\\left| \\\\begin{array}{cc} \\\\frac{\\\\partial g}{\\\\partial u} & \\\\frac{\\\\partial h}{\\\\partial u} \\\\\\\\ \\\\frac{\\\\partial g}{\\\\partial v} & \\\\frac{\\\\partial h}{\\\\partial v} \\\\end{array} \\\\right| = \\\\frac{\\\\partial g}{\\\\partial u} \\\\frac{\\\\partial h}{\\\\partial v} - \\\\frac{\\\\partial g}{\\\\partial v} \\\\frac{\\\\partial h}{\\\\partial u} \\\\) ?',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The Jacobian of a transformation \\\\( T(u,v) = (g(u,v), h(u,v)) \\\\) is indeed calculated as the determinant of the matrix of partial derivatives. The formula for the Jacobian determinant is:  \\\\[  J(u,v) = \\\\left| \\\\frac{\\\\partial(g,h)}{\\\\partial(u,v)} \\\\right| = \\\\left| \\\\begin{array}{cc} \\\\frac{\\\\partial g}{\\\\partial u} & \\\\frac{\\\\partial h}{\\\\partial u} \\\\\\\\ \\\\frac{\\\\partial g}{\\\\partial v} & \\\\frac{\\\\partial h}{\\\\partial v} \\\\end{array} \\\\right| = \\\\frac{\\\\partial g}{\\\\partial u} \\\\frac{\\\\partial h}{\\\\partial v} - \\\\frac{\\\\partial g}{\\\\partial v} \\\\frac{\\\\partial h}{\\\\partial u}.  \\\\]  This formula is a determinant of a 2x2 matrix, which captures how \\\\( u \\\\) and \\\\( v \\\\) are transformed to \\\\( g(u,v) \\\\) and \\\\( h(u,v) \\\\). The determinant calculation involves taking the product of the diagonal elements \\\\(\\\\frac{\\\\partial g}{\\\\partial u}\\\\) and \\\\(\\\\frac{\\\\partial h}{\\\\partial v}\\\\), and subtracting the product of the off-diagonal elements \\\\(\\\\frac{\\\\partial g}{\\\\partial v}\\\\) and \\\\(\\\\frac{\\\\partial h}{\\\\partial u}\\\\).',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-7-change-of-variables-in-multiple-integrals',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The Change of Variables for Double Integrals theorem states that if $f$ is continuous on a region $R$ in the $xy$-plane, and if $(x,y) = T(u,v) = (g(u,v), h(u,v))$ is a one-to-one $C^1$ transformation that maps a region $S$ in the $uv$-plane to $R$, then the integral of $f$ over $R$ is given by:\\\\n$$\\\\iint_R f(x,y) \\\\, dA = \\\\iint_S f(g(u,v), h(u,v)) \\\\left| \\\\frac{\\\\partial(x,y)}{\\\\partial(u,v)} \\\\right| \\\\, du \\\\, dv.$$',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given statement accurately reflects the change of variables formula for double integrals. The transformation $(x, y) = (g(u,v), h(u,v))$ maps a region $S$ in the $uv$-plane to a region $R$ in the $xy$-plane. The determinant of the Jacobian matrix $\\\\left| \\\\frac{\\\\partial(x,y)}{\\\\partial(u,v)} \\\\right|$ accounts for the area distortion caused by the transformation. Therefore, the double integral over $R$ can be evaluated as a double integral over $S$ via the given formula. For example, if $T(u,v) = (u^2, v^2)$, the transformation maps a region like $[0, 1] \\\\times [0, 1]$ in the $uv$-plane to $[0, 1] \\\\times [0, 1]$ in the $xy$-plane with the appropriate correction factor given by the Jacobian determinant.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-7-change-of-variables-in-multiple-integrals',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The Jacobian determinant $J(u,v,w)$ for the transformation from variables $(u, v, w)$ to $(x, y, z)$ is given by $J(u,v,w)=\\\\left| \\\\begin{matrix} \\\\frac{\\\\partial x}{\\\\partial u} & \\\\frac{\\\\partial x}{\\\\partial v} & \\\\frac{\\\\partial x}{\\\\partial w} \\\\\\\\ \\\\frac{\\\\partial y}{\\\\partial u} & \\\\frac{\\\\partial y}{\\\\partial v} & \\\\frac{\\\\partial y}{\\\\partial w} \\\\\\\\ \\\\frac{\\\\partial z}{\\\\partial u} & \\\\frac{\\\\partial z}{\\\\partial v} & \\\\frac{\\\\partial z}{\\\\partial w} \\\\end{matrix} \\\\right|.$',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The Jacobian determinant $J(u,v,w)$ represents the determinant of the $3 \\\\times 3$ matrix of partial derivatives of the transformed variables $(x, y, z)$ with respect to the original variables $(u, v, w)$. This can be written as $J(u,v,w) = \\\\left| \\\\begin{matrix} \\\\frac{\\\\partial x}{\\\\partial u} & \\\\frac{\\\\partial x}{\\\\partial v} & \\\\frac{\\\\partial x}{\\\\partial w} \\\\\\\\ \\\\frac{\\\\partial y}{\\\\partial u} & \\\\frac{\\\\partial y}{\\\\partial v} & \\\\frac{\\\\partial y}{\\\\partial w} \\\\\\\\ \\\\frac{\\\\partial z}{\\\\partial u} & \\\\frac{\\\\partial z}{\\\\partial v} & \\\\frac{\\\\partial z}{\\\\partial w} \\\\end{matrix} \\\\right|$. For example, if $x = uvw$, $y = u + v + w$, and $z = u - v + w$, the partial derivatives form such a matrix, and its determinant defines the Jacobian used in transformations and integrals.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-7-change-of-variables-in-multiple-integrals',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: When performing a change of variables in a triple integral with the transformation $T(u,v,w) = (x,y,z)$, the integral in the $xyz$-space $\\\\iiint_R F(x,y,z) \\\\,dV$ can be converted into the $uvw$-space as long as $T$ is a one-to-one $C^1$ transformation with nonzero Jacobian. The transformed integral is given by $\\\\iiint_G F(g(u,v,w), h(u,v,w), k(u,v,w)) \\\\left| \\\\frac{\\\\partial (x,y,z)}{\\\\partial (u,v,w)} \\\\right| \\\\, dudvdw = \\\\iiint_G H(u,v,w) \\\\left| J(u,v,w) \\\\right| \\\\, dudvdw$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The concept of changing variables in a triple integral involves transforming the region and the integrand to a new set of variables, often to simplify computation. The transformation $T(u,v,w) = (x, y, z)$ maps a region $G$ in $uvw$-space to a region $R$ in $xyz$-space. To ensure a valid transformation, $T$ must be one-to-one, continuously differentiable ($C^1$), and have a non-zero Jacobian determinant $J$. The integrand $F(x, y, z)$ is then expressed in terms of the new variables using the functions $g(u, v, w), h(u, v, w)$, and $k(u, v, w)$, and the volume element $dV$ is adjusted by the absolute value of the Jacobian determinant: $\\\\left| \\\\frac{\\\\partial (x, y, z)}{\\\\partial (u, v, w)} \\\\right|$. Hence, the original integral $\\\\iiint_R F(x, y, z) \\\\, dV$ is transformed to $\\\\iiint_G F(g(u, v, w), h(u, v, w), k(u, v, w)) \\\\left| \\\\frac{\\\\partial (x, y, z)}{\\\\partial (u, v, w)} \\\\right| \\\\, dudvdw$.',\n",
       "  'chapter': 'Multiple Integration',\n",
       "  'section': '5-7-change-of-variables-in-multiple-integrals',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: In a vector field $F$ in $\\\\mathbb{R}^3$, a three-dimensional vector $F(x,y,z)$ is assigned to each point $(x,y,z)$ of a domain $D$ which is a subset of $\\\\mathbb{R}^3$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'In the given definition, a vector field $F$ in $\\\\mathbb{R}^3$ is precisely an assignment of a three-dimensional vector $F(x,y,z)$ to each point $(x,y,z)$ of a subset $D$ of $\\\\mathbb{R}^3$. The domain $D$ represents the set of points in $\\\\mathbb{R}^3$ to which the vectors are assigned. For example, if $D$ is a unit sphere in $\\\\mathbb{R}^3$, then $F$ would assign a three-dimensional vector to each point on that sphere.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-1-vector-fields',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: In \\\\( \\\\mathbb{R}^2 \\\\) or \\\\( \\\\mathbb{R}^3 \\\\), if a vector field \\\\( \\\\mathbf{F} \\\\) is a gradient field, then there exists a scalar function \\\\( f \\\\) such that \\\\( \\\\nabla f = \\\\mathbf{F} \\\\).',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A vector field \\\\( \\\\mathbf{F} \\\\) in \\\\( \\\\mathbb{R}^2 \\\\) or \\\\( \\\\mathbb{R}^3 \\\\) is a gradient field if and only if there exists a scalar function \\\\( f \\\\) such that \\\\( \\\\nabla f = \\\\mathbf{F} \\\\). This means that \\\\( \\\\mathbf{F} \\\\) can be expressed as the gradient of some scalar function \\\\( f \\\\). For example, in \\\\( \\\\mathbb{R}^2 \\\\), if \\\\( \\\\mathbf{F} = (2x, 2y) \\\\), then \\\\( f(x, y) = x^2 + y^2 \\\\) satisfies \\\\( \\\\nabla f = (2x, 2y) = \\\\mathbf{F} \\\\).',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-1-vector-fields',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: If $F$ is a conservative vector field on an open and connected domain, and $f$ and $g$ are functions such that $\\\\\\\\nabla f = F$ and $\\\\\\\\nabla g = F$, then $f$ and $g$ differ by some constant $C$ such that $f = g + C$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'By definition, in a conservative vector field $F$ on an open and connected domain, there exist potentials $f$ and $g$ such that $\\\\\\\\nabla f = F$ and $\\\\\\\\nabla g = F$. The gradient of a function represents the direction and rate of the fastest increase. Since $f$ and $g$ have the same gradient, their difference must be a constant function, as the gradient of a constant is zero. Therefore, $f$ and $g$ differ by some constant $C$, expressed as $f = g + C$. For example, if $F = (2x, 2y)$, both $f = x^2 + y^2$ and $g = x^2 + y^2 + 3$ will have the same gradient, $F$, and differ by the constant $3$.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-1-vector-fields',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: In a conservative vector field $F(x,y) = \\\\langle P(x,y), Q(x,y) \\\\rangle$ in $\\\\mathbb{R}^2$, the cross-partial derivatives must satisfy $\\\\frac{\\\\partial P}{\\\\partial y} = \\\\frac{\\\\partial Q}{\\\\partial x}$. Similarly, in a conservative vector field $F(x,y,z) = \\\\langle P(x,y,z), Q(x,y,z), R(x,y,z) \\\\rangle$ in $\\\\mathbb{R}^3$, the cross-partial derivatives must satisfy $\\\\frac{\\\\partial P}{\\\\partial y} = \\\\frac{\\\\partial Q}{\\\\partial x}$, $\\\\frac{\\\\partial Q}{\\\\partial z} = \\\\frac{\\\\partial R}{\\\\partial y}$, and $\\\\frac{\\\\partial R}{\\\\partial x} = \\\\frac{\\\\partial P}{\\\\partial z}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The Cross-Partial Property of Conservative Vector Fields states that for a vector field $F$ with continuous first-order partial derivatives, certain relationships between the partial derivatives must hold for $F$ to be conservative. In $\\\\mathbb{R}^2$, for $F(x,y) = \\\\langle P(x,y), Q(x,y) \\\\rangle$ to be conservative, it must satisfy $\\\\frac{\\\\partial P}{\\\\partial y} = \\\\frac{\\\\partial Q}{\\\\partial x}$. Similarly, in $\\\\mathbb{R}^3$, for $F(x,y,z) = \\\\langle P(x,y,z), Q(x,y,z), R(x,y,z) \\\\rangle$ to be conservative, it must satisfy $\\\\frac{\\\\partial P}{\\\\partial y} = \\\\frac{\\\\partial Q}{\\\\partial x}$, $\\\\frac{\\\\partial Q}{\\\\partial z} = \\\\frac{\\\\partial R}{\\\\partial y}$, and $\\\\frac{\\\\partial R}{\\\\partial x} = \\\\frac{\\\\partial P}{\\\\partial z}$. This ensures the existence of a potential function from which the vector field can be derived, signifying that the vector field is conservative.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-1-vector-fields',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The scalar line integral of a function $f$ along a smooth planar curve $C$ parameterized by $r(t) = \\\\langle x(t), y(t) \\\\rangle$ over the interval $a \\\\leq t \\\\leq b$ is defined as $\\\\\\\\int_C f(x, y) \\\\\\\\ ds = \\\\\\\\lim_{n \\\\\\\\rightarrow \\\\\\\\infty} \\\\\\\\sum_{i=1}^{n} f(P_i^*) \\\\\\\\Delta s_i$ if the limit exists.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The scalar line integral of a function $f$ along a smooth planar curve $C$ parameterized by $r(t) = \\\\langle x(t), y(t) \\\\rangle$ over the interval $a \\\\\\\\leq t \\\\\\\\leq b$ is indeed defined as $\\\\\\\\int_C f(x, y) \\\\\\\\ ds = \\\\\\\\lim_{n \\\\\\\\rightarrow \\\\\\\\infty} \\\\\\\\sum_{i=1}^{n} f(P_i^*) \\\\\\\\Delta s_i$ if the limit exists. Here, $P_i^*$ are points on the curve, and $\\\\\\\\Delta s_i$ represents the arc length segment between consecutive parameter values $t_i$. This definition aligns with the standard definition of a scalar line integral, where the function $f$ is evaluated at points $P_i^*$ on the curve, summed over increasingly small segments $\\\\\\\\Delta s_i$ as $n$ approaches infinity.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-2-line-integrals',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: To evaluate the scalar line integral $\\\\\\\\int_C f \\\\, ds$ along a smooth curve $C$ parameterized by $\\\\\\\\mathbf{r}(t)$ where $a \\\\\\\\le t \\\\\\\\le b$, the integral can be expressed as $\\\\\\\\int_a^b f(\\\\\\\\mathbf{r}(t)) \\\\\\\\| \\\\\\\\mathbf{r}'(t) \\\\\\\\| \\\\, dt$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The scalar line integral of a continuous function $f$ over a smooth curve $C$ with parameterization $\\\\\\\\mathbf{r}(t)$ from $t=a$ to $t=b$ is evaluated using the formula $\\\\\\\\int_C f \\\\, ds = \\\\\\\\int_a^b f(\\\\\\\\mathbf{r}(t)) \\\\\\\\| \\\\\\\\mathbf{r}'(t) \\\\\\\\| \\\\, dt$. Here, $\\\\\\\\| \\\\\\\\mathbf{r}'(t) \\\\\\\\|$ represents the magnitude of the derivative of $\\\\\\\\mathbf{r}(t)$, which accounts for the arc length differential $ds$. For example, if $\\\\\\\\mathbf{r}(t) = (t, t^2)$ and $f(x, y) = x + y$, the integral would be evaluated by parameterizing $f$ with $\\\\\\\\mathbf{r}(t)$ and integrating with respect to $t$ considering the length element $\\\\\\\\| \\\\\\\\mathbf{r}'(t) \\\\\\\\|$.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-2-line-integrals',\n",
       "  'number': '2'},\n",
       " {'question': \"True or False: Given a scalar line integral over a smooth curve $C$ parameterized by $\\\\\\\\mathbf{r}(t) = \\\\\\\\langle x(t), y(t), z(t) \\\\\\\\rangle$ for $a \\\\\\\\leq t \\\\\\\\leq b$, the line integral $\\\\\\\\int_C f(x,y,z) \\\\\\\\, ds$ is equal to $\\\\\\\\int_a^b f(\\\\\\\\mathbf{r}(t)) \\\\\\\\sqrt{(x'(t))^2 + (y'(t))^2 + (z'(t))^2} \\\\\\\\, dt$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The expression provided is a formula for a scalar line integral over a smooth and parameterized curve $C$. The function $f(x,y,z)$ is evaluated along the curve determined by $\\\\\\\\mathbf{r}(t) = \\\\\\\\langle x(t), y(t), z(t) \\\\\\\\rangle$. The parameter $t$ ranges from $a$ to $b$. The integrand includes $f(\\\\\\\\mathbf{r}(t))$, which means the function $f$ is evaluated at the points on the curve. The differential arc length $ds$ is calculated using the Euclidean norm of the derivative $\\\\\\\\mathbf{r}'(t) = \\\\\\\\langle x'(t), y'(t), z'(t) \\\\\\\\rangle$, giving $\\\\\\\\sqrt{(x'(t))^2 + (y'(t))^2 + (z'(t))^2}$. An example of this concept can be visualized by considering the line integral of a height function $f$ along a helical path. The same procedure applies whether the curve is in 2D or 3D, modifying the formula accordingly as indicated for planar curves.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-2-line-integrals',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The vector line integral of a vector field $ \\\\mathbf{F} $ along an oriented smooth curve $ C $ is computed as $ \\\\int_C \\\\mathbf{F} \\\\cdot \\\\mathbf{T} \\\\, ds = \\\\lim_{n \\\\to \\\\infty} \\\\sum_{i=1}^{n} \\\\mathbf{F}(P_i^*) \\\\cdot \\\\mathbf{T}(P_i^*) \\\\Delta s_i $ if that limit exists.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of the vector line integral of a vector field $ \\\\mathbf{F} $ along an oriented smooth curve $ C $ is given by the provided equation, which states that it is computed as a limit of a Riemann sum. This involves breaking the curve into small segments, evaluating the vector field and the tangent vector at sample points on these segments, and then taking the dot product and summing over all segments. If the limit of such sums exists as the number of segments approaches infinity, it defines the vector line integral.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-2-line-integrals',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: If $\\\\\\\\vec{F}$ and $\\\\\\\\vec{G}$ are continuous vector fields with domains that include the oriented smooth curve $C$, then $\\\\\\\\int_C (\\\\\\\\vec{F} + \\\\\\\\vec{G}) \\\\\\\\cdot d\\\\\\\\vec{r} = \\\\\\\\int_C \\\\\\\\vec{F} \\\\\\\\cdot d\\\\\\\\vec{r} + \\\\\\\\int_C \\\\\\\\vec{G} \\\\\\\\cdot d\\\\\\\\vec{r}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'This equality holds because vector line integrals over a curve $C$ are linear with respect to the addition of vector fields. That means the integral of the sum of two vector fields over a curve is equal to the sum of the integrals of each vector field over the same curve. For example, if $\\\\\\\\vec{F}(x) = (x, y)$ and $\\\\\\\\vec{G}(x) = (y, x)$, then integrating their sum $\\\\\\\\vec{F} + \\\\\\\\vec{G} = (x + y, y + x)$ over the curve $C$ would yield the sum of the integrals of each vector field individually over $C$.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-2-line-integrals',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: The flux of a vector field $F$ across a curve $C$ can be expressed as the line integral $\\\\int_C F \\\\cdot n(t) \\\\|n(t)\\\\| \\\\, ds$.',\n",
       "  'answer': 'False',\n",
       "  'explanation': \"The given definition for the flux of a vector field $F$ across a curve $C$ is incorrect. The correct expression should be $\\\\int_C F \\\\cdot T \\\\, ds$, where $T$ is the unit tangent vector to the curve $C$, and $ds$ is the differential arc length along $C$. The error in the provided definition is the use of the normal vector $n(t)$ and its magnitude, which is unnecessary for the computation of flux. For instance, when computing flux through a curve in a plane, one should consider the vector field's component along the direction of the curve (tangential) rather than normal to it.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-2-line-integrals',\n",
       "  'number': '6'},\n",
       " {'question': \"True or False: The flux of a vector field $ F $ across a smooth curve $ C $ with parameterization $ \\\\mathbf{r}(t) = \\\\langle x(t), y(t) \\\\rangle $, $ a \\\\leq t \\\\leq b $ is given by $ \\\\int_C \\\\mathbf{F} \\\\cdot \\\\mathbf{N} \\\\, ds = \\\\int_a^b \\\\mathbf{F}(\\\\mathbf{r}(t)) \\\\cdot \\\\mathbf{n}(t) \\\\, dt $, where $ \\\\mathbf{n}(t) = \\\\langle y'(t), -x'(t) \\\\rangle $.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The statement accurately describes the concept of flux across a curve. The flux of a vector field $ \\\\mathbf{F} $ across a smooth curve $ C $ with parameterization $ \\\\mathbf{r}(t) = \\\\langle x(t), y(t) \\\\rangle $, from $ t=a $ to $ t=b $, is indeed calculated as $ \\\\int_C \\\\mathbf{F} \\\\cdot \\\\mathbf{N} \\\\, ds = \\\\int_a^b \\\\mathbf{F}(\\\\mathbf{r}(t)) \\\\cdot \\\\mathbf{n}(t) \\\\, dt $. Here, $ \\\\mathbf{n}(t) = \\\\langle y'(t), -x'(t) \\\\rangle $ represents the normal vector to the curve $ C $, which is essential in computing the dot product with the vector field $ \\\\mathbf{F} $ along the curve. This formula essentially quantifies the 'flow' of the vector field $ \\\\mathbf{F} $ across the curve $ C $.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-2-line-integrals',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: A curve $C$ can be both a closed curve and a simple curve if there exists a parameterization $\\\\\\\\mathbf{r}(t)$, $a \\\\\\\\leq t \\\\\\\\leq b$ of $C$ such that $\\\\\\\\mathbf{r}(a) = \\\\\\\\mathbf{r}(b)$ and $\\\\\\\\mathbf{r}$ is one-to-one over $(a, b)$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A curve $C$ being closed implies that its parameterization $\\\\\\\\mathbf{r}(t)$ satisfies $\\\\\\\\mathbf{r}(a) = \\\\\\\\mathbf{r}(b)$. A curve $C$ is simple if it does not cross itself, which means there exists a parameterization $\\\\\\\\mathbf{r}(t)$ that is one-to-one over $(a, b)$. Therefore, a curve $C$ can be both closed and simple if there is a parameterization $\\\\\\\\mathbf{r}(t)$ that is one-to-one over $(a, b)$ and satisfies $\\\\\\\\mathbf{r}(a) = \\\\\\\\mathbf{r}(b)$, meaning the curve forms a loop without self-intersections. An example of a closed and simple curve is a circle parameterized by $\\\\\\\\mathbf{r}(t) = (\\\\\\\\cos(t), \\\\\\\\sin(t))$ for $t$ in $[0, 2\\\\\\\\pi]$, where $\\\\\\\\mathbf{r}(0) = \\\\\\\\mathbf{r}(2\\\\\\\\pi)$ and $\\\\\\\\mathbf{r}(t)$ is one-to-one over $(0, 2\\\\\\\\pi)$.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-3-conservative-vector-fields',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: A region \\\\( D \\\\) is simply connected if it is connected and contains no holes.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A simply connected region \\\\( D \\\\) is one where any two points within it can be connected by a path that stays entirely within \\\\( D \\\\). Additionally, any simple closed curve \\\\( C \\\\) within \\\\( D \\\\) can be continuously shrunk to a point without leaving \\\\( D \\\\). In two dimensions, these properties imply that the region \\\\( D \\\\) must be connected and free of holes. For example, a circular region without any holes is simply connected, whereas a region with a central hole (like a doughnut shape) is not simply connected.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-3-conservative-vector-fields',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The value of the line integral $ \\\\int_C \\\\nabla f \\\\cdot d\\\\mathbf{r} $ over a piecewise smooth curve $C$ is equal to $f(\\\\mathbf{r}(b)) - f(\\\\mathbf{r}(a))$, where $ \\\\mathbf{r}(t) $ is the parameterization of $C$ from $a$ to $b$, and $f$ is a function with continuous first-order partial derivatives on $C$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The Fundamental Theorem for Line Integrals states that for a piecewise smooth curve $C$ parameterized by $ \\\\mathbf{r}(t) $ from $a$ to $b$ and a function $f$ with continuous first-order partial derivatives on $C$, the line integral of the gradient of $f$ over $C$ can be computed as the difference $f(\\\\mathbf{r}(b)) - f(\\\\mathbf{r}(a))$. For example, if $C$ is the path from $(1,1)$ to $(2,2)$ and $f(x,y)=x^2 + y^2$, the value of the line integral $ \\\\int_C \\\\nabla f \\\\cdot d\\\\mathbf{r} $ is $f(2,2) - f(1,1) = (2^2 + 2^2) - (1^2 + 1^2) = 8 - 2 = 6$.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-3-conservative-vector-fields',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: A vector field $F$ is path independent if the line integrals $\\\\int_{C1} F \\\\cdot d\\\\mathbf{r} = \\\\int_{C2} F \\\\cdot d\\\\mathbf{r}$ for any paths $C_1$ and $C_2$ in domain $D$ that share the same initial and terminal points.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A vector field $F$ being path independent means that the line integral of $F$ over two different paths $C_1$ and $C_2$ connecting the same start and end points will yield the same result. This definition implies that the integral depends only on the endpoints and not on the specific path taken. For example, if you have a point $A$ and a point $B$, and two different paths $C_1$ and $C_2$ connecting $A$ to $B$, the condition for path independence is $\\\\int_{C1} F \\\\cdot d\\\\mathbf{r} = \\\\int_{C2} F \\\\cdot d\\\\mathbf{r}$.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-3-conservative-vector-fields',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: If $\\\\\\\\mathbf{F}$ is a conservative vector field, then the line integral $\\\\\\\\int_{C} \\\\\\\\mathbf{F} \\\\\\\\cdot d\\\\\\\\mathbf{r}$ depends only on the path $C$ taken between two points.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'A conservative vector field $\\\\\\\\mathbf{F}$ has the property that the line integral $\\\\\\\\int_{C} \\\\\\\\mathbf{F} \\\\\\\\cdot d\\\\\\\\mathbf{r}$ over a path $C$ depends only on the endpoints of $C$, not the specific path taken. This is known as path independence. For example, if $\\\\\\\\mathbf{F}$ is the gradient of some scalar potential function $\\\\\\\\phi$, i.e., $\\\\\\\\mathbf{F} = \\\\\\\\nabla \\\\\\\\phi$, then $\\\\\\\\int_{C} \\\\\\\\mathbf{F} \\\\\\\\cdot d\\\\\\\\mathbf{r} = \\\\\\\\phi(B) - \\\\\\\\phi(A)$, where $A$ and $B$ are the endpoints of the path $C$. Thus, the integral depends only on the values of $\\\\\\\\phi$ at $A$ and $B$, not on the particular path $C$ connecting them.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-3-conservative-vector-fields',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: If $\\\\\\\\mathbf{F}$ is a continuous vector field with a domain $D$ that is open and connected, and $\\\\mathbf{F}$ is independent of path, then $\\\\\\\\mathbf{F}$ is conservative.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A vector field $\\\\\\\\mathbf{F}$ is conservative if there exists a potential function $\\\\phi$ such that $\\\\\\\\mathbf{F} = \\\\\\\\nabla \\\\phi$. One of the criteria that can be used to determine if a vector field is conservative is the path independence test. If $\\\\\\\\mathbf{F}$ is continuous, path independent, and the domain $D$ of $\\\\mathbf{F}$ is open and connected, then these conditions imply that $\\\\mathbf{F}$ is conservative. Essentially, this means that the line integral of $\\\\mathbf{F}$ over any path depends only on the endpoints of the path, which is a defining property of conservative fields.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-3-conservative-vector-fields',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: If a vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ in an open, simply connected region $D$ satisfies $\\\\\\\\frac{\\\\\\\\partial P}{\\\\\\\\partial y} = \\\\\\\\frac{\\\\\\\\partial Q}{\\\\\\\\partial x}$, $\\\\\\\\frac{\\\\\\\\partial P}{\\\\\\\\partial z} = \\\\\\\\frac{\\\\\\\\partial R}{\\\\\\\\partial x}$, and $\\\\\\\\frac{\\\\\\\\partial Q}{\\\\\\\\partial z} = \\\\\\\\frac{\\\\\\\\partial R}{\\\\\\\\partial y}$ throughout $D$, then $\\\\\\\\mathbf{F}$ is guaranteed to be conservative.',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The cross-partial derivatives' equality conditions, $\\\\\\\\frac{\\\\\\\\partial P}{\\\\\\\\partial y} = \\\\\\\\frac{\\\\\\\\partial Q}{\\\\\\\\partial x}$, $\\\\\\\\frac{\\\\\\\\partial P}{\\\\\\\\partial z} = \\\\\\\\frac{\\\\\\\\partial R}{\\\\\\\\partial x}$, and $\\\\\\\\frac{\\\\\\\\partial Q}{\\\\\\\\partial z} = \\\\\\\\frac{\\\\\\\\partial R}{\\\\\\\\partial y}$, as specified in the question, are collectively known as the Cross-Partial Test. They must hold true throughout the open, simply connected region $D$ to ensure that the vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ is conservative. A conservative vector field is one that can be described as the gradient of some scalar potential function. For example, the field $\\\\\\\\mathbf{F} = \\\\\\\\langle 2xy, x^2 + y^2, z \\\\\\\\rangle$ fulfills these conditions; hence it is conservative.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-3-conservative-vector-fields',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: For a vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ on an open, simply connected region $D$, the conditions $P_y = Q_x$, $P_z = R_x$, and $Q_z = R_y$ throughout $D$ are both necessary and sufficient for $\\\\\\\\mathbf{F}$ to be conservative.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ is conservative if and only if its components satisfy the cross-partial derivative equalities $P_y = Q_x$, $P_z = R_x$, and $Q_z = R_y$ in an open, simply connected region $D$. These conditions are derived from the symmetry in the second mixed partial derivatives implied by the existence of a scalar potential function $f$ such that $\\\\\\\\mathbf{F} = \\\\\\\\nabla f$. Examples of conservative fields include $\\\\\\\\mathbf{F} = \\\\\\\\langle y, x, 0 \\\\\\\\rangle$ where $P=x, Q=y, R=0,$ and checking the cross-partials shows $P_y = Q_x$ and $P_z = R_x, Q_z = R_y$ is trivially satisfied.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-3-conservative-vector-fields',\n",
       "  'number': '8'},\n",
       " {'question': \"True or False: According to Green's Theorem in its circulation form, if $D$ is an open, simply connected region with a boundary curve $C$ that is piecewise smooth and oriented clockwise, then $ \\\\oint_{C} F \\\\cdot dr = \\\\iint_{D} ( \\\\frac{\\\\partial Q}{\\\\partial x} -  \\\\frac{\\\\partial P}{\\\\partial y}) \\\\, dA $.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"Green's Theorem states that for an open, simply connected region $D$ with a boundary $C$ that is oriented counterclockwise, the circulation of vector field $F$ around $C$ is equal to the double integral over $D$ of the difference between the partial derivative of $Q$ with respect to $x$ and the partial derivative of $P$ with respect to $y$. The standard form is $ \\\\oint_{C} F \\\\cdot dr =  \\\\oint_{C} P \\\\, dx + Q \\\\, dy = \\\\iint_{D} ( \\\\frac{\\\\partial Q}{\\\\partial x} - \\\\frac{\\\\partial P}{\\\\partial y}) \\\\, dA $. If the boundary curve $C$ is oriented clockwise, the sign of the integral would change, making the given equation incorrect. For a clockwise orientation, the correct equation would be $ \\\\oint_{C} F \\\\cdot dr = - \\\\iint_{D} ( \\\\frac{\\\\partial Q}{\\\\partial x} -  \\\\frac{\\\\partial P}{\\\\partial y}) \\\\, dA $.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-4-greens-theorem',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: According to Green's Theorem in Flux Form for an open, simply connected region \\\\( D \\\\) with boundary curve \\\\( C \\\\) that is a piecewise smooth, simple closed curve oriented counterclockwise, the line integral \\\\( \\\\\\\\oint_{C} \\\\mathbf{F} \\\\cdot \\\\mathbf{N} \\\\, ds \\\\) equals the double integral \\\\( \\\\\\\\iint_{D} (P_x + Q_y) \\\\, dA \\\\), where \\\\( \\\\mathbf{F} = \\\\langle P, Q \\\\rangle \\\\) is a vector field with component functions having continuous partial derivatives on an open region containing \\\\( D \\\\).\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"Green's Theorem (Flux Form) states that for a vector field \\\\( \\\\\\\\mathbf{F} = \\\\\\\\langle P, Q \\\\\\\\rangle \\\\) with component functions \\\\( P \\\\) and \\\\( Q \\\\) having continuous partial derivatives on an open region containing \\\\( D \\\\), the line integral over the boundary \\\\( C \\\\) with respect to the outward normal \\\\( \\\\\\\\mathbf{N} \\\\) equals the double integral over \\\\( D \\\\) of \\\\( P_x + Q_y \\\\). This means:\\\\[ \\\\\\\\oint_{C} \\\\\\\\mathbf{F} \\\\cdot \\\\\\\\mathbf{N} \\\\, ds = \\\\\\\\iint_{D} (P_x + Q_y) \\\\, dA \\\\]The condition requires that \\\\( D \\\\) is an open, simply connected region with a boundary \\\\( C \\\\) that is a piecewise smooth, simple closed curve oriented counterclockwise. This helps ensure the theorem's application properly bridges the line integral and double integral over the specified region \\\\( D \\\\). For example, if \\\\( P \\\\) and \\\\( Q \\\\) are defined as \\\\( P = x^2 \\\\) and \\\\( Q = y^2 \\\\), the green's theorem in flux form can be used to compute the area integrals from boundary curve integrals or vice versa.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-4-greens-theorem',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: If $\\\\mathbf{F}=\\\\langle P, Q, R \\\\rangle$ is a vector field in $\\\\mathbb{R}^3$ and $\\\\frac{\\\\partial P}{\\\\partial x}$, $\\\\frac{\\\\partial Q}{\\\\partial y}$, and $\\\\frac{\\\\partial R}{\\\\partial z}$ all exist, then the divergence of $\\\\mathbf{F}$ is defined as $\\\\text{div} \\\\mathbf{F} = \\\\frac{\\\\partial P}{\\\\partial x} + \\\\frac{\\\\partial Q}{\\\\partial y} + \\\\frac{\\\\partial R}{\\\\partial z}$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The divergence of a vector field $\\\\mathbf{F}=\\\\langle P, Q, R \\\\rangle$ in $\\\\mathbb{R}^3$ measures the rate at which 'density' exits a given point in the field. For the divergence to be well-defined, the partial derivatives $\\\\frac{\\\\partial P}{\\\\partial x}$, $\\\\frac{\\\\partial Q}{\\\\partial y}$, and $\\\\frac{\\\\partial R}{\\\\partial z}$ must exist. When these conditions are met, the divergence is calculated as $\\\\text{div} \\\\mathbf{F} = \\\\frac{\\\\partial P}{\\\\partial x} + \\\\frac{\\\\partial Q}{\\\\partial y} + \\\\frac{\\\\partial R}{\\\\partial z}$. For example, if $\\\\mathbf{F} = \\\\langle y, z, x \\\\rangle$, then $\\\\frac{\\\\partial P}{\\\\partial x} = 0$, $\\\\frac{\\\\partial Q}{\\\\partial y} = 0$, and $\\\\frac{\\\\partial R}{\\\\partial z} = 0$, thus $\\\\text{div} \\\\mathbf{F} = 0 + 0 + 0 = 0$.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-5-divergence-and-curl',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: If $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q \\\\\\\\rangle$ is a source-free continuous vector field with differentiable component functions, then $\\\\\\\\nabla \\\\\\\\cdot \\\\\\\\mathbf{F} = 0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The divergence of a vector field $\\\\\\\\mathbf{F}$, denoted $\\\\\\\\nabla \\\\\\\\cdot \\\\\\\\mathbf{F}$, measures the magnitude of a source or sink at a given point. A vector field is considered source-free when there are no sources or sinks, meaning it is neither diverging nor converging at any point within the field. In mathematical terms, for a source-free vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q \\\\\\\\rangle$ with continuously differentiable components, $P$ and $Q$, the divergence is defined as $\\\\\\\\nabla \\\\\\\\cdot \\\\\\\\mathbf{F} = \\\\\\\\frac{\\\\\\\\partial P}{\\\\\\\\partial x} + \\\\\\\\frac{\\\\\\\\partial Q}{\\\\\\\\partial y}$. If the field is source-free, this sum equals zero, implying $\\\\\\\\nabla \\\\\\\\cdot \\\\\\\\mathbf{F} = 0$. For instance, consider $\\\\\\\\mathbf{F} = \\\\\\\\langle x, -x \\\\\\\\rangle$. Here, $\\\\\\\\frac{\\\\\\\\partial P}{\\\\\\\\partial x} = 1$ and $\\\\\\\\frac{\\\\\\\\partial Q}{\\\\\\\\partial y} = -1$, so $\\\\\\\\nabla \\\\\\\\cdot \\\\\\\\mathbf{F} = 1 - 1 = 0$, confirming that it is source-free.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-5-divergence-and-curl',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: Let $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q \\\\\\\\rangle$ be a continuous vector field with differentiable component functions on a simply connected domain. Then, $\\\\\\\\text{div } \\\\\\\\mathbf{F} = 0$ is a necessary and sufficient condition for $\\\\\\\\mathbf{F}$ to be source free.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q \\\\\\\\rangle$ being source free implies that the field has no net flux emerging from any point within its domain. According to the Divergence Test for Source-Free Vector Fields, if $\\\\\\\\mathbf{F}$ has continuous and differentiable component functions in a simply connected domain, having $\\\\\\\\text{div } \\\\\\\\mathbf{F} = 0$ means there is no net creation of the vector field within the domain, i.e., the vector field is source free. This relationship works both ways (if and only if), so the statement is true. For example, if $\\\\\\\\mathbf{F} = \\\\\\\\langle y, -x \\\\\\\\rangle$, the divergence $\\\\\\\\frac{\\\\\\\\partial y}{\\\\\\\\partial x} + \\\\\\\\frac{\\\\\\\\partial (-x)}{\\\\\\\\partial y} = 0$, indicating that the vector field is source free.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-5-divergence-and-curl',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The curl of a vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ in $\\\\\\\\mathbb{R}^3$ is a scalar field.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The curl of a vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ in $\\\\\\\\mathbb{R}^3$ is given by $\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F} = (\\\\\\\\frac{\\\\\\\\partial R}{\\\\\\\\partial y} - \\\\\\\\frac{\\\\\\\\partial Q}{\\\\\\\\partial z})\\\\\\\\mathbf{i} + (\\\\\\\\frac{\\\\\\\\partial P}{\\\\\\\\partial z} - \\\\\\\\frac{\\\\\\\\partial R}{\\\\\\\\partial x})\\\\\\\\mathbf{j} + (\\\\\\\\frac{\\\\\\\\partial Q}{\\\\\\\\partial x} - \\\\\\\\frac{\\\\\\\\partial P}{\\\\\\\\partial y})\\\\\\\\mathbf{k}$. This expression is a vector field, not a scalar field, because it results in a vector consisting of three components. In contrast, the divergence of a vector field results in a scalar field.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-5-divergence-and-curl',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: For a vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ in $\\\\\\\\mathbb{R}^3$ such that the component functions all have continuous second-order partial derivatives, the divergence of the curl, given by $\\\\\\\\nabla \\\\\\\\cdot (\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F})$, is always zero.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The expression $\\\\\\\\nabla \\\\\\\\cdot (\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F})$ represents the divergence of the curl of a vector field $\\\\\\\\mathbf{F}$ in $\\\\\\\\mathbb{R}^3$. By definition, if the component functions of $\\\\\\\\mathbf{F}$ have continuous second-order partial derivatives, then this quantity is always zero. This is a fundamental result in vector calculus. For example, if $\\\\\\\\mathbf{F} = \\\\\\\\langle x, y, x+y \\\\\\\\rangle$, the curl $\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F}$ is computed and then diverged, ultimately resulting in zero.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-5-divergence-and-curl',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: If $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ is a conservative vector field, then $\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F} = 0$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'A vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ is said to be conservative if there exists a scalar potential function $\\\\\\\\phi$ such that $\\\\\\\\mathbf{F} = \\\\\\\\nabla \\\\\\\\phi$. In other words, a conservative vector field is the gradient of some scalar potential. The curl of the gradient of any scalar field is always zero, which can be written as $\\\\\\\\nabla \\\\\\\\times (\\\\\\\\nabla \\\\\\\\phi) = 0$. Therefore, if $\\\\\\\\mathbf{F}$ is conservative, then $\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F} = 0$. For example, consider the conservative vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle 2x, 2y, 2z \\\\\\\\rangle$. It can be written as $\\\\\\\\mathbf{F} = \\\\\\\\nabla (x^2 + y^2 + z^2)$, and its curl $\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F} = 0$ confirms that $\\\\\\\\mathbf{F}$ is conservative.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-5-divergence-and-curl',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: For a vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$ in a simply connected domain, if $\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F} = \\\\\\\\mathbf{0}$, then $\\\\\\\\mathbf{F}$ is a conservative vector field.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'In a simply connected domain, if the curl of a vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle P, Q, R \\\\\\\\rangle$, denoted as $\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F}$, is zero, this implies that $\\\\\\\\mathbf{F}$ is a conservative vector field. A conservative vector field has a potential function $f$ such that $\\\\\\\\mathbf{F} = \\\\\\\\nabla f$. The simply connected domain ensures that there are no holes or discontinuities, allowing us to apply this principle. This is an essential concept in vector calculus, often used in physics and engineering. As an example, the gravitational field near the surface of the Earth can be described by a conservative vector field.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-5-divergence-and-curl',\n",
       "  'number': '7'},\n",
       " {'question': 'True or False: The parameter domain of the parameterization $\\\\\\\\mathbf{r}(u,v)=\\\\\\\\langle x(u,v), y(u,v), z(u,v) \\\\\\\\rangle$ is the range of values taken by $\\\\\\\\mathbf{r}(u,v)$ in 3D space.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'The parameter domain of the parameterization $\\\\\\\\mathbf{r}(u,v)=\\\\\\\\langle x(u,v), y(u,v), z(u,v) \\\\\\\\rangle$ is actually the set of points in the $uv$-plane that can be substituted into $\\\\\\\\mathbf{r}$, not the range of values taken by $\\\\\\\\mathbf{r}(u,v)$ in 3D space. This means that the domain specifies the permissible values of the parameters $(u,v)$, which form a subset in the $uv$-plane. For example, if $u$ and $v$ are both defined over the interval $[0, 1]$, the parameter domain is the square with corners $(0,0)$, $(1,0)$, $(0,1)$, and $(1,1)$ in the $uv$-plane.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-6-surface-integrals',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: A parameterization $\\\\\\\\mathbf{r}(u,v)=\\\\\\\\langle x(u,v), y(u,v), z(u,v) \\\\\\\\rangle$ is considered regular if $\\\\\\\\frac{\\\\\\\\partial \\\\\\\\mathbf{r}}{\\\\\\\\partial u} \\\\\\\\times \\\\\\\\frac{\\\\\\\\partial \\\\\\\\mathbf{r}}{\\\\\\\\partial v} \\\\\\\\neq \\\\\\\\mathbf{0}$ for all points $(u,v)$ in the parameter domain.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of a regular parameterization requires that the cross product of the partial derivatives $\\\\\\\\frac{\\\\\\\\partial \\\\\\\\mathbf{r}}{\\\\\\\\partial u}$ and $\\\\\\\\frac{\\\\\\\\partial \\\\\\\\mathbf{r}}{\\\\\\\\partial v}$ is not zero. This condition ensures that the parameterization is smooth and avoids singularities. Examples include the standard parameterization of a sphere, where the partial derivatives of the parameterization vectors form a non-zero cross product, indicating a well-defined surface.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-6-surface-integrals',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: A surface parameterization $ \\\\mathbf{r}(u,v)=\\\\langle x(u,v),y(u,v),z(u,v) \\\\rangle $ is considered smooth if and only if the vector $ \\\\mathbf{r}_u \\\\times \\\\mathbf{r}_v $ is non-zero for any choice of $u$ and $v$ in the parameter domain.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The smoothness of a surface parameterization $ \\\\mathbf{r}(u,v)=\\\\langle x(u,v),y(u,v),z(u,v) \\\\rangle $ is determined by the condition that the cross product of the partial derivatives $ \\\\mathbf{r}_u $ and $ \\\\mathbf{r}_v $ with respect to $u$ and $v$ respectively is non-zero for any values of $u$ and $v$ within the parameter domain. This condition ensures that the surface does not have any singular points where the tangent plane would degenerate, thus maintaining the smoothness of the surface. For example, if $ \\\\mathbf{r}_u \\\\times \\\\mathbf{r}_v = 0 $ at some $(u,v)$, there would be no distinct tangent plane at that point, indicating a singularity and therefore a lack of smoothness.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-6-surface-integrals',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: The surface area of a smooth parameterized surface $S$ given by $r(u,v)=\\\\\\\\langle x(u,v), y(u,v), z(u,v) \\\\\\\\rangle$ over the parameter domain $D$ can be found using the double integral $\\\\\\\\iint_D \\\\\\\\| t_u \\\\\\\\times t_v \\\\\\\\| \\\\\\\\, dA$, where $t_u = \\\\\\\\left\\\\\\\\langle \\\\\\\\frac{\\\\\\\\partial x}{\\\\\\\\partial u}, \\\\\\\\frac{\\\\\\\\partial y}{\\\\\\\\partial u}, \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial u} \\\\\\\\right\\\\\\\\rangle$ and $t_v = \\\\\\\\left\\\\\\\\langle \\\\\\\\frac{\\\\\\\\partial x}{\\\\\\\\partial v}, \\\\\\\\frac{\\\\\\\\partial y}{\\\\\\\\partial v}, \\\\\\\\frac{\\\\\\\\partial z}{\\\\\\\\partial v} \\\\\\\\right\\\\\\\\rangle$ represent the partial derivatives of $r$ with respect to $u$ and $v$ respectively.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The surface area of a smooth parameterized surface $S$ given by $r(u,v)$ over the parameter domain $D$ is computed using the double integral $\\\\\\\\iint_D \\\\\\\\| t_u \\\\\\\\times t_v \\\\\\\\| \\\\\\\\, dA$. Here, $t_u$ and $t_v$ are the tangent vectors to the surface, calculated as the partial derivatives of the parameterization $r$ with respect to $u$ and $v$, respectively. The cross product $t_u \\\\\\\\times t_v$ gives a vector perpendicular to the surface at each point, and its magnitude $\\\\\\\\| t_u \\\\\\\\times t_v \\\\\\\\|$ represents the area of the parallelogram formed by $t_u$ and $t_v$. Integrating this magnitude over the domain $D$ yields the total surface area of $S$. For example, for a parameterization $r(u,v) = \\\\\\\\langle u, v, uv \\\\\\\\rangle $, the partial derivatives would be $t_u = \\\\\\\\langle 1, 0, v \\\\\\\\rangle$ and $t_v = \\\\\\\\langle 0, 1, u \\\\\\\\rangle$, and the integral would be over the given domain $D$.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-6-surface-integrals',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: The surface integral of a scalar-valued function $f$ over a piecewise smooth surface $S$ can be approximated by summing the product of the function values at sample points $P_{ij}$ and the areas $\\\\Delta S_{ij}$ of small surface patches, then taking the limit as the number of surface patches goes to infinity.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of the surface integral of a scalar-valued function $f(x, y, z)$ over a piecewise smooth surface $S$ is given by  $\\\\\\\\iint_S f(x, y, z) dS = \\\\lim_{m, n \\\\\\\\to \\\\\\\\infty} \\\\\\\\sum_{i=1}^m \\\\\\\\sum_{j=1}^n f(P_{ij}) \\\\Delta S_{ij}$. This means that we approximate the integral by dividing the surface into small patches $\\\\\\\\Delta S_{ij}$, evaluating the function at sample points $P_{ij}$ within these patches, summing the products of the function values and the areas of the patches, and then taking the limit as the number of patches approaches infinity. For example, if we have a function $f(x, y, z) = x^2 + y^2 + z^2$ over a surface $S$, we sum the values of $x^2 + y^2 + z^2$ at various points on $S$, multiplied by the area of small patches of $S$, and this sum approaches the true surface integral as the patches get smaller and more numerous.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-6-surface-integrals',\n",
       "  'number': '5'},\n",
       " {'question': 'True or False: The surface integral of a continuous vector field $ \\\\mathbf{F} $ over an oriented surface $ S $ with a unit normal vector $ \\\\mathbf{N} $ can be expressed as $ \\\\iint_S \\\\mathbf{F} \\\\cdot d\\\\mathbf{S} = \\\\iint_S \\\\mathbf{F} \\\\cdot \\\\mathbf{N} dS $.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The surface integral of a continuous vector field $ \\\\mathbf{F} $ over an oriented surface $ S $ with a unit normal vector $ \\\\mathbf{N} $ is defined as $ \\\\iint_S \\\\mathbf{F} \\\\cdot d\\\\mathbf{S} $. Here, $ d\\\\mathbf{S} $ represents the vector area element, which can be decomposed into the product of the unit normal vector $ \\\\mathbf{N} $ and the scalar area element $ dS $. Hence, $ d\\\\mathbf{S} = \\\\mathbf{N} dS $. Substituting this into the integral gives $ \\\\iint_S \\\\mathbf{F} \\\\cdot d\\\\mathbf{S} = \\\\iint_S \\\\mathbf{F} \\\\cdot ( \\\\mathbf{N} dS ) $, which simplifies to $ \\\\iint_S \\\\mathbf{F} \\\\cdot \\\\mathbf{N} dS $. Therefore, the given statement is true. For example, if $ \\\\mathbf{F} = (x, y, z) $ and $ S $ is a surface in $ \\\\mathbb{R}^3 $ with a consistent orientation, this definition holds and ensures that the integral incorporates the direction and magnitude of $ \\\\mathbf{F} $ over $ S $ accurately.',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-6-surface-integrals',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: Stokes’ Theorem states that for a piecewise smooth oriented surface $S$ with boundary $C$, and a vector field $\\\\\\\\mathbf{F}$ with continuous partial derivatives, the line integral of $\\\\\\\\mathbf{F}$ over $C$ equals the surface integral of $\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F}$ over $S$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"Stokes’ Theorem connects the line integral of a vector field $\\\\\\\\mathbf{F}$ around a simple, closed curve $C$ to the surface integral of the curl of $\\\\\\\\mathbf{F}$ over the surface $S$ bounded by $C$. Mathematically, it is expressed as $\\\\\\\\int_{C} \\\\\\\\mathbf{F} \\\\\\\\cdot d\\\\\\\\mathbf{r} = \\\\\\\\iint_{S} (\\\\\\\\nabla \\\\\\\\times \\\\\\\\mathbf{F}) \\\\\\\\cdot d\\\\\\\\mathbf{S}$. This theorem illustrates the relationship between circulation around the boundary and the sum of the curls over the surface. For example, in fluid dynamics, this means the total circulation around a loop (like a vortex) on the fluid's surface relates to how the fluid rotates across the entire surface.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-7-stokes-theorem',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: According to the Divergence Theorem, if $S$ is a piecewise, smooth closed surface that encloses a solid $E$ in space and $\\\\\\\\mathbf{F}$ is a vector field with continuous partial derivatives on an open region containing $E$, then the volume integral of the divergence of $\\\\\\\\mathbf{F}$ over $E$ is equal to the surface integral of $\\\\\\\\mathbf{F}$ dotted with the outward-pointing normal vector over $S$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The Divergence Theorem states that if $S$ is a piecewise, smooth closed surface that encloses a solid $E$ in space and $\\\\\\\\mathbf{F}$ is a vector field with continuous partial derivatives on an open region containing $E$, then $\\\\\\\\iiint_E \\\\\\\\text{div}\\\\\\\\, \\\\\\\\mathbf{F} \\\\\\\\, dV = \\\\\\\\iint_{S} \\\\\\\\mathbf{F} \\\\\\\\cdot d\\\\\\\\mathbf{S}$. This theorem essentially relates the flux of $\\\\\\\\mathbf{F}$ through the boundary surface $S$ to the volume integral over the region $E$. For example, consider the vector field $\\\\\\\\mathbf{F} = \\\\\\\\langle x, y, z \\\\\\\\rangle$ over the solid region $E$ which is a unit ball. Applying the Divergence Theorem simplifies the problem of computing the flux through the surface of the ball (a complex surface integral) to calculating a triple integral of the divergence (a simpler volume integral).',\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-8-the-divergence-theorem',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: The flux of the vector field $\\\\\\\\mathbf{F} = \\\\\\\\frac{1}{r^2} \\\\\\\\langle x, y, z \\\\\\\\rangle$ across a connected, piecewise smooth closed surface $S$ is $4\\\\\\\\pi$ if and only if the surface $S$ encompasses the origin.',\n",
       "  'answer': 'True',\n",
       "  'explanation': \"According to the given definition, the flux of the vector field $\\\\\\\\mathbf{F} = \\\\\\\\frac{1}{r^2} \\\\\\\\langle x, y, z \\\\\\\\rangle$ across a closed surface $S$ depends entirely on whether $S$ encloses the origin or not. This concept is primarily based on the application of Gauss's theorem (also known as the Divergence theorem) in the context of this specific vector field. The theorem links the flux through a closed surface to the volume integral of the divergence of the field. In this specific case, the divergence of $\\\\\\\\mathbf{F}$ leads to a singularity at the origin causing the result to be either $0$ if the surface does not enclose the origin, or $4\\\\\\\\pi$ if it does. An example to illustrate this could be: For a sphere $S$ of radius $R$ centered at the origin, $\\\\\\\\mathbf{F} \\\\\\\\cdot \\\\\\\\mathbf{dS}$ results in the flux being $4\\\\\\\\pi$. Conversely, for a torus surface $S$ not enclosing the origin, the same integral results in $0$.\",\n",
       "  'chapter': 'Vector Calculus',\n",
       "  'section': '6-8-the-divergence-theorem',\n",
       "  'number': '2'},\n",
       " {'question': \"True or False: The second-order differential equation \\\\\\\\( 3x^2 y'' + 2xy' + y = 0 \\\\\\\\) is an example of a nonhomogeneous linear equation.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"To determine whether a second-order differential equation is homogeneous or nonhomogeneous, we look at the function \\\\\\\\( r(x) \\\\\\\\) on the right-hand side of the equation \\\\\\\\( a_2(x)y'' + a_1(x)y' + a_0(x)y = r(x) \\\\\\\\). If \\\\\\\\( r(x) \\\\\\\\equiv 0 \\\\\\\\), the equation is homogeneous; otherwise, it is nonhomogeneous. In the given equation \\\\\\\\( 3x^2 y'' + 2xy' + y = 0 \\\\\\\\), the right-hand side is zero (\\\\\\\\( r(x) = 0 \\\\\\\\)), so it is a homogeneous linear equation.\",\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-1-second-order-linear-equations',\n",
       "  'number': '1'},\n",
       " {'question': 'True or False: If $y_1(x)$ and $y_2(x)$ are solutions to a linear homogeneous differential equation, then the function $y(x) = c_1 y_1(x) + c_2 y_2(x)$, where $c_1$ and $c_2$ are constants, is not necessarily a solution.',\n",
       "  'answer': 'False',\n",
       "  'explanation': \"The superposition principle states that if $y_1(x)$ and $y_2(x)$ are solutions to a linear homogeneous differential equation, then any linear combination of them, such as $y(x) = c_1 y_1(x) + c_2 y_2(x)$, where $c_1$ and $c_2$ are arbitrary constants, is also a solution. For example, if $y_1(x) = e^x$ and $y_2(x) = e^{-x}$ are solutions to the differential equation $y'' - y = 0$, then $y(x) = c_1 e^x + c_2 e^{-x}$ is also a solution.\",\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-1-second-order-linear-equations',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The set of functions $\\\\\\\\{f_1(x), f_2(x), \\\\ldots, f_n(x)\\\\\\\\}$ is linearly dependent if and only if there exist constants $c_1, c_2, \\\\ldots, c_n$, not all zero, such that $c_1f_1(x) + c_2f_2(x) + \\\\cdots + c_nf_n(x) = 0$ for all $x$ over the interval of interest.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The definition of linear dependence asserts that a set of functions $\\\\\\\\{f_1(x), f_2(x), \\\\ldots, f_n(x)\\\\\\\\}$ is linearly dependent if there exist constants $c_1, c_2, \\\\ldots, c_n$, not all zero, such that their linear combination $c_1f_1(x) + c_2f_2(x) + \\\\cdots + c_nf_n(x)$ equals zero for all $x$ in the given interval. This means that at least one of the functions can be represented as a linear combination of the others. Conversely, if no such non-zero constants exist, the functions are linearly independent. For example, the functions $\\\\\\\\{1, x, x^2\\\\\\\\}$ are linearly independent since there are no non-zero constants $c_1, c_2, c_3$ such that $c_1 \\\\cdot 1 + c_2 \\\\cdot x + c_3 \\\\cdot x^2 = 0$ for all $x$.',\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-1-second-order-linear-equations',\n",
       "  'number': '3'},\n",
       " {'question': 'True or False: Two functions $f_1(x)$ and $f_2(x)$ are linearly dependent if and only if $f_1(x) = 2f_2(x)$ for some constant $C$ and for all $x$ over the interval of interest.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'For two functions $f_1(x)$ and $f_2(x)$ to be linearly dependent, there must exist a constant $C$ such that $f_1(x) = Cf_2(x)$ for all $x$ over the interval of interest. The given statement restricts this to $C = 2$, which is not general enough. The correct understanding is that $f_1(x)$ can be any constant multiple of $f_2(x)$, not just 2.',\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-1-second-order-linear-equations',\n",
       "  'number': '4'},\n",
       " {'question': 'True or False: If $y_1(x)$ and $y_2(x)$ are linearly independent solutions to a second-order, linear, homogeneous differential equation, then the general solution can be expressed as $y(x) = c_1 y_1(x) + c_2 y_2(x)$, where $c_1$ and $c_2$ are constants.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'For a second-order, linear, homogeneous differential equation, the general solution is formed by taking a linear combination of two linearly independent solutions. In this context, $y_1(x)$ and $y_2(x)$ are linearly independent solutions, implying that no scalar multiple of one solution can equal the other. Thus, the general solution is expressed as $y(x) = c_1 y_1(x) + c_2 y_2(x)$, where $c_1$ and $c_2$ are arbitrary constants. This ensures that all possible solutions to the differential equation are covered by varying the values of $c_1$ and $c_2$ appropriately. For example, if $y_1(x) = e^x$ and $y_2(x) = e^{-x}$, then a general solution could be $y(x) = c_1 e^x + c_2 e^{-x}$.',\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-1-second-order-linear-equations',\n",
       "  'number': '5'},\n",
       " {'question': \"True or False: The characteristic equation for the differential equation $a y'' + b y' + c y = 0$ is $a \\\\lambda^2 + b \\\\lambda + c = 0$.\",\n",
       "  'answer': 'True',\n",
       "  'explanation': \"The characteristic equation is obtained by assuming that the solution to the differential equation $a y'' + b y' + c y = 0$ takes the form $y = e^{\\\\lambda t}$. Substituting this assumed solution into the differential equation, we obtain $a \\\\lambda^2 e^{\\\\lambda t} + b \\\\lambda e^{\\\\lambda t} + c e^{\\\\lambda t} = 0$. Factoring out $e^{\\\\lambda t}$, a non-zero term, yields the quadratic equation $a \\\\lambda^2 + b \\\\lambda + c = 0$. This is known as the characteristic equation, and solving it provides the values for $\\\\lambda$ that determine the general solution of the differential equation.\",\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-1-second-order-linear-equations',\n",
       "  'number': '6'},\n",
       " {'question': 'True or False: A particular solution $y_p(x)$ of a differential equation must contain arbitrary constants.',\n",
       "  'answer': 'False',\n",
       "  'explanation': 'A particular solution $y_p(x)$ of a differential equation is specifically defined to contain no arbitrary constants. This means it is a specific solution that satisfies the differential equation without any free parameters. For example, if the general solution of a differential equation is $y(x) = C_1 e^x + C_2 e^{-x}$ (where $C_1$ and $C_2$ are arbitrary constants), a particular solution could be $y_p(x) = e^x$, which does not include any arbitrary constants.',\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-2-nonhomogeneous-linear-equations',\n",
       "  'number': '1'},\n",
       " {'question': \"True or False: If $y_p(x)$ is a particular solution to the nonhomogeneous linear differential equation $a_2(x)y'' + a_1(x)y' + a_0(x)y = r(x)$ and $c_1 y_1(x) + c_2 y_2(x)$ is the general solution to the homogeneous equation $a_2(x)y'' + a_1(x)y' + a_0(x)y = 0$, then the general solution to the nonhomogeneous equation is given by $y(x) = c_1 y_1(x) + c_2 y_2(x) - y_p(x)$.\",\n",
       "  'answer': 'False',\n",
       "  'explanation': \"The general solution to the nonhomogeneous linear differential equation $a_2(x)y'' + a_1(x)y' + a_0(x)y = r(x)$ is actually given by $y(x) = c_1 y_1(x) + c_2 y_2(x) + y_p(x)$, not $y(x) = c_1 y_1(x) + c_2 y_2(x) - y_p(x)$. Here, $y_p(x)$ is any particular solution to the nonhomogeneous equation, and $c_1 y_1(x) + c_2 y_2(x)$ is the general solution to the corresponding homogeneous equation $a_2(x)y'' + a_1(x)y' + a_0(x)y = 0$. For example, consider the nonhomogeneous equation $y'' - y = e^x$. A particular solution is $y_p(x) = \\\\frac{1}{2}e^x$, and the complementary solution is $c_1 e^x + c_2 e^{-x}$. Thus, the general solution is $y(x) = c_1 e^x + c_2 e^{-x} + \\\\frac{1}{2} e^x$.\",\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-2-nonhomogeneous-linear-equations',\n",
       "  'number': '2'},\n",
       " {'question': 'True or False: The function $x(t) = c_1 \\\\cos(ωt) + c_2 \\\\sin(ωt)$ can be rewritten in the form $x(t) = A \\\\sin(ωt + ϕ)$, where $A = \\\\sqrt{c_1^2 + c_2^2}$ and $ϕ = \\\\tan^{-1}(\\\\frac{c_2}{c_1})$.',\n",
       "  'answer': 'True',\n",
       "  'explanation': 'The given function $x(t) = c_1 \\\\cos(ωt) + c_2 \\\\sin(ωt)$ can indeed be rewritten in the form $x(t) = A \\\\sin(ωt + ϕ)$. Here, the amplitude $A$ is given by $A = \\\\sqrt{c_1^2 + c_2^2}$, which comes from the Pythagorean identity considering $c_1$ and $c_2$ as the components of a right triangle. The phase angle $ϕ$ is determined by the ratio of $c_2$ to $c_1$, resulting in $ϕ = \\\\tan^{-1}(\\\\frac{c_2}{c_1})$. For example, if $c_1 = 3$ and $c_2 = 4$, then $A = \\\\sqrt{3^2 + 4^2} = 5$ and $ϕ = \\\\tan^{-1}(\\\\frac{4}{3})$.',\n",
       "  'chapter': 'Second-Order Differential Equations',\n",
       "  'section': '7-3-applications',\n",
       "  'number': '1'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "382ab79a-de09-4b79-b59c-9dee5aa550da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions =  dict()\n",
    "for q in questions:\n",
    "    chapter = q['chapter']\n",
    "    section = q['section']\n",
    "    quest = q['question'].replace(\"\\\\\\\\\", \"\\\\\")\n",
    "    explanation = q['explanation'].replace(\"\\\\\\\\\", \"\\\\\")\n",
    "    generated_question = f\"\"\"\\\\item {quest.replace(\"True or False:\", \"\").strip()}\n",
    "    \n",
    "    \\\\ifnum \\\\Solutions=1 {{\\\\color{{EmphBlue}} Answer: {q['answer']} \\\\\\\\ Explanation: {explanation}}}\n",
    "    \\\\fi\"\"\"\n",
    "\n",
    "    if (chapter not in all_questions):\n",
    "        all_questions[chapter] = dict()\n",
    "    if (section not in all_questions[chapter]):\n",
    "        all_questions[chapter][section] = []\n",
    "    all_questions[chapter][section].append(generated_question)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36d1a590-c5ca-4a0f-8859-ae92a1dba129",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"./generated_files/MultivariableCalculus/\"\n",
    "i = 0;\n",
    "for chapter in all_questions:\n",
    "    i+=1;\n",
    "    # chapter_directory = location + f\"Chapter {i}: \" + chapter + \"/\"\n",
    "    chapter_directory = location + f\"Chapter{i}/\"\n",
    "    if (not os.path.exists(chapter_directory)):\n",
    "        os.mkdir(chapter_directory)\n",
    "    for section in all_questions[chapter]:\n",
    "        path = chapter_directory + section + \".tex\"\n",
    "        section_title = ' '.join(section.split(\"-\")[2:]).title()\n",
    "        joined_questions = ('\\n'.join(all_questions[chapter][section]))\n",
    "        with open(path, \"w\") as f:\n",
    "            latex = \"\\\\section{\" + section_title + \"}\" + f\"\"\"\n",
    "                \\\\begin{{enumerate}}\n",
    "                {unicode_to_latex(joined_questions, non_ascii_only=True)}\n",
    "                \\\\end{{enumerate}}\n",
    "                \"\"\"\n",
    "            f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8680584e-3bfb-4822-b1ca-479a6e94d985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\chapter{Parametric Equations and Polar Coordinates}\n",
      "\\input{Chapter1/1-1-parametric-equations}\n",
      "\\input{Chapter1/1-2-calculus-of-parametric-curves}\n",
      "\\input{Chapter1/1-3-polar-coordinates}\n",
      "\\input{Chapter1/1-4-area-and-arc-length-in-polar-coordinates}\n",
      "\\input{Chapter1/1-5-conic-sections}\n",
      "\\chapter{Vectors in Space}\n",
      "\\input{Chapter2/2-1-vectors-in-the-plane}\n",
      "\\input{Chapter2/2-2-vectors-in-three-dimensions}\n",
      "\\input{Chapter2/2-3-the-dot-product}\n",
      "\\input{Chapter2/2-4-the-cross-product}\n",
      "\\input{Chapter2/2-5-equations-of-lines-and-planes-in-space}\n",
      "\\input{Chapter2/2-6-quadric-surfaces}\n",
      "\\input{Chapter2/2-7-cylindrical-and-spherical-coordinates}\n",
      "\\chapter{Vector-Valued Functions}\n",
      "\\input{Chapter3/3-1-vector-valued-functions-and-space-curves}\n",
      "\\input{Chapter3/3-2-calculus-of-vector-valued-functions}\n",
      "\\input{Chapter3/3-3-arc-length-and-curvature}\n",
      "\\input{Chapter3/3-4-motion-in-space}\n",
      "\\chapter{Differentiation of Functions of Several Variables}\n",
      "\\input{Chapter4/4-1-functions-of-several-variables}\n",
      "\\input{Chapter4/4-2-limits-and-continuity}\n",
      "\\input{Chapter4/4-3-partial-derivatives}\n",
      "\\input{Chapter4/4-4-tangent-planes-and-linear-approximations}\n",
      "\\input{Chapter4/4-5-the-chain-rule}\n",
      "\\input{Chapter4/4-6-directional-derivatives-and-the-gradient}\n",
      "\\input{Chapter4/4-7-maxima-minima-problems}\n",
      "\\input{Chapter4/4-8-lagrange-multipliers}\n",
      "\\chapter{Multiple Integration}\n",
      "\\input{Chapter5/5-1-double-integrals-over-rectangular-regions}\n",
      "\\input{Chapter5/5-2-double-integrals-over-general-regions}\n",
      "\\input{Chapter5/5-3-double-integrals-in-polar-coordinates}\n",
      "\\input{Chapter5/5-4-triple-integrals}\n",
      "\\input{Chapter5/5-5-triple-integrals-in-cylindrical-and-spherical-coordinates}\n",
      "\\input{Chapter5/5-6-calculating-centers-of-mass-and-moments-of-inertia}\n",
      "\\input{Chapter5/5-7-change-of-variables-in-multiple-integrals}\n",
      "\\chapter{Vector Calculus}\n",
      "\\input{Chapter6/6-1-vector-fields}\n",
      "\\input{Chapter6/6-2-line-integrals}\n",
      "\\input{Chapter6/6-3-conservative-vector-fields}\n",
      "\\input{Chapter6/6-4-greens-theorem}\n",
      "\\input{Chapter6/6-5-divergence-and-curl}\n",
      "\\input{Chapter6/6-6-surface-integrals}\n",
      "\\input{Chapter6/6-7-stokes-theorem}\n",
      "\\input{Chapter6/6-8-the-divergence-theorem}\n",
      "\\chapter{Second-Order Differential Equations}\n",
      "\\input{Chapter7/7-1-second-order-linear-equations}\n",
      "\\input{Chapter7/7-2-nonhomogeneous-linear-equations}\n",
      "\\input{Chapter7/7-3-applications}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "/tmp/ipykernel_2879630/1059457583.py:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  print(\"\\chapter{\" + a + \"}\")\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for a in all_questions:\n",
    "    i+=1\n",
    "    print(\"\\\\chapter{\" + a + \"}\")\n",
    "    for b in all_questions[a]:\n",
    "        print(\"\\\\input{Chapter\" + str(i) + f\"/{b}\" + \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f0991-9e73-4151-be3a-07d34e410ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "question-generator (myenv)",
   "language": "python",
   "name": "question-generator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
